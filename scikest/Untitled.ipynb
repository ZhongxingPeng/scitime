{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Desktop/scikest\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikest.train import Trainer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikest.train.Trainer:INFO:Generating dummy training durations to create a training set\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 154.64937591552734 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 82.27437591552734 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 212.9084439277649 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 7.341813087463379 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 75.22556281089783 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.9593558311462402 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 78.74309372901917 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.9703540802001953 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 78.26599192619324 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 107.2333619594574 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 43.410680055618286 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 3.631678342819214 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.7599287033081055 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 82.44717502593994 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 1.6116249561309814 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 44.84040117263794 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.7530951499938965 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 157.29675388336182 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.9490323066711426 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 4.923130989074707 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 4.341777086257935 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 59.0531120300293 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 7.0052032470703125 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 4.599289178848267 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 2.5309131145477295 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 10.58789873123169 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 95.03422117233276 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 50.319899797439575 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 86.0964879989624 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 218.50295400619507 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 3.2712390422821045 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 160.63943719863892 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 7.20452880859375 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 7.170783996582031 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.9984979629516602 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 3.508364200592041 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 4.675762891769409 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 9.272800922393799 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 54.55322885513306 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.9086489677429199 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.6910688877105713 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 1.4345118999481201 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 88.13018608093262 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 43.57166790962219 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 1.8329672813415527 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 1.5030479431152344 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.8347609043121338 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 4.805279970169067 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 217.6943337917328 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.8416440486907959 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 49.92408514022827 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 5.4282166957855225 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.7528030872344971 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.772291898727417 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 109.72019720077515 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 7.255817890167236 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.7853271961212158 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 3.425938844680786 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 3.5730648040771484 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 57.19715404510498 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 4.971391916275024 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 80.31871795654297 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.8493030071258545 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 156.04837775230408 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 3.5922141075134277 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 3.23600697517395 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 107.16872072219849 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 7.122172832489014 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 50.39636301994324 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 4.715657949447632 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 7.2461419105529785 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 1.110720157623291 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 61.74249601364136 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 3.8960890769958496 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 2.9611990451812744 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 208.1505527496338 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.6269712448120117 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 7.223683834075928 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 78.64342522621155 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.7888062000274658 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 79.81802916526794 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.7299261093139648 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.7421576976776123 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0, 'max_features': 20, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 202.7479658126831 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 7.13103723526001 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.8724360466003418 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 48.21693992614746 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 1.0198338031768799 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.8266899585723877 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 155.8717451095581 seconds\n",
      "scikest.train.Trainer:WARNING:model fit for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 1.3226158618927002 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 58.57104778289795 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': None, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 208.78128576278687 seconds\n",
      "scikest.train.Trainer:INFO:data added for {'num_rows': 10000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': None, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 78.50138807296753 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0f4ee8c594b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/scikest/scikest/log.py\u001b[0m in \u001b[0;36mtimed\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{method.__qualname__} took {round(te - ts, 3)}s seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36mmodel_fit\u001b[0;34m(self, generate_data, inputs, outputs, save_model)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \"\"\"\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/log.py\u001b[0m in \u001b[0;36mtimed\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{method.__qualname__} took {round(te - ts, 3)}s seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36m_generate_data\u001b[0;34m(self, validation)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         inputs, outputs, estimated_outputs = self._permute(concat_dic, parameters_list, external_parameters_list,\n\u001b[0;32m--> 205\u001b[0;31m                                                            meta_params, algo_type, validation)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/log.py\u001b[0m in \u001b[0;36mtimed\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{method.__qualname__} took {round(te - ts, 3)}s seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36m_permute\u001b[0;34m(self, concat_dic, parameters_list, external_parameters_list, meta_params, algo_type, validation)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0mrow_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_cpu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mrow_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_measure_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36m_measure_time\u001b[0;34m(model, X, y, meta_params)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melapsed_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(drop_rate=0.99 ,verbose=3)\n",
    "dfs = trainer.model_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Desktop/RFDATA\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/RFDATA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('new_clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Desktop/scikest\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/scikest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikest.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = Trainer(verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: clean row\n",
    "def clean(row):\n",
    "    try:\n",
    "        return int(row)\n",
    "    except:\n",
    "        return row\n",
    "df_1['max_features'] = df_1['max_features'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = df_1.drop(['Unnamed: 0', 'output'], axis=1), df_1[['output']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['auto', 10, 50, 20, 100, 30, 40, 200, 4, 1, 2, 3, 5], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.max_features.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikest.train.Trainer:INFO:Transforming dataset for semi dummy features\n",
      "scikest.train.Trainer:INFO:Model inputs: ['total_memory', 'available_memory', 'num_cpu', 'num_rows', 'num_features', 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'min_weight_fraction_leaf', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'bootstrap', 'oob_score', 'n_jobs', 'max_depth_None', 'max_features_auto', 'max_leaf_nodes_None', 'min_impurity_split_None']\n"
     ]
    }
   ],
   "source": [
    "X,y,col,cols = t._transform_data(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=3, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=[2000], learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=8000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=9, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0, validation_fraction=0.1, verbose=3,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPRegressor(alpha=0.0001,max_iter=8000, activation='tanh', solver='lbfgs', random_state=9, tol=0.0000000,hidden_layer_sizes=[2000], early_stopping=False, verbose=3)\n",
    "mlp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.660497442325983"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#25secs\n",
    "np.sqrt(mean_squared_error(y, mlp.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(np.unique(mlp.predict(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.6396968364715576,\n",
       " 0.99065208435058605,\n",
       " 1.9765419960021973,\n",
       " 2.501600980758667,\n",
       " 1.0017199516296389,\n",
       " 2.7320578098297119,\n",
       " 0.94883513450622559,\n",
       " 0.9593651294708252,\n",
       " 9.4498558044433594,\n",
       " 9.3593528270721453,\n",
       " 16.44660496711731,\n",
       " 6.7557339668273926,\n",
       " 16.696814298629761,\n",
       " 1.6611478328704834,\n",
       " 1.4855382442474363,\n",
       " 19.698585987091068,\n",
       " 2.270305871963501,\n",
       " 2.1334619522094727,\n",
       " 2.4163429737091064,\n",
       " 20.100405931472785,\n",
       " 11.148092985153198,\n",
       " 3.5301220417022705,\n",
       " 2.3471980094909668,\n",
       " 2.399691104888916,\n",
       " 2.410973072052002,\n",
       " 1.4912629127502439,\n",
       " 1.9122459888458248,\n",
       " 1.1502659320831301,\n",
       " 9.1019179821014387,\n",
       " 1.1914129257202148,\n",
       " 1.1847960948944092,\n",
       " 1.1912450790405271,\n",
       " 7.8466351032257071,\n",
       " 11.416064977645874,\n",
       " 3.6994240283966064,\n",
       " 1.9708521366119385,\n",
       " 12.413171768188475,\n",
       " 1.9394419193267824,\n",
       " 1.3904147148132324,\n",
       " 3.4963159561157227,\n",
       " 1.5721132755279541,\n",
       " 2.0711932182312007,\n",
       " 1.262408971786499,\n",
       " 1.5732581615447998,\n",
       " 1.1499159336090088,\n",
       " 1.0293228626251221,\n",
       " 2.1776719093322754,\n",
       " 1.5365371704101562,\n",
       " 0.83307528495788574,\n",
       " 1.1627492904663086,\n",
       " 2.1861109733581543,\n",
       " 1.0821890830993652,\n",
       " 4.0414271354675284,\n",
       " 17.32170581817627,\n",
       " 2.202768087387085,\n",
       " 15.965322971343994,\n",
       " 6.1374049186706516,\n",
       " 6.3604230880737305,\n",
       " 1.4192078113555908,\n",
       " 1.429877758026123,\n",
       " 1.4090571403503418,\n",
       " 1.7391769886016846,\n",
       " 0.32790684700012213,\n",
       " 0.91185188293457042,\n",
       " 0.9442911148071288,\n",
       " 0.36596202850341802,\n",
       " 0.33153009414672852,\n",
       " 0.33740687370300287,\n",
       " 7.6563341617584229,\n",
       " 0.70620894432067871,\n",
       " 3.4140939712524414,\n",
       " 1.0577960014343262,\n",
       " 6.4692111015319824,\n",
       " 1.1372799873352051,\n",
       " 10.511122941970823,\n",
       " 1.3094840049743652,\n",
       " 10.69046688079834,\n",
       " 16.030905961990356,\n",
       " 1.5089302062988279,\n",
       " 0.27531194686889648,\n",
       " 0.2822959423065185,\n",
       " 0.8115541934967041,\n",
       " 0.47826910018920898,\n",
       " 0.3788752555847168,\n",
       " 0.27796506881713873,\n",
       " 0.38118886947631841,\n",
       " 1.0624210834503174,\n",
       " 1.2811861038208008,\n",
       " 1.071397066116333,\n",
       " 0.27046704292297363,\n",
       " 1.6571619510650637,\n",
       " 0.41278195381164551,\n",
       " 1.9158568382263184,\n",
       " 3.7323038578033447,\n",
       " 2.021583080291748,\n",
       " 4.3648409843444815,\n",
       " 2.5432357788085938,\n",
       " 0.51671814918518066,\n",
       " 0.40995097160339361,\n",
       " 0.36913204193115229,\n",
       " 0.34356498718261719,\n",
       " 0.35747313499450684,\n",
       " 0.4714891910552978,\n",
       " 0.38046574592590332,\n",
       " 0.38982772827148438,\n",
       " 0.18436193466186526,\n",
       " 1.7361369132995603,\n",
       " 0.48865008354187012,\n",
       " 0.28391218185424805,\n",
       " 0.42251014709472656,\n",
       " 2.1630620956420903,\n",
       " 1.799652099609375,\n",
       " 0.5755760669708252,\n",
       " 8.503633975982666,\n",
       " 7.8200430870056152,\n",
       " 1.9887478351593011,\n",
       " 2.0034818649291988,\n",
       " 4.2923398017883301,\n",
       " 5.5198521614074716,\n",
       " 8.1753818988800049,\n",
       " 4.1946110725402832,\n",
       " 2.0556674003601074,\n",
       " 4.2688050270080566,\n",
       " 2.1557400226593018,\n",
       " 4.080470085144043,\n",
       " 12.736166000366213,\n",
       " 34.702160835266106,\n",
       " 2.9720408916473389,\n",
       " 2.976560115814209,\n",
       " 12.087102890014648,\n",
       " 11.160573959350586,\n",
       " 31.93537878990173,\n",
       " 21.809358835220337,\n",
       " 3.1076669692993164,\n",
       " 2.8670587539672852,\n",
       " 2.8760218620300293,\n",
       " 9.5879080295562726,\n",
       " 7.1073307991027823,\n",
       " 5.3257420063018799,\n",
       " 69.21123099327086,\n",
       " 67.451202869415283,\n",
       " 66.902997016906738,\n",
       " 1.1874499320983891,\n",
       " 1.0292360782623291,\n",
       " 4.3759169578552255,\n",
       " 4.5309710502624512,\n",
       " 12.500858068466187,\n",
       " 11.484102725982664,\n",
       " 33.846876859664924,\n",
       " 2.3394229412078857,\n",
       " 10.26121997833252,\n",
       " 2.2173030376434326,\n",
       " 66.071314096450791,\n",
       " 7.5385720729827872,\n",
       " 68.370000123977647,\n",
       " 4.0637609958648682,\n",
       " 7.9274618625640878,\n",
       " 4.2907350063323975,\n",
       " 4.1793742179870605,\n",
       " 569.8985080718993,\n",
       " 224.72003102302551,\n",
       " 244.2170627117157,\n",
       " 237.16353178024289,\n",
       " 221.12734484672544,\n",
       " 230.47888779640201,\n",
       " 235.42155194282529,\n",
       " 216.36144614219663,\n",
       " 214.98210120201111,\n",
       " 226.09169888496399,\n",
       " 232.17589092254642,\n",
       " 226.03108477592468,\n",
       " 7.0921101570129403,\n",
       " 4.2563309669494629,\n",
       " 8.3339231014251709,\n",
       " 0.72224307060241699,\n",
       " 6.512164831161499,\n",
       " 4.4253380298614502,\n",
       " 6.8820102214813224,\n",
       " 0.78075385093688965,\n",
       " 2.7631621360778809,\n",
       " 1.7461147308349609,\n",
       " 1.7793200016021729,\n",
       " 12.73531174659729,\n",
       " 1.7108311653137207,\n",
       " 5.3045978546142578,\n",
       " 4.8683509826660165,\n",
       " 1.76845383644104,\n",
       " 7.9131028652191162,\n",
       " 3.1007258892059326,\n",
       " 7.1647360324859628,\n",
       " 2.9022238254547119,\n",
       " 33.181116819381714,\n",
       " 6.1025462150573722,\n",
       " 3.7001059055328369,\n",
       " 23.613882780075073,\n",
       " 8.5447399616241473,\n",
       " 3.8489079475402832,\n",
       " 3.6555619239807129,\n",
       " 3.3609719276428223,\n",
       " 7.4670038223266602,\n",
       " 1.313046932220459,\n",
       " 4.9525058269500732,\n",
       " 1.1574587821960449,\n",
       " 1.191331148147583,\n",
       " 3.0488097667694087,\n",
       " 33.020812034606926,\n",
       " 3.3589498996734619,\n",
       " 32.784518957138054,\n",
       " 6.3755290508270264,\n",
       " 33.874639987945557,\n",
       " 4.9393641948699951,\n",
       " 9.6791238784790039,\n",
       " 1.7216770648956301,\n",
       " 1.5209388732910156,\n",
       " 32.95893931388855,\n",
       " 8.5902400016784686,\n",
       " 5.708280086517334,\n",
       " 16.163385152816772,\n",
       " 23.759759902954102,\n",
       " 5.6714470386505127,\n",
       " 6.9385888576507577,\n",
       " 6.8184289932250977,\n",
       " 10.618829965591429,\n",
       " 23.809983015060425,\n",
       " 71.638052940368652,\n",
       " 8.4305469989776611,\n",
       " 1.9220478534698489,\n",
       " 2.3921809196472168,\n",
       " 4.5667662620544434,\n",
       " 1.9080266952514648,\n",
       " 1.8365840911865241,\n",
       " 1.7124772071838381,\n",
       " 3.9174759387969971,\n",
       " 13.242067098617554,\n",
       " 11.96455192565918,\n",
       " 23.611342191696171,\n",
       " 3.0161750316619886,\n",
       " 5.0765209197998047,\n",
       " 6.7831358909606925,\n",
       " 3.9349770545959473,\n",
       " 67.7610569000244,\n",
       " 22.76624703407288,\n",
       " 7.1418941020965576,\n",
       " 21.112554073333737,\n",
       " 11.750306129455565,\n",
       " 9.3685221672058105,\n",
       " 32.045736074447625,\n",
       " 15.451483011245728,\n",
       " 8.8355231285095215,\n",
       " 34.950169801712043,\n",
       " 19.236552953720093,\n",
       " 23.590514898300171,\n",
       " 18.965276002883911,\n",
       " 21.000531911849976,\n",
       " 15.510055780410767,\n",
       " 24.035312175750732,\n",
       " 16.600022077560425,\n",
       " 34.62657618522644,\n",
       " 33.717164039611816,\n",
       " 10.118722200393675,\n",
       " 32.984634876251221,\n",
       " 51.803428173065186,\n",
       " 26.427707195281982,\n",
       " 30.962695837020874,\n",
       " 22.536164283752441,\n",
       " 40.246304988861091,\n",
       " 24.5609290599823,\n",
       " 33.357803106307976,\n",
       " 25.905377864837646,\n",
       " 29.715124130249023,\n",
       " 50.801390647888184,\n",
       " 21.707671880722046,\n",
       " 25.159125089645386,\n",
       " 26.494355916976929,\n",
       " 19.605075836181641,\n",
       " 49.091561079025276,\n",
       " 141.58187818527222,\n",
       " 140.14389586448669,\n",
       " 153.00578618049622,\n",
       " 7.4385709762573242,\n",
       " 4.3515279293060294,\n",
       " 0.015442848205566406,\n",
       " 0.11684012413024902,\n",
       " 0.013324737548828123,\n",
       " 0.11483216285705565,\n",
       " 0.11593198776245114,\n",
       " 0.010036945343017578,\n",
       " 0.0092890262603759766,\n",
       " 0.0093901157379150408,\n",
       " 0.043128013610839837,\n",
       " 0.14194512367248535,\n",
       " 0.043070077896118164,\n",
       " 0.1502227783203125,\n",
       " 0.16888594627380371,\n",
       " 0.1717979907989502,\n",
       " 0.1082139015197754,\n",
       " 0.11047077178955078,\n",
       " 0.11244010925292967,\n",
       " 0.012832880020141602,\n",
       " 0.1121230125427246,\n",
       " 0.010438919067382812,\n",
       " 0.13977503776550293,\n",
       " 0.13818693161010742,\n",
       " 0.051028966903686516,\n",
       " 0.13738107681274414,\n",
       " 0.13655495643615725,\n",
       " 0.13479113578796387,\n",
       " 0.17243814468383789,\n",
       " 0.17191696166992188,\n",
       " 0.17325115203857422,\n",
       " 0.16000628471374512,\n",
       " 0.16885089874267578,\n",
       " 0.16614294052124026,\n",
       " 0.15902996063232422,\n",
       " 0.15960288047790527,\n",
       " 0.11093878746032716,\n",
       " 0.11172699928283693,\n",
       " 0.1139371395111084,\n",
       " 0.11203384399414062,\n",
       " 0.11378097534179688,\n",
       " 0.1372830867767334,\n",
       " 0.13280081748962402,\n",
       " 0.13706207275390625,\n",
       " 0.13745498657226562,\n",
       " 0.15967106819152832,\n",
       " 0.15715408325195312,\n",
       " 0.095433950424194336,\n",
       " 0.16612982749938965,\n",
       " 0.16291308403015134,\n",
       " 0.10972213745117188,\n",
       " 0.10989022254943848,\n",
       " 0.011043071746826172,\n",
       " 0.13918399810791016,\n",
       " 0.13569998741149902,\n",
       " 0.041654109954833984,\n",
       " 0.13203001022338867,\n",
       " 0.094406843185424805,\n",
       " 0.17253494262695312,\n",
       " 0.16735482215881348,\n",
       " 0.16081380844116211,\n",
       " 0.012121915817260742,\n",
       " 0.11467599868774415,\n",
       " 0.11224198341369628,\n",
       " 0.1227409839630127,\n",
       " 0.11400890350341795,\n",
       " 0.13783407211303711,\n",
       " 0.1418461799621582,\n",
       " 0.040304899215698235,\n",
       " 0.033975601196289062,\n",
       " 0.13506984710693359,\n",
       " 0.13749289512634275,\n",
       " 0.049702167510986328,\n",
       " 0.051637172698974609,\n",
       " 0.039359092712402337,\n",
       " 0.051553964614868164,\n",
       " 0.17236709594726562,\n",
       " 0.16960287094116211,\n",
       " 0.1691899299621582,\n",
       " 0.079175233840942369,\n",
       " 0.16793584823608398,\n",
       " 0.16506528854370114,\n",
       " 0.074368000030517578,\n",
       " 0.16668605804443359,\n",
       " 0.16771817207336426,\n",
       " 0.07648468017578125,\n",
       " 0.013942956924438477,\n",
       " 0.011851072311401369,\n",
       " 0.0085768699645996094,\n",
       " 0.1314539909362793,\n",
       " 0.13653993606567386,\n",
       " 0.13326311111450195,\n",
       " 0.03992772102355957,\n",
       " 0.13280892372131348,\n",
       " 0.13453125953674314,\n",
       " 0.047340869903564453,\n",
       " 0.14002203941345215,\n",
       " 0.064971208572387695,\n",
       " 0.16160082817077634,\n",
       " 0.17001605033874512,\n",
       " 0.15818595886230469,\n",
       " 0.16443204879760742,\n",
       " 0.16998410224914551,\n",
       " 0.17427611351013186,\n",
       " 0.17198395729064939,\n",
       " 0.11301398277282715,\n",
       " 0.1117560863494873,\n",
       " 0.11342573165893555,\n",
       " 0.012600183486938477,\n",
       " 0.11252474784851074,\n",
       " 0.052855014801025391,\n",
       " 0.1362907886505127,\n",
       " 0.14143204689025879,\n",
       " 0.13926196098327634,\n",
       " 0.13547801971435547,\n",
       " 0.043247222900390632,\n",
       " 0.14308905601501465,\n",
       " 0.1423189640045166,\n",
       " 0.14113903045654294,\n",
       " 0.13911104202270508,\n",
       " 0.040663003921508789,\n",
       " 0.16241979598999026,\n",
       " 0.17572927474975586,\n",
       " 0.16900181770324707,\n",
       " 0.16768193244934082,\n",
       " 0.1764681339263916,\n",
       " 0.17264723777770996,\n",
       " 0.11138391494750977,\n",
       " 0.11067819595336914,\n",
       " 0.11060404777526857,\n",
       " 0.11559391021728516,\n",
       " 0.13614511489868164,\n",
       " 0.1400599479675293,\n",
       " 0.13905596733093262,\n",
       " 0.14063477516174314,\n",
       " 0.13857698440551758,\n",
       " 0.13970613479614258,\n",
       " 0.13993406295776367,\n",
       " 0.17151737213134766,\n",
       " 0.1693272590637207,\n",
       " 0.27529287338256841,\n",
       " 0.16393494606018064,\n",
       " 0.28107619285583496,\n",
       " 0.12120199203491212,\n",
       " 0.27006983757019043,\n",
       " 0.014165163040161131,\n",
       " 0.030484914779663086,\n",
       " 0.11207675933837891,\n",
       " 0.11188101768493652,\n",
       " 0.11072325706481934,\n",
       " 0.11074304580688477,\n",
       " 0.11497926712036133,\n",
       " 0.11125588417053224,\n",
       " 0.039006948471069336,\n",
       " 0.12108278274536133,\n",
       " 0.11368274688720705,\n",
       " 0.11143898963928224,\n",
       " 0.14079403877258301,\n",
       " 0.061484098434448235,\n",
       " 0.11311912536621095,\n",
       " 0.2890779972076416,\n",
       " 0.17092204093933105,\n",
       " 0.16559505462646484,\n",
       " 0.26524806022644043,\n",
       " 0.16727209091186526,\n",
       " 0.26712203025817871,\n",
       " 0.17031025886535645,\n",
       " 0.26679205894470209,\n",
       " 0.12301111221313475,\n",
       " 0.021132707595825195,\n",
       " 0.018044233322143555,\n",
       " 0.117401123046875,\n",
       " 0.12003087997436525,\n",
       " 0.11750984191894533,\n",
       " 0.11770510673522948,\n",
       " 0.14065909385681152,\n",
       " 0.14215183258056641,\n",
       " 0.13985681533813474,\n",
       " 0.1759040355682373,\n",
       " 0.1741640567779541,\n",
       " 0.33654475212097168,\n",
       " 0.27259325981140137,\n",
       " 0.16374683380126953,\n",
       " 0.12449121475219728,\n",
       " 0.11873888969421388,\n",
       " 0.11798477172851562,\n",
       " 0.11815786361694335,\n",
       " 0.11854887008666992,\n",
       " 0.13643693923950195,\n",
       " 0.14660501480102539,\n",
       " 0.14100003242492676,\n",
       " 0.14256715774536133,\n",
       " 0.14196109771728516,\n",
       " 0.13260483741760254,\n",
       " 0.16647005081176758,\n",
       " 0.17503499984741211,\n",
       " 0.11120986938476562,\n",
       " 0.16276907920837402,\n",
       " 0.12077021598815918,\n",
       " 0.12140798568725585,\n",
       " 0.042558431625366211,\n",
       " 0.12846708297729492,\n",
       " 0.12292981147766112,\n",
       " 0.11811017990112305,\n",
       " 0.12106490135192872,\n",
       " 0.11992192268371582,\n",
       " 0.11726284027099609,\n",
       " 0.14258003234863281,\n",
       " 0.14223408699035645,\n",
       " 0.15062499046325686,\n",
       " 0.14797496795654294,\n",
       " 0.14536190032958984,\n",
       " 0.1513373851776123,\n",
       " 0.13864302635192871,\n",
       " 0.28836989402771002,\n",
       " 0.17699408531188965,\n",
       " 0.16605019569396973,\n",
       " 0.17296004295349121,\n",
       " 0.17552709579467773,\n",
       " 0.27171587944030762,\n",
       " 0.11805486679077147,\n",
       " 0.27076268196105963,\n",
       " 0.13427209854125974,\n",
       " 0.041068792343139648,\n",
       " 0.042971134185791016,\n",
       " 0.12356686592102052,\n",
       " 0.12869501113891602,\n",
       " 0.12811589241027832,\n",
       " 0.1481468677520752,\n",
       " 0.14899682998657227,\n",
       " 0.071152925491333008,\n",
       " 0.14925694465637207,\n",
       " 0.070908069610595703,\n",
       " 0.15670228004455564,\n",
       " 0.28236603736877441,\n",
       " 0.11942100524902345,\n",
       " 0.18125391006469727,\n",
       " 0.17951488494873047,\n",
       " 0.17683887481689453,\n",
       " 0.1781611442565918,\n",
       " 0.12942099571228027,\n",
       " 0.29421305656433105,\n",
       " 0.28003096580505371,\n",
       " 0.2718510627746582,\n",
       " 0.18518710136413569,\n",
       " 0.29078292846679688,\n",
       " 0.2744448184967041,\n",
       " 0.11359786987304688,\n",
       " 0.14594388008117676,\n",
       " 0.13954806327819824,\n",
       " 0.060476064682006836,\n",
       " 0.1436312198638916,\n",
       " 0.13976311683654785,\n",
       " 0.044373989105224609,\n",
       " 0.16729998588562012,\n",
       " 0.16430997848510742,\n",
       " 0.083048820495605469,\n",
       " 0.16852474212646484,\n",
       " 0.16578388214111328,\n",
       " 0.16641879081726074,\n",
       " 0.16160106658935547,\n",
       " 0.16839194297790527,\n",
       " 0.16495704650878906,\n",
       " 0.079496860504150391,\n",
       " 0.16809487342834473,\n",
       " 0.12884974479675293,\n",
       " 0.13777399063110352,\n",
       " 0.13301897048950195,\n",
       " 0.19582104682922369,\n",
       " 0.19216513633728027,\n",
       " 0.29094815254211426,\n",
       " 0.29521608352661127,\n",
       " 0.28931021690368652,\n",
       " 0.20063877105712891,\n",
       " 0.19128012657165527,\n",
       " 0.19653487205505371,\n",
       " 0.1993370056152344,\n",
       " 0.073143959045410156,\n",
       " 0.12744808197021484,\n",
       " 1.3098669052124023,\n",
       " 0.40177202224731451,\n",
       " 2.469310998916626,\n",
       " 0.3665778636932373,\n",
       " 0.39458107948303223,\n",
       " 0.38921809196472168,\n",
       " 0.36978983879089361,\n",
       " 0.26355481147766113,\n",
       " 1.5102250576019287,\n",
       " 1.4923250675201416,\n",
       " 1.4783139228820801,\n",
       " 0.16936802864074707,\n",
       " 0.9619879722595216,\n",
       " 1.2135670185089111,\n",
       " 1.9033598899841309,\n",
       " 0.31876301765441889,\n",
       " 2.2323310375213623,\n",
       " 0.4717869758605957,\n",
       " 2.5849637985229492,\n",
       " 0.29877114295959473,\n",
       " 1.9852578639984131,\n",
       " 0.13672709465026855,\n",
       " 0.2804648876190185,\n",
       " 0.39786076545715332,\n",
       " 0.10108613967895508,\n",
       " 0.16122078895568848,\n",
       " 0.31218814849853521,\n",
       " 0.63330388069152832,\n",
       " 0.31460094451904297,\n",
       " 1.5409109592437744,\n",
       " 1.4074561595916748,\n",
       " 0.97716832160949718,\n",
       " 2.6793448925018311,\n",
       " 0.43837094306945795,\n",
       " 0.48451709747314448,\n",
       " 3.2815229892730717,\n",
       " 2.1443498134613042,\n",
       " 0.23461294174194336,\n",
       " 0.22753286361694336,\n",
       " 0.2308800220489502,\n",
       " 0.23075008392333984,\n",
       " 0.19722390174865725,\n",
       " 0.47787594795227051,\n",
       " 0.36981606483459473,\n",
       " 0.35668396949768066,\n",
       " 0.48750782012939448,\n",
       " 1.6705899238586426,\n",
       " 2.0282943248748784,\n",
       " 0.52131819725036621,\n",
       " 0.24887704849243164,\n",
       " 0.32284784317016602,\n",
       " 1.7474050521850586,\n",
       " 1.7845077514648438,\n",
       " 0.48482298851013178,\n",
       " 0.4194331169128418,\n",
       " 0.49454307556152338,\n",
       " 0.44793319702148438,\n",
       " 0.45632696151733398,\n",
       " 0.25700998306274409,\n",
       " 0.27196884155273438,\n",
       " 0.26067113876342768,\n",
       " 0.47168993949890142,\n",
       " 0.22848892211914065,\n",
       " 0.27444291114807129,\n",
       " 0.47137093544006348,\n",
       " 0.26826810836791992,\n",
       " 0.20549106597900391,\n",
       " 1.1705527305603027,\n",
       " 1.2399299144744873,\n",
       " 0.38704109191894531,\n",
       " 1.8162479400634768,\n",
       " 1.1216819286346436,\n",
       " 1.1158840656280518,\n",
       " 1.5207087993621826,\n",
       " 0.2864229679107666,\n",
       " 0.47764706611633295,\n",
       " 0.26906967163085938,\n",
       " 0.4174041748046875,\n",
       " 0.6002960205078125,\n",
       " 0.51587295532226562,\n",
       " 3.1188719272613525,\n",
       " 3.0850760936737061,\n",
       " 0.40712094306945795,\n",
       " 0.44561982154846191,\n",
       " 0.68750596046447754,\n",
       " 0.66522812843322754,\n",
       " 0.4410707950592041,\n",
       " 0.69387197494506836,\n",
       " 0.46124100685119629,\n",
       " 1.7060050964355469,\n",
       " 1.4248619079589844,\n",
       " 1.3989918231964111,\n",
       " 1.8528070449829104,\n",
       " 1.9140331745147705,\n",
       " 1.3294417858123779,\n",
       " 0.53476190567016602,\n",
       " 2.3719751834869385,\n",
       " 0.66759824752807617,\n",
       " 0.69921994209289551,\n",
       " 3.1470091342926025,\n",
       " 2.5884280204772949,\n",
       " 2.5549530982971191,\n",
       " 0.5570828914642334,\n",
       " 2.4411509037017822,\n",
       " 3.2053167819976807,\n",
       " 3.3228738307952881,\n",
       " 2.6405079364776611,\n",
       " 0.66788887977600098,\n",
       " 0.84270000457763672,\n",
       " 0.57713103294372559,\n",
       " 0.65336704254150391,\n",
       " 1.5208570957183838,\n",
       " 1.719292163848877,\n",
       " 1.7225840091705322,\n",
       " 0.67158603668212891,\n",
       " 0.78501677513122559,\n",
       " 0.68269991874694824,\n",
       " 1.5238080024719238,\n",
       " 1.7129731178283691,\n",
       " 1.4760811328887939,\n",
       " 0.77762198448181152,\n",
       " 2.8890178203582764,\n",
       " 2.9041337966918945,\n",
       " 3.5804691314697266,\n",
       " 3.542417049407959,\n",
       " 0.89545917510986328,\n",
       " 0.8142540454864502,\n",
       " 3.0362012386322017,\n",
       " 1.9708077907562256,\n",
       " 20.883893966674805,\n",
       " 4.0462589263916025,\n",
       " 11.890672206878662,\n",
       " 12.491387844085693,\n",
       " 3.0941720008850098,\n",
       " 66.320782661437988,\n",
       " 5.5457720756530762,\n",
       " 4.4210801124572754,\n",
       " 7.7067019939422634,\n",
       " 3.1674787998199463,\n",
       " 2.2141580581665039,\n",
       " 3.4972848892211914,\n",
       " 19.974884986877441,\n",
       " 4.4114136695861816,\n",
       " 2.0891337394714355,\n",
       " 2.1060848236083984,\n",
       " 31.373883247375488,\n",
       " 64.70428085327147,\n",
       " 3.7188007831573486,\n",
       " 7.5825660228729248,\n",
       " 11.367936849594116,\n",
       " 1.3303070068359375,\n",
       " 5.9322819709777823,\n",
       " 7.2283840179443359,\n",
       " 2.6761660575866699,\n",
       " 5.2220511436462402,\n",
       " 1.3929059505462646,\n",
       " 1.3320519924163818,\n",
       " 6.9202837944030762,\n",
       " 6.3823800086975098,\n",
       " 13.569665908813475,\n",
       " 3.68255615234375,\n",
       " 37.161947965621962,\n",
       " 14.430454015731812,\n",
       " 3.6116900444030762,\n",
       " 20.940958023071289,\n",
       " 4.4317512512207031,\n",
       " 24.189832210540771,\n",
       " 45.217422962188721,\n",
       " 4.0973141193389884,\n",
       " 39.978125095367432,\n",
       " 4.0058028697967529,\n",
       " 8.6308648586273211,\n",
       " 1.92183518409729,\n",
       " 10.227597236633301,\n",
       " 14.07593297958374,\n",
       " 14.078250169754028,\n",
       " 6.4105389118194571,\n",
       " 35.312801837921143,\n",
       " 7.6896450519561776,\n",
       " 6.4752588272094727,\n",
       " 66.974832057952881,\n",
       " 35.43201208114624,\n",
       " 4.5155987739562988,\n",
       " 16.334769248962402,\n",
       " 4.34511399269104,\n",
       " 8.4311900138854963,\n",
       " 3.0032379627227783,\n",
       " 9.1377720832824707,\n",
       " 2.4097962379455566,\n",
       " 15.760344266891479,\n",
       " 10.30829906463623,\n",
       " 7.4313068389892578,\n",
       " 23.309384822845459,\n",
       " 2.9799330234527588,\n",
       " 5.2026851177215585,\n",
       " 4.4347143173217773,\n",
       " 20.829714059829712,\n",
       " 23.183391809463501,\n",
       " 20.078271150588989,\n",
       " 4.1810228824615487,\n",
       " 4.3882067203521737,\n",
       " 4.0243008136749268,\n",
       " 11.493178129196167,\n",
       " 14.9256432056427,\n",
       " 18.002377986907963,\n",
       " 12.536481142044067,\n",
       " 16.000673055648804,\n",
       " 33.54315710067749,\n",
       " 9.4032220840454102,\n",
       " 40.933038949966431,\n",
       " 47.522290945053101,\n",
       " 23.862994909286499,\n",
       " 29.466220855712891,\n",
       " 46.117664813995361,\n",
       " 11.382328987121582,\n",
       " 41.514820098876953,\n",
       " 12.794801950454712,\n",
       " 18.051794052124023,\n",
       " 30.895118713378906,\n",
       " 32.354009866714485,\n",
       " 26.974310874938965,\n",
       " 15.903908014297485,\n",
       " 42.02484917640686,\n",
       " 52.112241983413703,\n",
       " 14.888460159301758,\n",
       " 68.79494309425354,\n",
       " 64.03702712059021,\n",
       " 23.757961988449093,\n",
       " 53.152840137481689,\n",
       " 36.304144144058228,\n",
       " 85.57168292999269,\n",
       " 144.42830181121823,\n",
       " 143.00229811668396,\n",
       " 147.82476687431338,\n",
       " 0.016405820846557617,\n",
       " 0.12305784225463867,\n",
       " 0.1296699047088623,\n",
       " 0.019701004028320312,\n",
       " 0.11308526992797853,\n",
       " 0.1135251522064209,\n",
       " 0.1095278263092041,\n",
       " 0.1134033203125,\n",
       " 0.10995197296142578,\n",
       " 0.11091303825378418,\n",
       " 0.1182410717010498,\n",
       " 0.11235189437866212,\n",
       " 0.11030220985412598,\n",
       " 0.12182307243347168,\n",
       " 0.11824893951416016,\n",
       " 0.12179303169250487,\n",
       " 0.11267614364624025,\n",
       " 0.11875200271606445,\n",
       " 0.11676025390625,\n",
       " 0.11307787895202635,\n",
       " 0.11124920845031737,\n",
       " 0.015898942947387695,\n",
       " 0.11774110794067386,\n",
       " 0.1190187931060791,\n",
       " 0.013457059860229492,\n",
       " 0.1184849739074707,\n",
       " 0.11330008506774902,\n",
       " 0.11286401748657228,\n",
       " 0.1146070957183838,\n",
       " 0.11532807350158693,\n",
       " 0.11619687080383299,\n",
       " 0.021980047225952148,\n",
       " 0.11969828605651855,\n",
       " 0.027289867401123047,\n",
       " 0.12915778160095215,\n",
       " 0.014933109283447266,\n",
       " 0.11987400054931641,\n",
       " 0.11889195442199707,\n",
       " 0.12184596061706544,\n",
       " 0.11883902549743652,\n",
       " 0.1283719539642334,\n",
       " 0.12124300003051758,\n",
       " 0.014118194580078125,\n",
       " 0.13132500648498535,\n",
       " 0.12604713439941406,\n",
       " 0.12651896476745605,\n",
       " 0.12015604972839355,\n",
       " 0.12601280212402344,\n",
       " 0.1270289421081543,\n",
       " 0.12205195426940918,\n",
       " 0.11561822891235353,\n",
       " 0.039784908294677727,\n",
       " 0.12368392944335938,\n",
       " 0.12828612327575686,\n",
       " 0.042276859283447273,\n",
       " 0.1220860481262207,\n",
       " 0.12766575813293454,\n",
       " 0.12013101577758788,\n",
       " 0.1414039134979248,\n",
       " 0.12375593185424805,\n",
       " 0.14295291900634766,\n",
       " 0.1253659725189209,\n",
       " 0.12563610076904294,\n",
       " 0.14510393142700195,\n",
       " 0.1372230052947998,\n",
       " 0.046781063079833984,\n",
       " 0.12776708602905273,\n",
       " 0.12769269943237305,\n",
       " 0.1284182071685791,\n",
       " 0.12873101234436035,\n",
       " 0.14414572715759275,\n",
       " 0.14270615577697754,\n",
       " 0.12721014022827148,\n",
       " 0.13178181648254395,\n",
       " 0.15044903755187988,\n",
       " 0.12660503387451172,\n",
       " 0.15807223320007324,\n",
       " 0.13046479225158691,\n",
       " 0.060959815979003913,\n",
       " 0.15132427215576172,\n",
       " 0.14267873764038086,\n",
       " 0.15218114852905273,\n",
       " 0.15115094184875488,\n",
       " 0.13182997703552246,\n",
       " 0.14809584617614746,\n",
       " 0.1520838737487793,\n",
       " 0.15301799774169922,\n",
       " 0.12738776206970215,\n",
       " 0.13214015960693359,\n",
       " 0.14499187469482422,\n",
       " 0.13004112243652344,\n",
       " 0.14372682571411133,\n",
       " 0.15150094032287598,\n",
       " 0.15107917785644531,\n",
       " 0.09598898887634276,\n",
       " 0.13725018501281738,\n",
       " 0.17290806770324707,\n",
       " 0.13437914848327634,\n",
       " 0.16265320777893064,\n",
       " 0.13185906410217285,\n",
       " 0.16202712059020996,\n",
       " 0.1350700855255127,\n",
       " 0.14565300941467285,\n",
       " 0.1402440071105957,\n",
       " 0.16553115844726562,\n",
       " 0.13800597190856936,\n",
       " 0.15725898742675781,\n",
       " 0.13570380210876465,\n",
       " 0.19074273109436035,\n",
       " 0.1353600025177002,\n",
       " 0.1383059024810791,\n",
       " 0.1370398998260498,\n",
       " 0.1381678581237793,\n",
       " 0.16191577911376953,\n",
       " 0.16687297821044922,\n",
       " 0.14369511604309082,\n",
       " 0.15791797637939453,\n",
       " 0.16403388977050781,\n",
       " 0.13790583610534668,\n",
       " 0.0692138671875,\n",
       " 0.13780879974365234,\n",
       " 0.13872981071472168,\n",
       " 0.039882898330688484,\n",
       " 0.14059877395629886,\n",
       " 0.046679019927978516,\n",
       " 0.18786883354187006,\n",
       " 0.14217972755432129,\n",
       " 0.21379995346069336,\n",
       " 0.16556024551391602,\n",
       " 0.16520285606384275,\n",
       " 0.20644688606262207,\n",
       " 0.21710896492004395,\n",
       " 0.22460007667541504,\n",
       " 0.16830587387084961,\n",
       " 0.16867423057556152,\n",
       " 0.16795492172241211,\n",
       " 0.1840822696685791,\n",
       " 0.21533083915710449,\n",
       " 0.16388988494873047,\n",
       " 0.17275595664978027,\n",
       " 0.14825701713562012,\n",
       " 0.16573810577392578,\n",
       " 0.092794179916381836,\n",
       " 0.13294792175292969,\n",
       " 0.19093608856201166,\n",
       " 0.18797898292541504,\n",
       " 0.086082696914672852,\n",
       " 0.16816115379333496,\n",
       " 0.16468501091003418,\n",
       " 0.22114300727844241,\n",
       " 0.22818088531494141,\n",
       " 0.23114228248596189,\n",
       " 0.23377418518066409,\n",
       " 0.16866827011108398,\n",
       " 0.41458415985107422,\n",
       " 0.17335009574890134,\n",
       " 0.22197794914245605,\n",
       " 0.22772789001464844,\n",
       " 0.22666692733764651,\n",
       " 0.4201359748840332,\n",
       " 0.25566506385803223,\n",
       " 0.31502175331115723,\n",
       " 0.3380589485168457,\n",
       " 0.34802412986755371,\n",
       " 0.31645917892456049,\n",
       " 0.33871102333068848,\n",
       " 0.26237392425537109,\n",
       " 0.31766104698181152,\n",
       " 0.24733281135559079,\n",
       " 0.17199611663818359,\n",
       " 0.34494304656982422,\n",
       " 0.34971070289611816,\n",
       " 0.32752180099487305,\n",
       " 0.23166179656982425,\n",
       " 0.33340191841125488,\n",
       " 0.31787276268005371,\n",
       " 0.46166491508483892,\n",
       " 0.11690592765808105,\n",
       " 0.11490607261657715,\n",
       " 0.12277507781982422,\n",
       " 0.11029696464538574,\n",
       " 0.1138780117034912,\n",
       " 0.11335206031799315,\n",
       " 0.11304187774658205,\n",
       " 0.11278724670410155,\n",
       " 0.1178278923034668,\n",
       " 0.10953021049499513,\n",
       " 0.11512875556945799,\n",
       " 0.11361312866210938,\n",
       " 0.11788582801818848,\n",
       " 0.11410284042358396,\n",
       " 0.11214590072631836,\n",
       " 0.018095254898071289,\n",
       " 0.016508102416992188,\n",
       " 0.11728310585021973,\n",
       " 0.12112116813659668,\n",
       " 0.11524295806884766,\n",
       " 0.011816263198852541,\n",
       " 0.10976696014404297,\n",
       " 0.11388683319091795,\n",
       " 0.11475896835327147,\n",
       " 0.11586689949035645,\n",
       " 0.019505977630615241,\n",
       " 0.11148500442504884,\n",
       " 0.0095689296722412127,\n",
       " 0.11214709281921388,\n",
       " 0.12102580070495605,\n",
       " 0.11020064353942872,\n",
       " ...]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/train.py\u001b[0m(232)\u001b[0;36m_transform_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    231 \u001b[0;31m        \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 232 \u001b[0;31m        \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    233 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> inputs\n",
      "       total_memory  available_memory  num_cpu  num_rows  num_features  \\\n",
      "0       17179869184        7036096512        8   5000000            50   \n",
      "1       17179869184        6761955328        8   5000000            50   \n",
      "2       17179869184        6267830272        8   5000000            50   \n",
      "3       17179869184        5694320640        8   5000000            50   \n",
      "4       17179869184        5679689728        8   5000000            50   \n",
      "5       17179869184        5683245056        8   5000000            50   \n",
      "6       17179869184        4346757120        8   5000000            50   \n",
      "7       17179869184        4284518400        8   5000000            50   \n",
      "8       17179869184        4335284224        8   5000000            50   \n",
      "9       17179869184        4384038912        8   5000000            50   \n",
      "10      17179869184        4358402048        8   5000000            50   \n",
      "11      17179869184        3759247360        8   5000000            50   \n",
      "12      17179869184        3329490944        8   5000000            50   \n",
      "13      17179869184        7016251392        8   5000000            50   \n",
      "14      17179869184        6637260800        8   5000000            50   \n",
      "15      17179869184        5078642688        8   5000000            50   \n",
      "16      17179869184        4386443264        8   5000000            50   \n",
      "17      17179869184        4390096896        8   5000000            50   \n",
      "18      17179869184        3443556352        8   5000000            50   \n",
      "19      17179869184        6981324800        8   5000000            50   \n",
      "20      17179869184        5074989056        8   5000000            50   \n",
      "21      17179869184        6246006784        8   5000000            50   \n",
      "22      17179869184        4871557120        8   5000000            50   \n",
      "23      17179869184        6153269248        8   5000000            50   \n",
      "24      17179869184        3435200512        8   5000000            25   \n",
      "25      17179869184        3112235008        8   5000000            25   \n",
      "26      17179869184        7535542272        8   5000000            25   \n",
      "27      17179869184        7481905152        8   5000000            25   \n",
      "28      17179869184        7407673344        8   5000000            25   \n",
      "29      17179869184        6718763008        8   5000000            25   \n",
      "...             ...               ...      ...       ...           ...   \n",
      "15947    8589934592        2218577920        4  10000000            15   \n",
      "15948    8589934592        2416312320        4  10000000            15   \n",
      "15949    8589934592        1926840320        4  10000000            15   \n",
      "15950    8589934592        1893961728        4  10000000            15   \n",
      "15951    8589934592        3211255808        4  10000000            15   \n",
      "15952    8589934592        2104168448        4  10000000            15   \n",
      "15953    8589934592        1736871936        4  10000000            15   \n",
      "15954    8589934592        2897174528        4  10000000            15   \n",
      "15955    8589934592        2475376640        4  10000000            15   \n",
      "15956    8589934592        2604957696        4  10000000            15   \n",
      "15957    8589934592         495296512        4  10000000            15   \n",
      "15958    8589934592        1600913408        4  10000000            15   \n",
      "15959    8589934592        1744605184        4  10000000            15   \n",
      "15960    8589934592        2573602816        4  10000000            15   \n",
      "15961    8589934592        2500558848        4  10000000            15   \n",
      "15962    8589934592        2583158784        4  10000000            15   \n",
      "15963    8589934592         916041728        4  10000000            15   \n",
      "15964    8589934592        1877397504        4  10000000            15   \n",
      "15965    8589934592        2438651904        4  10000000            15   \n",
      "15966    8589934592        2216837120        4  10000000            15   \n",
      "15967    8589934592        2439237632        4  10000000            15   \n",
      "15968    8589934592        2465222656        4  10000000            15   \n",
      "15969    8589934592        1750499328        4  10000000            15   \n",
      "15970    8589934592        1799426048        4  10000000            15   \n",
      "15971    8589934592        1732190208        4  10000000            15   \n",
      "15972    8589934592        2120351744        4  10000000            15   \n",
      "15973    8589934592        2470027264        4  10000000            15   \n",
      "15974    8589934592        2093924352        4  10000000            15   \n",
      "15975    8589934592        2059784192        4  10000000            15   \n",
      "15976    8589934592        3228401664        4  10000000            15   \n",
      "\n",
      "       n_estimators  max_depth  min_samples_split  min_samples_leaf  \\\n",
      "0                10       10.0                  2               1.0   \n",
      "1                10       10.0                  2               1.0   \n",
      "2                10       10.0                  2               5.0   \n",
      "3                10       10.0                  2              10.0   \n",
      "4                10       50.0                  4               1.0   \n",
      "5                10       50.0                 10              10.0   \n",
      "6                10      100.0                  2               1.0   \n",
      "7                10      100.0                  4               5.0   \n",
      "8                50       10.0                  2               5.0   \n",
      "9                50       10.0                 10               5.0   \n",
      "10               50       50.0                  4              10.0   \n",
      "11               50       50.0                 10               1.0   \n",
      "12               50      100.0                  2               5.0   \n",
      "13               50      100.0                  4               1.0   \n",
      "14               50      100.0                 10               5.0   \n",
      "15              100       10.0                  2               1.0   \n",
      "16              100       10.0                  4               1.0   \n",
      "17              100       10.0                 10               5.0   \n",
      "18              100       50.0                  4              10.0   \n",
      "19              100       50.0                 10               1.0   \n",
      "20              100       50.0                 10               5.0   \n",
      "21              100       50.0                 10               5.0   \n",
      "22              100      100.0                  2               1.0   \n",
      "23              100      100.0                  4              10.0   \n",
      "24               10       50.0                  4               5.0   \n",
      "25               10      100.0                 10               1.0   \n",
      "26               50       10.0                 10               1.0   \n",
      "27               50       10.0                 10               5.0   \n",
      "28               50       50.0                  4               1.0   \n",
      "29               50       50.0                  4               5.0   \n",
      "...             ...        ...                ...               ...   \n",
      "15947            10       10.0                  4               5.0   \n",
      "15948            10       10.0                  4               5.0   \n",
      "15949            10       10.0                  4               5.0   \n",
      "15950            10       10.0                  4               5.0   \n",
      "15951            10       10.0                  4               5.0   \n",
      "15952            10       10.0                  4               5.0   \n",
      "15953            10       10.0                  4               5.0   \n",
      "15954            10       10.0                  4               5.0   \n",
      "15955            10       10.0                  4               5.0   \n",
      "15956            10       10.0                  4               5.0   \n",
      "15957            10       10.0                  4              10.0   \n",
      "15958            10       10.0                  4              10.0   \n",
      "15959            10       10.0                  4              10.0   \n",
      "15960            10       10.0                  4              10.0   \n",
      "15961            10       10.0                  4              10.0   \n",
      "15962            10       10.0                  4              10.0   \n",
      "15963            10       10.0                  4              10.0   \n",
      "15964            10       10.0                  4              10.0   \n",
      "15965            10       10.0                  4              10.0   \n",
      "15966            10       10.0                  4              10.0   \n",
      "15967            10       10.0                  4              10.0   \n",
      "15968            10       10.0                  4              10.0   \n",
      "15969            10       10.0                 10               1.0   \n",
      "15970            10       10.0                 10               1.0   \n",
      "15971            10       10.0                 10               1.0   \n",
      "15972            10       10.0                 10               1.0   \n",
      "15973            10       10.0                 10               1.0   \n",
      "15974            10       10.0                 10               1.0   \n",
      "15975            10       10.0                 10               1.0   \n",
      "15976            10       10.0                 10               1.0   \n",
      "\n",
      "       min_weight_fraction_leaf max_features  max_leaf_nodes  \\\n",
      "0                          0.10         None             2.0   \n",
      "1                          0.10         None             4.0   \n",
      "2                          0.25           10             2.0   \n",
      "3                          0.10           50             4.0   \n",
      "4                          0.10           50            10.0   \n",
      "5                          0.25           50            10.0   \n",
      "6                          0.50           10             2.0   \n",
      "7                          0.50         None            10.0   \n",
      "8                          0.25           50             2.0   \n",
      "9                          0.10           50             4.0   \n",
      "10                         0.50           20             2.0   \n",
      "11                         0.25         None             2.0   \n",
      "12                         0.10           10             2.0   \n",
      "13                         0.50           50             4.0   \n",
      "14                         0.25           10             2.0   \n",
      "15                         0.25           10             2.0   \n",
      "16                         0.25         None            10.0   \n",
      "17                         0.50           50             2.0   \n",
      "18                         0.25         None             4.0   \n",
      "19                         0.10           50             4.0   \n",
      "20                         0.10           50             4.0   \n",
      "21                         0.25         None             4.0   \n",
      "22                         0.10           50             4.0   \n",
      "23                         0.25         None            10.0   \n",
      "24                         0.25         None             2.0   \n",
      "25                         0.25           20             2.0   \n",
      "26                         0.25           10             2.0   \n",
      "27                         0.10           10             4.0   \n",
      "28                         0.10           10            10.0   \n",
      "29                         0.50           10             4.0   \n",
      "...                         ...          ...             ...   \n",
      "15947                      0.50         None            10.0   \n",
      "15948                      0.50         None            10.0   \n",
      "15949                      0.50           10             2.0   \n",
      "15950                      0.50           10             2.0   \n",
      "15951                      0.50           10             2.0   \n",
      "15952                      0.50           10             2.0   \n",
      "15953                      0.50           10             2.0   \n",
      "15954                      0.50           10            10.0   \n",
      "15955                      0.50           10            10.0   \n",
      "15956                      0.50           10            10.0   \n",
      "15957                      0.10         None             2.0   \n",
      "15958                      0.10         None            10.0   \n",
      "15959                      0.10         None            10.0   \n",
      "15960                      0.10           10             2.0   \n",
      "15961                      0.10           10             2.0   \n",
      "15962                      0.10           10            10.0   \n",
      "15963                      0.50         None             2.0   \n",
      "15964                      0.50         None            10.0   \n",
      "15965                      0.50           10             2.0   \n",
      "15966                      0.50           10             2.0   \n",
      "15967                      0.50           10             2.0   \n",
      "15968                      0.50           10            10.0   \n",
      "15969                      0.10         None             2.0   \n",
      "15970                      0.10         None             2.0   \n",
      "15971                      0.10         None            10.0   \n",
      "15972                      0.10         None            10.0   \n",
      "15973                      0.10           10            10.0   \n",
      "15974                      0.10           10            10.0   \n",
      "15975                      0.10           10            10.0   \n",
      "15976                      0.10           10            10.0   \n",
      "\n",
      "       min_impurity_decrease  min_impurity_split  bootstrap  oob_score  \\\n",
      "0                          1                 1.0       True      False   \n",
      "1                          5                 5.0      False      False   \n",
      "2                          1                 1.0       True      False   \n",
      "3                         10                 5.0       True      False   \n",
      "4                          1                 1.0      False      False   \n",
      "5                          1                 5.0       True      False   \n",
      "6                          1                 1.0      False      False   \n",
      "7                          5                10.0      False      False   \n",
      "8                          5                10.0       True      False   \n",
      "9                          1                 1.0       True      False   \n",
      "10                        10                 1.0       True      False   \n",
      "11                        10                 5.0       True      False   \n",
      "12                         1                 5.0       True      False   \n",
      "13                         5                10.0      False      False   \n",
      "14                        10                 5.0      False      False   \n",
      "15                         5                 5.0       True      False   \n",
      "16                         5                 1.0      False      False   \n",
      "17                         5                10.0      False      False   \n",
      "18                         1                 5.0      False      False   \n",
      "19                        10                 5.0       True      False   \n",
      "20                         5                 5.0       True      False   \n",
      "21                         1                 5.0      False      False   \n",
      "22                        10                 1.0      False      False   \n",
      "23                         5                 1.0      False      False   \n",
      "24                         5                10.0       True      False   \n",
      "25                        10                 5.0      False      False   \n",
      "26                         5                 5.0      False      False   \n",
      "27                        10                 1.0      False      False   \n",
      "28                        10                10.0       True      False   \n",
      "29                         5                10.0      False      False   \n",
      "...                      ...                 ...        ...        ...   \n",
      "15947                      1                10.0      False      False   \n",
      "15948                     10                 1.0       True      False   \n",
      "15949                      1                 1.0       True      False   \n",
      "15950                      1                 1.0      False      False   \n",
      "15951                      1                10.0       True      False   \n",
      "15952                      1                10.0      False      False   \n",
      "15953                     10                 1.0      False      False   \n",
      "15954                      1                 1.0      False      False   \n",
      "15955                     10                 1.0       True      False   \n",
      "15956                     10                10.0      False      False   \n",
      "15957                      1                 1.0      False      False   \n",
      "15958                     10                 1.0       True      False   \n",
      "15959                     10                 1.0       True      False   \n",
      "15960                      1                 1.0       True      False   \n",
      "15961                     10                 1.0      False      False   \n",
      "15962                     10                 1.0      False      False   \n",
      "15963                     10                 1.0      False      False   \n",
      "15964                      1                10.0      False      False   \n",
      "15965                      1                 1.0       True      False   \n",
      "15966                      1                10.0      False      False   \n",
      "15967                     10                10.0      False      False   \n",
      "15968                      1                 1.0       True      False   \n",
      "15969                      1                 1.0      False      False   \n",
      "15970                      1                10.0      False      False   \n",
      "15971                      1                 1.0       True      False   \n",
      "15972                     10                 1.0       True      False   \n",
      "15973                      1                 1.0       True      False   \n",
      "15974                     10                10.0       True      False   \n",
      "15975                     10                10.0       True      False   \n",
      "15976                     10                10.0      False      False   \n",
      "\n",
      "       n_jobs  max_depth_None  max_features_auto  \n",
      "0         2.0           False               True  \n",
      "1         2.0           False               True  \n",
      "2         5.0           False              False  \n",
      "3         2.0           False              False  \n",
      "4         2.0           False              False  \n",
      "5         2.0           False              False  \n",
      "6         1.0           False              False  \n",
      "7         5.0           False               True  \n",
      "8         2.0           False              False  \n",
      "9         2.0           False              False  \n",
      "10        1.0           False              False  \n",
      "11        8.0           False               True  \n",
      "12        1.0           False              False  \n",
      "13        8.0           False              False  \n",
      "14        5.0           False              False  \n",
      "15        2.0           False              False  \n",
      "16        2.0           False               True  \n",
      "17        5.0           False              False  \n",
      "18        2.0           False               True  \n",
      "19        2.0           False              False  \n",
      "20        8.0           False              False  \n",
      "21        1.0           False               True  \n",
      "22        2.0           False              False  \n",
      "23        8.0           False               True  \n",
      "24        2.0           False               True  \n",
      "25        8.0           False              False  \n",
      "26        1.0           False              False  \n",
      "27        2.0           False              False  \n",
      "28        2.0           False              False  \n",
      "29        5.0           False              False  \n",
      "...       ...             ...                ...  \n",
      "15947     8.0           False               True  \n",
      "15948     2.0           False               True  \n",
      "15949     1.0           False              False  \n",
      "15950     2.0           False              False  \n",
      "15951     1.0           False              False  \n",
      "15952     8.0           False              False  \n",
      "15953     2.0           False              False  \n",
      "15954     8.0           False              False  \n",
      "15955     1.0           False              False  \n",
      "15956     8.0           False              False  \n",
      "15957     8.0           False               True  \n",
      "15958     2.0           False               True  \n",
      "15959     8.0           False               True  \n",
      "15960     1.0           False              False  \n",
      "15961     2.0           False              False  \n",
      "15962     1.0           False              False  \n",
      "15963     1.0           False               True  \n",
      "15964     8.0           False               True  \n",
      "15965     8.0           False              False  \n",
      "15966     1.0           False              False  \n",
      "15967     2.0           False              False  \n",
      "15968     1.0           False              False  \n",
      "15969     1.0           False               True  \n",
      "15970     1.0           False               True  \n",
      "15971     1.0           False               True  \n",
      "15972     1.0           False               True  \n",
      "15973     1.0           False              False  \n",
      "15974     1.0           False              False  \n",
      "15975     2.0           False              False  \n",
      "15976     8.0           False              False  \n",
      "\n",
      "[15977 rows x 19 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> inputs[inputs.max_features.isnull()]\n",
      "       total_memory  available_memory  num_cpu  num_rows  num_features  \\\n",
      "0       17179869184        7036096512        8   5000000            50   \n",
      "1       17179869184        6761955328        8   5000000            50   \n",
      "7       17179869184        4284518400        8   5000000            50   \n",
      "11      17179869184        3759247360        8   5000000            50   \n",
      "16      17179869184        4386443264        8   5000000            50   \n",
      "18      17179869184        3443556352        8   5000000            50   \n",
      "21      17179869184        6246006784        8   5000000            50   \n",
      "23      17179869184        6153269248        8   5000000            50   \n",
      "24      17179869184        3435200512        8   5000000            25   \n",
      "33      17179869184        6321741824        8   5000000            25   \n",
      "35      17179869184        5751881728        8   5000000            25   \n",
      "48      17179869184        3245744128        8   3000000            50   \n",
      "50      17179869184        3285618688        8   3000000            50   \n",
      "56      17179869184        4145975296        8   3000000            50   \n",
      "60      17179869184        4370792448        8   3000000            50   \n",
      "61      17179869184        4300423168        8   3000000            25   \n",
      "62      17179869184        4588101632        8   3000000            25   \n",
      "66      17179869184        4439281664        8   3000000            25   \n",
      "69      17179869184        3955752960        8   3000000            25   \n",
      "71      17179869184        2466942976        8   3000000            25   \n",
      "72      17179869184        2751901696        8   3000000            25   \n",
      "73      17179869184        2369163264        8   3000000            25   \n",
      "74      17179869184        2415116288        8   3000000            25   \n",
      "76      17179869184        1643536384        8   3000000            25   \n",
      "78      17179869184        1297113088        8   3000000            25   \n",
      "89      17179869184        6996914176        8   1000000            50   \n",
      "92      17179869184        7180689408        8   1000000            50   \n",
      "100     17179869184        6650564608        8   1000000            25   \n",
      "102     17179869184        6650638336        8   1000000            25   \n",
      "103     17179869184        6990123008        8   1000000            25   \n",
      "...             ...               ...      ...       ...           ...   \n",
      "15914    8589934592        2440957952        4  10000000            15   \n",
      "15915    8589934592        2256908288        4  10000000            15   \n",
      "15916    8589934592        2448203776        4  10000000            15   \n",
      "15917    8589934592        2382315520        4  10000000            15   \n",
      "15920    8589934592        1655316480        4  10000000            15   \n",
      "15921    8589934592        1980194816        4  10000000            15   \n",
      "15926    8589934592         499527680        4  10000000            15   \n",
      "15927    8589934592        1658597376        4  10000000            15   \n",
      "15928    8589934592        1720770560        4  10000000            15   \n",
      "15932    8589934592         507035648        4  10000000            15   \n",
      "15933    8589934592        2201657344        4  10000000            15   \n",
      "15934    8589934592        2535825408        4  10000000            15   \n",
      "15935    8589934592        2424799232        4  10000000            15   \n",
      "15936    8589934592        2566856704        4  10000000            15   \n",
      "15937    8589934592        2456645632        4  10000000            15   \n",
      "15943    8589934592         511655936        4  10000000            15   \n",
      "15944    8589934592        1951092736        4  10000000            15   \n",
      "15945    8589934592        2165342208        4  10000000            15   \n",
      "15946    8589934592        2334167040        4  10000000            15   \n",
      "15947    8589934592        2218577920        4  10000000            15   \n",
      "15948    8589934592        2416312320        4  10000000            15   \n",
      "15957    8589934592         495296512        4  10000000            15   \n",
      "15958    8589934592        1600913408        4  10000000            15   \n",
      "15959    8589934592        1744605184        4  10000000            15   \n",
      "15963    8589934592         916041728        4  10000000            15   \n",
      "15964    8589934592        1877397504        4  10000000            15   \n",
      "15969    8589934592        1750499328        4  10000000            15   \n",
      "15970    8589934592        1799426048        4  10000000            15   \n",
      "15971    8589934592        1732190208        4  10000000            15   \n",
      "15972    8589934592        2120351744        4  10000000            15   \n",
      "\n",
      "       n_estimators  max_depth  min_samples_split  min_samples_leaf  \\\n",
      "0                10       10.0                  2               1.0   \n",
      "1                10       10.0                  2               1.0   \n",
      "7                10      100.0                  4               5.0   \n",
      "11               50       50.0                 10               1.0   \n",
      "16              100       10.0                  4               1.0   \n",
      "18              100       50.0                  4              10.0   \n",
      "21              100       50.0                 10               5.0   \n",
      "23              100      100.0                  4              10.0   \n",
      "24               10       50.0                  4               5.0   \n",
      "33              100       10.0                  4               1.0   \n",
      "35              100       50.0                  4              10.0   \n",
      "48               10      100.0                 10              10.0   \n",
      "50               50       10.0                 10               1.0   \n",
      "56              100       50.0                  2              10.0   \n",
      "60              100      100.0                 10               5.0   \n",
      "61               10       10.0                  4               1.0   \n",
      "62               10       10.0                  4              10.0   \n",
      "66               10       50.0                 10              10.0   \n",
      "69               50       50.0                 10               1.0   \n",
      "71               50      100.0                  4              10.0   \n",
      "72              100       50.0                  2               5.0   \n",
      "73              100       50.0                  2              10.0   \n",
      "74              100       50.0                  2              10.0   \n",
      "76              100       50.0                 10               5.0   \n",
      "78              100      100.0                 10               5.0   \n",
      "89               50       50.0                 10               5.0   \n",
      "92              100       10.0                 10               5.0   \n",
      "100              10       50.0                  4               5.0   \n",
      "102              10       50.0                 10               5.0   \n",
      "103              10      100.0                  4               1.0   \n",
      "...             ...        ...                ...               ...   \n",
      "15914            10       10.0                  2              10.0   \n",
      "15915            10       10.0                  2              10.0   \n",
      "15916            10       10.0                  2              10.0   \n",
      "15917            10       10.0                  2              10.0   \n",
      "15920            10       10.0                  4               1.0   \n",
      "15921            10       10.0                  4               1.0   \n",
      "15926            10       10.0                  4               1.0   \n",
      "15927            10       10.0                  4               1.0   \n",
      "15928            10       10.0                  4               1.0   \n",
      "15932            10       10.0                  4               5.0   \n",
      "15933            10       10.0                  4               5.0   \n",
      "15934            10       10.0                  4               5.0   \n",
      "15935            10       10.0                  4               5.0   \n",
      "15936            10       10.0                  4               5.0   \n",
      "15937            10       10.0                  4               5.0   \n",
      "15943            10       10.0                  4               5.0   \n",
      "15944            10       10.0                  4               5.0   \n",
      "15945            10       10.0                  4               5.0   \n",
      "15946            10       10.0                  4               5.0   \n",
      "15947            10       10.0                  4               5.0   \n",
      "15948            10       10.0                  4               5.0   \n",
      "15957            10       10.0                  4              10.0   \n",
      "15958            10       10.0                  4              10.0   \n",
      "15959            10       10.0                  4              10.0   \n",
      "15963            10       10.0                  4              10.0   \n",
      "15964            10       10.0                  4              10.0   \n",
      "15969            10       10.0                 10               1.0   \n",
      "15970            10       10.0                 10               1.0   \n",
      "15971            10       10.0                 10               1.0   \n",
      "15972            10       10.0                 10               1.0   \n",
      "\n",
      "       min_weight_fraction_leaf max_features  max_leaf_nodes  \\\n",
      "0                          0.10         None             2.0   \n",
      "1                          0.10         None             4.0   \n",
      "7                          0.50         None            10.0   \n",
      "11                         0.25         None             2.0   \n",
      "16                         0.25         None            10.0   \n",
      "18                         0.25         None             4.0   \n",
      "21                         0.25         None             4.0   \n",
      "23                         0.25         None            10.0   \n",
      "24                         0.25         None             2.0   \n",
      "33                         0.25         None            10.0   \n",
      "35                         0.10         None            10.0   \n",
      "48                         0.10         None             2.0   \n",
      "50                         0.25         None             2.0   \n",
      "56                         0.25         None             4.0   \n",
      "60                         0.25         None             4.0   \n",
      "61                         0.50         None             2.0   \n",
      "62                         0.25         None             4.0   \n",
      "66                         0.25         None            10.0   \n",
      "69                         0.50         None             4.0   \n",
      "71                         0.25         None            10.0   \n",
      "72                         0.50         None            10.0   \n",
      "73                         0.25         None             2.0   \n",
      "74                         0.50         None            10.0   \n",
      "76                         0.25         None             2.0   \n",
      "78                         0.25         None            10.0   \n",
      "89                         0.25         None             4.0   \n",
      "92                         0.50         None             4.0   \n",
      "100                        0.10         None             2.0   \n",
      "102                        0.10         None             2.0   \n",
      "103                        0.25         None             4.0   \n",
      "...                         ...          ...             ...   \n",
      "15914                      0.50         None            10.0   \n",
      "15915                      0.50         None            10.0   \n",
      "15916                      0.50         None            10.0   \n",
      "15917                      0.50         None            10.0   \n",
      "15920                      0.10         None             2.0   \n",
      "15921                      0.10         None            10.0   \n",
      "15926                      0.50         None             2.0   \n",
      "15927                      0.50         None             2.0   \n",
      "15928                      0.50         None            10.0   \n",
      "15932                      0.10         None             2.0   \n",
      "15933                      0.10         None             2.0   \n",
      "15934                      0.10         None            10.0   \n",
      "15935                      0.10         None            10.0   \n",
      "15936                      0.10         None            10.0   \n",
      "15937                      0.10         None            10.0   \n",
      "15943                      0.50         None             2.0   \n",
      "15944                      0.50         None             2.0   \n",
      "15945                      0.50         None            10.0   \n",
      "15946                      0.50         None            10.0   \n",
      "15947                      0.50         None            10.0   \n",
      "15948                      0.50         None            10.0   \n",
      "15957                      0.10         None             2.0   \n",
      "15958                      0.10         None            10.0   \n",
      "15959                      0.10         None            10.0   \n",
      "15963                      0.50         None             2.0   \n",
      "15964                      0.50         None            10.0   \n",
      "15969                      0.10         None             2.0   \n",
      "15970                      0.10         None             2.0   \n",
      "15971                      0.10         None            10.0   \n",
      "15972                      0.10         None            10.0   \n",
      "\n",
      "       min_impurity_decrease  min_impurity_split  bootstrap  oob_score  \\\n",
      "0                          1                 1.0       True      False   \n",
      "1                          5                 5.0      False      False   \n",
      "7                          5                10.0      False      False   \n",
      "11                        10                 5.0       True      False   \n",
      "16                         5                 1.0      False      False   \n",
      "18                         1                 5.0      False      False   \n",
      "21                         1                 5.0      False      False   \n",
      "23                         5                 1.0      False      False   \n",
      "24                         5                10.0       True      False   \n",
      "33                        10                 1.0       True      False   \n",
      "35                         5                 1.0      False      False   \n",
      "48                         1                 5.0      False      False   \n",
      "50                        10                 1.0      False      False   \n",
      "56                         1                 5.0       True      False   \n",
      "60                         1                10.0      False      False   \n",
      "61                         5                 1.0       True      False   \n",
      "62                         5                10.0      False      False   \n",
      "66                         1                10.0      False      False   \n",
      "69                         1                 5.0      False      False   \n",
      "71                        10                10.0      False      False   \n",
      "72                        10                10.0       True      False   \n",
      "73                        10                10.0      False      False   \n",
      "74                         5                 1.0       True      False   \n",
      "76                         5                10.0       True      False   \n",
      "78                        10                 5.0      False      False   \n",
      "89                         5                 1.0      False      False   \n",
      "92                        10                10.0       True      False   \n",
      "100                        1                 5.0       True      False   \n",
      "102                        1                 1.0       True      False   \n",
      "103                        1                 5.0       True      False   \n",
      "...                      ...                 ...        ...        ...   \n",
      "15914                      1                10.0       True      False   \n",
      "15915                      1                10.0      False      False   \n",
      "15916                     10                 1.0      False      False   \n",
      "15917                     10                10.0      False      False   \n",
      "15920                      1                10.0       True      False   \n",
      "15921                      1                10.0      False      False   \n",
      "15926                     10                 1.0      False      False   \n",
      "15927                     10                 1.0      False      False   \n",
      "15928                      1                 1.0       True      False   \n",
      "15932                      1                 1.0      False      False   \n",
      "15933                     10                 1.0      False      False   \n",
      "15934                     10                 1.0       True      False   \n",
      "15935                     10                 1.0       True      False   \n",
      "15936                     10                 1.0      False      False   \n",
      "15937                     10                10.0       True      False   \n",
      "15943                      1                10.0       True      False   \n",
      "15944                     10                 1.0       True      False   \n",
      "15945                      1                 1.0      False      False   \n",
      "15946                      1                10.0      False      False   \n",
      "15947                      1                10.0      False      False   \n",
      "15948                     10                 1.0       True      False   \n",
      "15957                      1                 1.0      False      False   \n",
      "15958                     10                 1.0       True      False   \n",
      "15959                     10                 1.0       True      False   \n",
      "15963                     10                 1.0      False      False   \n",
      "15964                      1                10.0      False      False   \n",
      "15969                      1                 1.0      False      False   \n",
      "15970                      1                10.0      False      False   \n",
      "15971                      1                 1.0       True      False   \n",
      "15972                     10                 1.0       True      False   \n",
      "\n",
      "       n_jobs  max_depth_None  max_features_auto  \n",
      "0         2.0           False               True  \n",
      "1         2.0           False               True  \n",
      "7         5.0           False               True  \n",
      "11        8.0           False               True  \n",
      "16        2.0           False               True  \n",
      "18        2.0           False               True  \n",
      "21        1.0           False               True  \n",
      "23        8.0           False               True  \n",
      "24        2.0           False               True  \n",
      "33        5.0           False               True  \n",
      "35        8.0           False               True  \n",
      "48        2.0           False               True  \n",
      "50        1.0           False               True  \n",
      "56        8.0           False               True  \n",
      "60        2.0           False               True  \n",
      "61        1.0           False               True  \n",
      "62        5.0           False               True  \n",
      "66        8.0           False               True  \n",
      "69        2.0           False               True  \n",
      "71        1.0           False               True  \n",
      "72        8.0           False               True  \n",
      "73        5.0           False               True  \n",
      "74        2.0           False               True  \n",
      "76        2.0           False               True  \n",
      "78        2.0           False               True  \n",
      "89        5.0           False               True  \n",
      "92        8.0           False               True  \n",
      "100       1.0           False               True  \n",
      "102       5.0           False               True  \n",
      "103       1.0           False               True  \n",
      "...       ...             ...                ...  \n",
      "15914     2.0           False               True  \n",
      "15915     1.0           False               True  \n",
      "15916     2.0           False               True  \n",
      "15917     2.0           False               True  \n",
      "15920     2.0           False               True  \n",
      "15921     1.0           False               True  \n",
      "15926     1.0           False               True  \n",
      "15927     2.0           False               True  \n",
      "15928     8.0           False               True  \n",
      "15932     8.0           False               True  \n",
      "15933     2.0           False               True  \n",
      "15934     2.0           False               True  \n",
      "15935     8.0           False               True  \n",
      "15936     2.0           False               True  \n",
      "15937     8.0           False               True  \n",
      "15943     1.0           False               True  \n",
      "15944     8.0           False               True  \n",
      "15945     1.0           False               True  \n",
      "15946     1.0           False               True  \n",
      "15947     8.0           False               True  \n",
      "15948     2.0           False               True  \n",
      "15957     8.0           False               True  \n",
      "15958     2.0           False               True  \n",
      "15959     8.0           False               True  \n",
      "15963     1.0           False               True  \n",
      "15964     8.0           False               True  \n",
      "15969     1.0           False               True  \n",
      "15970     1.0           False               True  \n",
      "15971     1.0           False               True  \n",
      "15972     1.0           False               True  \n",
      "\n",
      "[3727 rows x 19 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1fbd662d0deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_trf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36m_transform_data\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36m_transform_data\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_trf = t._transform_data(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[17179869184, 7036096512, 8, ..., 0, 0, 1],\n",
       "        [17179869184, 6761955328, 8, ..., 0, 0, 1],\n",
       "        [17179869184, 6267830272, 8, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [8589934592, 2093924352, 4, ..., 0, 0, 0],\n",
       "        [8589934592, 2059784192, 4, ..., 0, 0, 0],\n",
       "        [8589934592, 3228401664, 4, ..., 0, 0, 0]], dtype=object),\n",
       " array([ 2.63969684,  0.99065208,  1.976542  , ...,  6.84104204,\n",
       "         4.51330805,  1.01906776]),\n",
       " Index(['total_memory', 'available_memory', 'num_cpu', 'num_rows',\n",
       "        'num_features', 'n_estimators', 'max_depth', 'min_samples_split',\n",
       "        'min_samples_leaf', 'min_weight_fraction_leaf', 'max_leaf_nodes',\n",
       "        'min_impurity_decrease', 'min_impurity_split', 'bootstrap', 'oob_score',\n",
       "        'n_jobs', 'max_depth_None', 'max_features_auto', 'max_features_1',\n",
       "        'max_features_10', 'max_features_100', 'max_features_2',\n",
       "        'max_features_20', 'max_features_200', 'max_features_3',\n",
       "        'max_features_30', 'max_features_4', 'max_features_40',\n",
       "        'max_features_5', 'max_features_50', 'max_features_auto'],\n",
       "       dtype='object'),\n",
       " Index(['total_memory', 'available_memory', 'num_cpu', 'num_rows',\n",
       "        'num_features', 'n_estimators', 'max_depth', 'min_samples_split',\n",
       "        'min_samples_leaf', 'min_weight_fraction_leaf', 'max_features',\n",
       "        'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split',\n",
       "        'bootstrap', 'oob_score', 'n_jobs', 'max_depth_None',\n",
       "        'max_features_auto'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>total_memory</th>\n",
       "      <th>available_memory</th>\n",
       "      <th>num_cpu</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>num_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_weight_fraction_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_impurity_split</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>oob_score</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, total_memory, available_memory, num_cpu, num_rows, num_features, n_estimators, max_depth, min_samples_split, min_samples_leaf, min_weight_fraction_leaf, max_features, max_leaf_nodes, min_impurity_decrease, min_impurity_split, bootstrap, oob_score, n_jobs, output]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1[df_1.max_features.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>total_memory</th>\n",
       "      <th>available_memory</th>\n",
       "      <th>num_cpu</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>num_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>...</th>\n",
       "      <th>max_features_20</th>\n",
       "      <th>max_features_200</th>\n",
       "      <th>max_features_3</th>\n",
       "      <th>max_features_30</th>\n",
       "      <th>max_features_4</th>\n",
       "      <th>max_features_40</th>\n",
       "      <th>max_features_5</th>\n",
       "      <th>max_features_50</th>\n",
       "      <th>max_features_auto</th>\n",
       "      <th>max_features_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14121</th>\n",
       "      <td>228</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5739671552</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14122</th>\n",
       "      <td>229</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5739732992</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14123</th>\n",
       "      <td>230</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5505212416</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14124</th>\n",
       "      <td>231</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5505236992</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14125</th>\n",
       "      <td>232</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5492637696</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14126</th>\n",
       "      <td>233</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5492662272</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14127</th>\n",
       "      <td>234</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4255526912</td>\n",
       "      <td>8</td>\n",
       "      <td>50000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14128</th>\n",
       "      <td>235</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4247465984</td>\n",
       "      <td>8</td>\n",
       "      <td>50000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14129</th>\n",
       "      <td>236</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4125597696</td>\n",
       "      <td>8</td>\n",
       "      <td>50000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14130</th>\n",
       "      <td>237</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4069433344</td>\n",
       "      <td>8</td>\n",
       "      <td>50000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14131</th>\n",
       "      <td>238</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4068786176</td>\n",
       "      <td>8</td>\n",
       "      <td>50000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14134</th>\n",
       "      <td>241</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4038275072</td>\n",
       "      <td>8</td>\n",
       "      <td>50000</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14135</th>\n",
       "      <td>242</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4021616640</td>\n",
       "      <td>8</td>\n",
       "      <td>50000</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14136</th>\n",
       "      <td>243</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4002238464</td>\n",
       "      <td>8</td>\n",
       "      <td>50000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14139</th>\n",
       "      <td>246</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3903647744</td>\n",
       "      <td>8</td>\n",
       "      <td>50000</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14140</th>\n",
       "      <td>247</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3903647744</td>\n",
       "      <td>8</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14141</th>\n",
       "      <td>248</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3903647744</td>\n",
       "      <td>8</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14144</th>\n",
       "      <td>251</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3882037248</td>\n",
       "      <td>8</td>\n",
       "      <td>100000</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14147</th>\n",
       "      <td>254</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3782332416</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14150</th>\n",
       "      <td>257</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4850151424</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14154</th>\n",
       "      <td>261</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5217873920</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14155</th>\n",
       "      <td>262</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5644267520</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14158</th>\n",
       "      <td>265</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5738717184</td>\n",
       "      <td>8</td>\n",
       "      <td>2000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14159</th>\n",
       "      <td>266</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5645123584</td>\n",
       "      <td>8</td>\n",
       "      <td>2000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14165</th>\n",
       "      <td>272</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5309120512</td>\n",
       "      <td>8</td>\n",
       "      <td>2000000</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14166</th>\n",
       "      <td>273</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5775069184</td>\n",
       "      <td>8</td>\n",
       "      <td>2000000</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14168</th>\n",
       "      <td>275</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5802713088</td>\n",
       "      <td>8</td>\n",
       "      <td>2000000</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14169</th>\n",
       "      <td>276</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5887983616</td>\n",
       "      <td>8</td>\n",
       "      <td>2000000</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14171</th>\n",
       "      <td>278</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5413576704</td>\n",
       "      <td>8</td>\n",
       "      <td>3000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14172</th>\n",
       "      <td>279</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5228990464</td>\n",
       "      <td>8</td>\n",
       "      <td>3000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15577</th>\n",
       "      <td>1684</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6008270848</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15578</th>\n",
       "      <td>1685</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5868376064</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15579</th>\n",
       "      <td>1686</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5566922752</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15580</th>\n",
       "      <td>1687</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5432008704</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15581</th>\n",
       "      <td>1688</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5487017984</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15582</th>\n",
       "      <td>1689</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5486841856</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15583</th>\n",
       "      <td>1690</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5485113344</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15584</th>\n",
       "      <td>1691</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5264596992</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15585</th>\n",
       "      <td>1692</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5310558208</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15586</th>\n",
       "      <td>1693</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5199241216</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15587</th>\n",
       "      <td>1694</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4798296064</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15592</th>\n",
       "      <td>1699</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6038519808</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>1700</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5916446720</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15594</th>\n",
       "      <td>1701</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6026104832</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15595</th>\n",
       "      <td>1702</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4157825024</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15596</th>\n",
       "      <td>1703</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6014070784</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15597</th>\n",
       "      <td>1704</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3828346880</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15610</th>\n",
       "      <td>1717</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6334115840</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15611</th>\n",
       "      <td>1718</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5642948608</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15612</th>\n",
       "      <td>1719</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7276892160</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15613</th>\n",
       "      <td>1720</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6606065664</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15614</th>\n",
       "      <td>1721</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6794895360</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15615</th>\n",
       "      <td>1722</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7143030784</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15616</th>\n",
       "      <td>1723</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7082577920</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15617</th>\n",
       "      <td>1724</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6778093568</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15618</th>\n",
       "      <td>1725</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6647767040</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15619</th>\n",
       "      <td>1726</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4837568512</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15620</th>\n",
       "      <td>1727</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4917084160</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630</th>\n",
       "      <td>1737</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7118925824</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15631</th>\n",
       "      <td>1738</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>8617660416</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>790 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  total_memory  available_memory  num_cpu  num_rows  \\\n",
       "14121         228   17179869184        5739671552        8      1000   \n",
       "14122         229   17179869184        5739732992        8      1000   \n",
       "14123         230   17179869184        5505212416        8      1000   \n",
       "14124         231   17179869184        5505236992        8      1000   \n",
       "14125         232   17179869184        5492637696        8      1000   \n",
       "14126         233   17179869184        5492662272        8      1000   \n",
       "14127         234   17179869184        4255526912        8     50000   \n",
       "14128         235   17179869184        4247465984        8     50000   \n",
       "14129         236   17179869184        4125597696        8     50000   \n",
       "14130         237   17179869184        4069433344        8     50000   \n",
       "14131         238   17179869184        4068786176        8     50000   \n",
       "14134         241   17179869184        4038275072        8     50000   \n",
       "14135         242   17179869184        4021616640        8     50000   \n",
       "14136         243   17179869184        4002238464        8     50000   \n",
       "14139         246   17179869184        3903647744        8     50000   \n",
       "14140         247   17179869184        3903647744        8    100000   \n",
       "14141         248   17179869184        3903647744        8    100000   \n",
       "14144         251   17179869184        3882037248        8    100000   \n",
       "14147         254   17179869184        3782332416        8   1000000   \n",
       "14150         257   17179869184        4850151424        8   1000000   \n",
       "14154         261   17179869184        5217873920        8   1000000   \n",
       "14155         262   17179869184        5644267520        8   1000000   \n",
       "14158         265   17179869184        5738717184        8   2000000   \n",
       "14159         266   17179869184        5645123584        8   2000000   \n",
       "14165         272   17179869184        5309120512        8   2000000   \n",
       "14166         273   17179869184        5775069184        8   2000000   \n",
       "14168         275   17179869184        5802713088        8   2000000   \n",
       "14169         276   17179869184        5887983616        8   2000000   \n",
       "14171         278   17179869184        5413576704        8   3000000   \n",
       "14172         279   17179869184        5228990464        8   3000000   \n",
       "...           ...           ...               ...      ...       ...   \n",
       "15577        1684   17179869184        6008270848        8  10000000   \n",
       "15578        1685   17179869184        5868376064        8  10000000   \n",
       "15579        1686   17179869184        5566922752        8  10000000   \n",
       "15580        1687   17179869184        5432008704        8  10000000   \n",
       "15581        1688   17179869184        5487017984        8  10000000   \n",
       "15582        1689   17179869184        5486841856        8  10000000   \n",
       "15583        1690   17179869184        5485113344        8  10000000   \n",
       "15584        1691   17179869184        5264596992        8  10000000   \n",
       "15585        1692   17179869184        5310558208        8  10000000   \n",
       "15586        1693   17179869184        5199241216        8  10000000   \n",
       "15587        1694   17179869184        4798296064        8  10000000   \n",
       "15592        1699   17179869184        6038519808        8  10000000   \n",
       "15593        1700   17179869184        5916446720        8  10000000   \n",
       "15594        1701   17179869184        6026104832        8  10000000   \n",
       "15595        1702   17179869184        4157825024        8  10000000   \n",
       "15596        1703   17179869184        6014070784        8  10000000   \n",
       "15597        1704   17179869184        3828346880        8  10000000   \n",
       "15610        1717   17179869184        6334115840        8  10000000   \n",
       "15611        1718   17179869184        5642948608        8  10000000   \n",
       "15612        1719   17179869184        7276892160        8  10000000   \n",
       "15613        1720   17179869184        6606065664        8  10000000   \n",
       "15614        1721   17179869184        6794895360        8  10000000   \n",
       "15615        1722   17179869184        7143030784        8  10000000   \n",
       "15616        1723   17179869184        7082577920        8  10000000   \n",
       "15617        1724   17179869184        6778093568        8  10000000   \n",
       "15618        1725   17179869184        6647767040        8  10000000   \n",
       "15619        1726   17179869184        4837568512        8  10000000   \n",
       "15620        1727   17179869184        4917084160        8  10000000   \n",
       "15630        1737   17179869184        7118925824        8  10000000   \n",
       "15631        1738   17179869184        8617660416        8  10000000   \n",
       "\n",
       "       num_features  n_estimators  max_depth  min_samples_split  \\\n",
       "14121             2            10        NaN                  2   \n",
       "14122             2            10        NaN                  2   \n",
       "14123             2            10        NaN                  2   \n",
       "14124             2            10        NaN                  2   \n",
       "14125             2            10        NaN                  2   \n",
       "14126             2            10        NaN                  2   \n",
       "14127            10            10        NaN                  2   \n",
       "14128            10            10        NaN                  2   \n",
       "14129            10            10        NaN                  2   \n",
       "14130            10            10        NaN                  2   \n",
       "14131            10            10        NaN                  4   \n",
       "14134            40            10        NaN                  4   \n",
       "14135            40            10        NaN                  4   \n",
       "14136            50            10        NaN                  4   \n",
       "14139           100            10        NaN                  2   \n",
       "14140            10            10        NaN                  2   \n",
       "14141            10            10        NaN                  4   \n",
       "14144            40            10        NaN                 10   \n",
       "14147            10            10        NaN                  2   \n",
       "14150            40            10        NaN                 10   \n",
       "14154           100            10        NaN                  4   \n",
       "14155           100            10        NaN                  4   \n",
       "14158            10            10        NaN                  2   \n",
       "14159            10            10        NaN                  4   \n",
       "14165            20            10        NaN                  4   \n",
       "14166            20            10        NaN                 10   \n",
       "14168            40            10        NaN                  2   \n",
       "14169            40            10        NaN                  4   \n",
       "14171            10            10        NaN                  2   \n",
       "14172            10            10        NaN                 10   \n",
       "...             ...           ...        ...                ...   \n",
       "15577            10            10        NaN                  2   \n",
       "15578            10            10        NaN                  2   \n",
       "15579            10            10        NaN                  2   \n",
       "15580            10            10        NaN                  2   \n",
       "15581            10            10        NaN                  2   \n",
       "15582            10            10        NaN                  4   \n",
       "15583            10            10        NaN                  4   \n",
       "15584            10            10        NaN                  4   \n",
       "15585            10            10        NaN                 10   \n",
       "15586            10            10        NaN                 10   \n",
       "15587            10            10        NaN                 10   \n",
       "15592            20            10        NaN                  2   \n",
       "15593            20            10        NaN                  2   \n",
       "15594            20            10        NaN                  2   \n",
       "15595            20            10        NaN                  4   \n",
       "15596            20            10        NaN                  4   \n",
       "15597            20            10        NaN                 10   \n",
       "15610            30            10        NaN                  2   \n",
       "15611            30            10        NaN                  2   \n",
       "15612            30            10        NaN                  2   \n",
       "15613            30            10        NaN                  4   \n",
       "15614            30            10        NaN                  4   \n",
       "15615            30            10        NaN                 10   \n",
       "15616            30            10        NaN                 10   \n",
       "15617            30            10        NaN                 10   \n",
       "15618            30            10        NaN                 10   \n",
       "15619            30            10        NaN                 10   \n",
       "15620            30            10        NaN                 10   \n",
       "15630            40            10        NaN                  2   \n",
       "15631            40            10        NaN                  2   \n",
       "\n",
       "       min_samples_leaf        ...         max_features_20  max_features_200  \\\n",
       "14121               1.0        ...                       0                 0   \n",
       "14122               1.0        ...                       0                 0   \n",
       "14123               1.0        ...                       0                 0   \n",
       "14124               1.0        ...                       0                 0   \n",
       "14125               1.0        ...                       0                 0   \n",
       "14126               1.0        ...                       0                 0   \n",
       "14127               1.0        ...                       0                 0   \n",
       "14128               1.0        ...                       0                 0   \n",
       "14129               1.0        ...                       0                 0   \n",
       "14130               1.0        ...                       0                 0   \n",
       "14131               5.0        ...                       0                 0   \n",
       "14134               1.0        ...                       0                 0   \n",
       "14135              10.0        ...                       0                 0   \n",
       "14136              10.0        ...                       0                 0   \n",
       "14139               1.0        ...                       0                 0   \n",
       "14140              10.0        ...                       0                 0   \n",
       "14141               1.0        ...                       0                 0   \n",
       "14144               1.0        ...                       0                 0   \n",
       "14147              10.0        ...                       0                 0   \n",
       "14150               5.0        ...                       0                 0   \n",
       "14154               1.0        ...                       0                 0   \n",
       "14155              10.0        ...                       0                 0   \n",
       "14158              10.0        ...                       0                 0   \n",
       "14159              10.0        ...                       0                 0   \n",
       "14165               1.0        ...                       0                 0   \n",
       "14166              10.0        ...                       0                 0   \n",
       "14168              10.0        ...                       0                 0   \n",
       "14169               5.0        ...                       0                 0   \n",
       "14171              10.0        ...                       0                 0   \n",
       "14172              10.0        ...                       0                 0   \n",
       "...                 ...        ...                     ...               ...   \n",
       "15577               1.0        ...                       0                 0   \n",
       "15578               5.0        ...                       0                 0   \n",
       "15579               5.0        ...                       0                 0   \n",
       "15580              10.0        ...                       0                 0   \n",
       "15581              10.0        ...                       0                 0   \n",
       "15582               5.0        ...                       0                 0   \n",
       "15583              10.0        ...                       0                 0   \n",
       "15584              10.0        ...                       0                 0   \n",
       "15585               1.0        ...                       0                 0   \n",
       "15586               1.0        ...                       0                 0   \n",
       "15587               5.0        ...                       0                 0   \n",
       "15592               1.0        ...                       0                 0   \n",
       "15593              10.0        ...                       0                 0   \n",
       "15594              10.0        ...                       0                 0   \n",
       "15595               1.0        ...                       0                 0   \n",
       "15596               5.0        ...                       0                 0   \n",
       "15597               5.0        ...                       0                 0   \n",
       "15610               1.0        ...                       0                 0   \n",
       "15611               5.0        ...                       0                 0   \n",
       "15612              10.0        ...                       0                 0   \n",
       "15613               1.0        ...                       0                 0   \n",
       "15614               5.0        ...                       0                 0   \n",
       "15615               1.0        ...                       0                 0   \n",
       "15616               1.0        ...                       0                 0   \n",
       "15617               1.0        ...                       0                 0   \n",
       "15618               5.0        ...                       0                 0   \n",
       "15619               5.0        ...                       0                 0   \n",
       "15620              10.0        ...                       0                 0   \n",
       "15630               1.0        ...                       0                 0   \n",
       "15631              10.0        ...                       0                 0   \n",
       "\n",
       "       max_features_3  max_features_30  max_features_4  max_features_40  \\\n",
       "14121               0                0               0                0   \n",
       "14122               0                0               0                0   \n",
       "14123               0                0               0                0   \n",
       "14124               0                0               0                0   \n",
       "14125               0                0               0                0   \n",
       "14126               0                0               0                0   \n",
       "14127               0                0               0                0   \n",
       "14128               0                0               0                0   \n",
       "14129               0                0               0                0   \n",
       "14130               0                0               0                0   \n",
       "14131               0                0               0                0   \n",
       "14134               0                0               0                0   \n",
       "14135               0                0               0                0   \n",
       "14136               0                0               0                0   \n",
       "14139               0                0               0                0   \n",
       "14140               0                0               0                0   \n",
       "14141               0                0               0                0   \n",
       "14144               0                0               0                0   \n",
       "14147               0                0               0                0   \n",
       "14150               0                0               0                0   \n",
       "14154               0                0               0                0   \n",
       "14155               0                0               0                0   \n",
       "14158               0                0               0                0   \n",
       "14159               0                0               0                0   \n",
       "14165               0                0               0                0   \n",
       "14166               0                0               0                0   \n",
       "14168               0                0               0                0   \n",
       "14169               0                0               0                0   \n",
       "14171               0                0               0                0   \n",
       "14172               0                0               0                0   \n",
       "...               ...              ...             ...              ...   \n",
       "15577               0                0               0                0   \n",
       "15578               0                0               0                0   \n",
       "15579               0                0               0                0   \n",
       "15580               0                0               0                0   \n",
       "15581               0                0               0                0   \n",
       "15582               0                0               0                0   \n",
       "15583               0                0               0                0   \n",
       "15584               0                0               0                0   \n",
       "15585               0                0               0                0   \n",
       "15586               0                0               0                0   \n",
       "15587               0                0               0                0   \n",
       "15592               0                0               0                0   \n",
       "15593               0                0               0                0   \n",
       "15594               0                0               0                0   \n",
       "15595               0                0               0                0   \n",
       "15596               0                0               0                0   \n",
       "15597               0                0               0                0   \n",
       "15610               0                0               0                0   \n",
       "15611               0                0               0                0   \n",
       "15612               0                0               0                0   \n",
       "15613               0                0               0                0   \n",
       "15614               0                0               0                0   \n",
       "15615               0                0               0                0   \n",
       "15616               0                0               0                0   \n",
       "15617               0                0               0                0   \n",
       "15618               0                0               0                0   \n",
       "15619               0                0               0                0   \n",
       "15620               0                0               0                0   \n",
       "15630               0                0               0                0   \n",
       "15631               0                0               0                0   \n",
       "\n",
       "       max_features_5  max_features_50  max_features_auto  max_features_nan  \n",
       "14121               0                0                  1                 0  \n",
       "14122               0                0                  1                 0  \n",
       "14123               0                0                  1                 0  \n",
       "14124               0                0                  1                 0  \n",
       "14125               0                0                  1                 0  \n",
       "14126               0                0                  1                 0  \n",
       "14127               0                0                  1                 0  \n",
       "14128               0                0                  1                 0  \n",
       "14129               0                0                  1                 0  \n",
       "14130               0                0                  1                 0  \n",
       "14131               0                0                  1                 0  \n",
       "14134               0                0                  1                 0  \n",
       "14135               1                0                  0                 0  \n",
       "14136               0                0                  1                 0  \n",
       "14139               0                0                  0                 0  \n",
       "14140               0                0                  1                 0  \n",
       "14141               0                0                  1                 0  \n",
       "14144               0                0                  0                 0  \n",
       "14147               1                0                  0                 0  \n",
       "14150               1                0                  0                 0  \n",
       "14154               0                0                  0                 0  \n",
       "14155               1                0                  0                 0  \n",
       "14158               0                0                  0                 0  \n",
       "14159               1                0                  0                 0  \n",
       "14165               0                0                  1                 0  \n",
       "14166               0                0                  0                 0  \n",
       "14168               0                0                  1                 0  \n",
       "14169               0                0                  0                 0  \n",
       "14171               0                0                  0                 0  \n",
       "14172               1                0                  0                 0  \n",
       "...               ...              ...                ...               ...  \n",
       "15577               0                0                  0                 0  \n",
       "15578               0                0                  1                 0  \n",
       "15579               0                0                  1                 0  \n",
       "15580               0                0                  1                 0  \n",
       "15581               1                0                  0                 0  \n",
       "15582               0                0                  0                 0  \n",
       "15583               0                0                  0                 0  \n",
       "15584               0                0                  0                 0  \n",
       "15585               0                0                  0                 0  \n",
       "15586               0                0                  1                 0  \n",
       "15587               1                0                  0                 0  \n",
       "15592               1                0                  0                 0  \n",
       "15593               0                0                  0                 0  \n",
       "15594               1                0                  0                 0  \n",
       "15595               0                0                  0                 0  \n",
       "15596               0                0                  0                 0  \n",
       "15597               1                0                  0                 0  \n",
       "15610               0                0                  0                 0  \n",
       "15611               0                0                  0                 0  \n",
       "15612               0                0                  0                 0  \n",
       "15613               0                0                  0                 0  \n",
       "15614               0                0                  0                 0  \n",
       "15615               0                0                  1                 0  \n",
       "15616               0                0                  0                 0  \n",
       "15617               0                0                  0                 0  \n",
       "15618               1                0                  0                 0  \n",
       "15619               1                0                  0                 0  \n",
       "15620               0                0                  0                 0  \n",
       "15630               0                0                  0                 0  \n",
       "15631               0                0                  1                 0  \n",
       "\n",
       "[790 rows x 32 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dums = pd.get_dummies(df_1, dummy_na=True)\n",
    "dums[dums.max_depth.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>total_memory</th>\n",
       "      <th>available_memory</th>\n",
       "      <th>num_cpu</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>num_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>...</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>output</th>\n",
       "      <th>max_features_10</th>\n",
       "      <th>max_features_100</th>\n",
       "      <th>max_features_20</th>\n",
       "      <th>max_features_200</th>\n",
       "      <th>max_features_30</th>\n",
       "      <th>max_features_40</th>\n",
       "      <th>max_features_50</th>\n",
       "      <th>max_features_auto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7036096512</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.639697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6761955328</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.990652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6267830272</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.976542</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5694320640</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.501601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5679689728</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.001720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5683245056</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.732058</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4346757120</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948835</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4284518400</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.959365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4335284224</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.449856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4384038912</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.359353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4358402048</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.446605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3759247360</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.755734</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3329490944</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.696814</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7016251392</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.661148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6637260800</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.485538</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5078642688</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.698586</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4386443264</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.270306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4390096896</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.133462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3443556352</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.416343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6981324800</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.100406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5074989056</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.148093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6246006784</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.530122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4871557120</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.347198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6153269248</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.399691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3435200512</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.410973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3112235008</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.491263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7535542272</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.912246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7481905152</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.150266</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7407673344</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.101918</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6718763008</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.191413</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13863</th>\n",
       "      <td>3522</td>\n",
       "      <td>3522</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7737450496</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.408077</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13864</th>\n",
       "      <td>3523</td>\n",
       "      <td>3523</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7737171968</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.864994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13865</th>\n",
       "      <td>3524</td>\n",
       "      <td>3524</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7737393152</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.311031</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>3525</td>\n",
       "      <td>3525</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7743938560</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.777174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>3526</td>\n",
       "      <td>3526</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7743918080</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.363928</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13868</th>\n",
       "      <td>3527</td>\n",
       "      <td>3527</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7722721280</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.953918</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869</th>\n",
       "      <td>3528</td>\n",
       "      <td>3528</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7708467200</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.885204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870</th>\n",
       "      <td>3529</td>\n",
       "      <td>3529</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7721271296</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.177824</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13871</th>\n",
       "      <td>3530</td>\n",
       "      <td>3530</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7728721920</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.228459</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13872</th>\n",
       "      <td>3531</td>\n",
       "      <td>3531</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7720828928</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.899300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13873</th>\n",
       "      <td>3532</td>\n",
       "      <td>3532</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7713673216</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.829369</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13874</th>\n",
       "      <td>3533</td>\n",
       "      <td>3533</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7713808384</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.861142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13875</th>\n",
       "      <td>3534</td>\n",
       "      <td>3534</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7714541568</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.877358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13876</th>\n",
       "      <td>3535</td>\n",
       "      <td>3535</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7702306816</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.883076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13877</th>\n",
       "      <td>3536</td>\n",
       "      <td>3536</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7682064384</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.848859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13878</th>\n",
       "      <td>3537</td>\n",
       "      <td>3537</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7700299776</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.719067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13879</th>\n",
       "      <td>3538</td>\n",
       "      <td>3538</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7699615744</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.927418</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13880</th>\n",
       "      <td>3539</td>\n",
       "      <td>3539</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7696257024</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.871254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13881</th>\n",
       "      <td>3540</td>\n",
       "      <td>3540</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7716163584</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.092481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13882</th>\n",
       "      <td>3541</td>\n",
       "      <td>3541</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7724032000</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.926043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13883</th>\n",
       "      <td>3542</td>\n",
       "      <td>3542</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7708397568</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.919522</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13884</th>\n",
       "      <td>3543</td>\n",
       "      <td>3543</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7672819712</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.864806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13885</th>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7721512960</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.847708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13886</th>\n",
       "      <td>3545</td>\n",
       "      <td>3545</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7713689600</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.176153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13887</th>\n",
       "      <td>3546</td>\n",
       "      <td>3546</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7721811968</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.279345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13888</th>\n",
       "      <td>3547</td>\n",
       "      <td>3547</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7708086272</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.127818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13889</th>\n",
       "      <td>3548</td>\n",
       "      <td>3548</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7672541184</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.429864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13890</th>\n",
       "      <td>3549</td>\n",
       "      <td>3549</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7716155392</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.879327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13891</th>\n",
       "      <td>3550</td>\n",
       "      <td>3550</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7721082880</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.820026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13892</th>\n",
       "      <td>3551</td>\n",
       "      <td>3551</td>\n",
       "      <td>8375676928</td>\n",
       "      <td>7728533504</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.877606</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13893 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1  total_memory  available_memory  num_cpu  \\\n",
       "0               0             0   17179869184        7036096512        8   \n",
       "1               1             1   17179869184        6761955328        8   \n",
       "2               2             2   17179869184        6267830272        8   \n",
       "3               3             3   17179869184        5694320640        8   \n",
       "4               4             4   17179869184        5679689728        8   \n",
       "5               5             5   17179869184        5683245056        8   \n",
       "6               6             6   17179869184        4346757120        8   \n",
       "7               7             7   17179869184        4284518400        8   \n",
       "8               8             8   17179869184        4335284224        8   \n",
       "9               9             9   17179869184        4384038912        8   \n",
       "10             10            10   17179869184        4358402048        8   \n",
       "11             11            11   17179869184        3759247360        8   \n",
       "12             12            12   17179869184        3329490944        8   \n",
       "13             13            13   17179869184        7016251392        8   \n",
       "14             14            14   17179869184        6637260800        8   \n",
       "15             15            15   17179869184        5078642688        8   \n",
       "16             16            16   17179869184        4386443264        8   \n",
       "17             17            17   17179869184        4390096896        8   \n",
       "18             18            18   17179869184        3443556352        8   \n",
       "19             19            19   17179869184        6981324800        8   \n",
       "20             20            20   17179869184        5074989056        8   \n",
       "21             21            21   17179869184        6246006784        8   \n",
       "22             22            22   17179869184        4871557120        8   \n",
       "23             23            23   17179869184        6153269248        8   \n",
       "24             24            24   17179869184        3435200512        8   \n",
       "25             25            25   17179869184        3112235008        8   \n",
       "26             26            26   17179869184        7535542272        8   \n",
       "27             27            27   17179869184        7481905152        8   \n",
       "28             28            28   17179869184        7407673344        8   \n",
       "29             29            29   17179869184        6718763008        8   \n",
       "...           ...           ...           ...               ...      ...   \n",
       "13863        3522          3522    8375676928        7737450496        4   \n",
       "13864        3523          3523    8375676928        7737171968        4   \n",
       "13865        3524          3524    8375676928        7737393152        4   \n",
       "13866        3525          3525    8375676928        7743938560        4   \n",
       "13867        3526          3526    8375676928        7743918080        4   \n",
       "13868        3527          3527    8375676928        7722721280        4   \n",
       "13869        3528          3528    8375676928        7708467200        4   \n",
       "13870        3529          3529    8375676928        7721271296        4   \n",
       "13871        3530          3530    8375676928        7728721920        4   \n",
       "13872        3531          3531    8375676928        7720828928        4   \n",
       "13873        3532          3532    8375676928        7713673216        4   \n",
       "13874        3533          3533    8375676928        7713808384        4   \n",
       "13875        3534          3534    8375676928        7714541568        4   \n",
       "13876        3535          3535    8375676928        7702306816        4   \n",
       "13877        3536          3536    8375676928        7682064384        4   \n",
       "13878        3537          3537    8375676928        7700299776        4   \n",
       "13879        3538          3538    8375676928        7699615744        4   \n",
       "13880        3539          3539    8375676928        7696257024        4   \n",
       "13881        3540          3540    8375676928        7716163584        4   \n",
       "13882        3541          3541    8375676928        7724032000        4   \n",
       "13883        3542          3542    8375676928        7708397568        4   \n",
       "13884        3543          3543    8375676928        7672819712        4   \n",
       "13885        3544          3544    8375676928        7721512960        4   \n",
       "13886        3545          3545    8375676928        7713689600        4   \n",
       "13887        3546          3546    8375676928        7721811968        4   \n",
       "13888        3547          3547    8375676928        7708086272        4   \n",
       "13889        3548          3548    8375676928        7672541184        4   \n",
       "13890        3549          3549    8375676928        7716155392        4   \n",
       "13891        3550          3550    8375676928        7721082880        4   \n",
       "13892        3551          3551    8375676928        7728533504        4   \n",
       "\n",
       "       num_rows  num_features  n_estimators  max_depth  min_samples_split  \\\n",
       "0       5000000            50            10         10                  2   \n",
       "1       5000000            50            10         10                  2   \n",
       "2       5000000            50            10         10                  2   \n",
       "3       5000000            50            10         10                  2   \n",
       "4       5000000            50            10         50                  4   \n",
       "5       5000000            50            10         50                 10   \n",
       "6       5000000            50            10        100                  2   \n",
       "7       5000000            50            10        100                  4   \n",
       "8       5000000            50            50         10                  2   \n",
       "9       5000000            50            50         10                 10   \n",
       "10      5000000            50            50         50                  4   \n",
       "11      5000000            50            50         50                 10   \n",
       "12      5000000            50            50        100                  2   \n",
       "13      5000000            50            50        100                  4   \n",
       "14      5000000            50            50        100                 10   \n",
       "15      5000000            50           100         10                  2   \n",
       "16      5000000            50           100         10                  4   \n",
       "17      5000000            50           100         10                 10   \n",
       "18      5000000            50           100         50                  4   \n",
       "19      5000000            50           100         50                 10   \n",
       "20      5000000            50           100         50                 10   \n",
       "21      5000000            50           100         50                 10   \n",
       "22      5000000            50           100        100                  2   \n",
       "23      5000000            50           100        100                  4   \n",
       "24      5000000            25            10         50                  4   \n",
       "25      5000000            25            10        100                 10   \n",
       "26      5000000            25            50         10                 10   \n",
       "27      5000000            25            50         10                 10   \n",
       "28      5000000            25            50         50                  4   \n",
       "29      5000000            25            50         50                  4   \n",
       "...         ...           ...           ...        ...                ...   \n",
       "13863   1000000           600           100         50                 10   \n",
       "13864   1000000           600           100         50                 10   \n",
       "13865   1000000           600           100         50                 10   \n",
       "13866   1000000           600           100        100                  2   \n",
       "13867   1000000           600           100        100                  2   \n",
       "13868   1000000           600           100        100                  2   \n",
       "13869   1000000           600           100        100                  2   \n",
       "13870   1000000           600           100        100                  2   \n",
       "13871   1000000           600           100        100                  2   \n",
       "13872   1000000           600           100        100                  4   \n",
       "13873   1000000           600           100        100                  4   \n",
       "13874   1000000           600           100        100                  4   \n",
       "13875   1000000           600           100        100                  4   \n",
       "13876   1000000           600           100        100                  4   \n",
       "13877   1000000           600           100        100                  4   \n",
       "13878   1000000           600           100        100                  4   \n",
       "13879   1000000           600           100        100                  4   \n",
       "13880   1000000           600           100        100                  4   \n",
       "13881   1000000           600           100        100                  4   \n",
       "13882   1000000           600           100        100                  4   \n",
       "13883   1000000           600           100        100                  4   \n",
       "13884   1000000           600           100        100                  4   \n",
       "13885   1000000           600           100        100                  4   \n",
       "13886   1000000           600           100        100                  4   \n",
       "13887   1000000           600           100        100                 10   \n",
       "13888   1000000           600           100        100                 10   \n",
       "13889   1000000           600           100        100                 10   \n",
       "13890   1000000           600           100        100                 10   \n",
       "13891   1000000           600           100        100                 10   \n",
       "13892   1000000           600           100        100                 10   \n",
       "\n",
       "             ...          n_jobs     output  max_features_10  \\\n",
       "0            ...             2.0   2.639697                0   \n",
       "1            ...             2.0   0.990652                0   \n",
       "2            ...             5.0   1.976542                1   \n",
       "3            ...             2.0   2.501601                0   \n",
       "4            ...             2.0   1.001720                0   \n",
       "5            ...             2.0   2.732058                0   \n",
       "6            ...             1.0   0.948835                1   \n",
       "7            ...             5.0   0.959365                0   \n",
       "8            ...             2.0   9.449856                0   \n",
       "9            ...             2.0   9.359353                0   \n",
       "10           ...             1.0  16.446605                0   \n",
       "11           ...             8.0   6.755734                0   \n",
       "12           ...             1.0  16.696814                1   \n",
       "13           ...             8.0   1.661148                0   \n",
       "14           ...             5.0   1.485538                1   \n",
       "15           ...             2.0  19.698586                1   \n",
       "16           ...             2.0   2.270306                0   \n",
       "17           ...             5.0   2.133462                0   \n",
       "18           ...             2.0   2.416343                0   \n",
       "19           ...             2.0  20.100406                0   \n",
       "20           ...             8.0  11.148093                0   \n",
       "21           ...             1.0   3.530122                0   \n",
       "22           ...             2.0   2.347198                0   \n",
       "23           ...             8.0   2.399691                0   \n",
       "24           ...             2.0   2.410973                0   \n",
       "25           ...             8.0   1.491263                0   \n",
       "26           ...             1.0   1.912246                1   \n",
       "27           ...             2.0   1.150266                1   \n",
       "28           ...             2.0   9.101918                1   \n",
       "29           ...             5.0   1.191413                1   \n",
       "...          ...             ...        ...              ...   \n",
       "13863        ...             1.0   8.408077                0   \n",
       "13864        ...             1.0   7.864994                0   \n",
       "13865        ...             8.0   4.311031                0   \n",
       "13866        ...             1.0   7.777174                0   \n",
       "13867        ...             8.0   4.363928                1   \n",
       "13868        ...             2.0   2.953918                1   \n",
       "13869        ...             8.0   2.885204                0   \n",
       "13870        ...             1.0   3.177824                0   \n",
       "13871        ...             1.0   8.228459                0   \n",
       "13872        ...             5.0   2.899300                0   \n",
       "13873        ...             1.0   7.829369                1   \n",
       "13874        ...             8.0   4.861142                0   \n",
       "13875        ...             2.0   4.877358                0   \n",
       "13876        ...             2.0   4.883076                0   \n",
       "13877        ...             5.0   2.848859                0   \n",
       "13878        ...             2.0   4.719067                0   \n",
       "13879        ...             2.0   4.927418                1   \n",
       "13880        ...             8.0   2.871254                1   \n",
       "13881        ...             1.0   3.092481                1   \n",
       "13882        ...             8.0   2.926043                0   \n",
       "13883        ...             2.0   4.919522                0   \n",
       "13884        ...             5.0   2.864806                0   \n",
       "13885        ...             8.0   2.847708                0   \n",
       "13886        ...             1.0   3.176153                0   \n",
       "13887        ...             5.0   4.279345                0   \n",
       "13888        ...             2.0   5.127818                0   \n",
       "13889        ...             5.0   4.429864                0   \n",
       "13890        ...             5.0   2.879327                0   \n",
       "13891        ...             5.0   4.820026                0   \n",
       "13892        ...             5.0   2.877606                0   \n",
       "\n",
       "       max_features_100  max_features_20  max_features_200  max_features_30  \\\n",
       "0                     0                0                 0                0   \n",
       "1                     0                0                 0                0   \n",
       "2                     0                0                 0                0   \n",
       "3                     0                0                 0                0   \n",
       "4                     0                0                 0                0   \n",
       "5                     0                0                 0                0   \n",
       "6                     0                0                 0                0   \n",
       "7                     0                0                 0                0   \n",
       "8                     0                0                 0                0   \n",
       "9                     0                0                 0                0   \n",
       "10                    0                1                 0                0   \n",
       "11                    0                0                 0                0   \n",
       "12                    0                0                 0                0   \n",
       "13                    0                0                 0                0   \n",
       "14                    0                0                 0                0   \n",
       "15                    0                0                 0                0   \n",
       "16                    0                0                 0                0   \n",
       "17                    0                0                 0                0   \n",
       "18                    0                0                 0                0   \n",
       "19                    0                0                 0                0   \n",
       "20                    0                0                 0                0   \n",
       "21                    0                0                 0                0   \n",
       "22                    0                0                 0                0   \n",
       "23                    0                0                 0                0   \n",
       "24                    0                0                 0                0   \n",
       "25                    0                1                 0                0   \n",
       "26                    0                0                 0                0   \n",
       "27                    0                0                 0                0   \n",
       "28                    0                0                 0                0   \n",
       "29                    0                0                 0                0   \n",
       "...                 ...              ...               ...              ...   \n",
       "13863                 1                0                 0                0   \n",
       "13864                 0                0                 0                0   \n",
       "13865                 0                0                 0                0   \n",
       "13866                 0                0                 0                0   \n",
       "13867                 0                0                 0                0   \n",
       "13868                 0                0                 0                0   \n",
       "13869                 0                1                 0                0   \n",
       "13870                 1                0                 0                0   \n",
       "13871                 1                0                 0                0   \n",
       "13872                 0                0                 0                0   \n",
       "13873                 0                0                 0                0   \n",
       "13874                 0                1                 0                0   \n",
       "13875                 0                0                 0                0   \n",
       "13876                 0                1                 0                0   \n",
       "13877                 0                0                 0                0   \n",
       "13878                 1                0                 0                0   \n",
       "13879                 0                0                 0                0   \n",
       "13880                 0                0                 0                0   \n",
       "13881                 0                0                 0                0   \n",
       "13882                 0                0                 0                0   \n",
       "13883                 1                0                 0                0   \n",
       "13884                 0                0                 0                0   \n",
       "13885                 0                1                 0                0   \n",
       "13886                 1                0                 0                0   \n",
       "13887                 0                1                 0                0   \n",
       "13888                 0                0                 0                0   \n",
       "13889                 0                0                 0                0   \n",
       "13890                 0                0                 0                0   \n",
       "13891                 0                1                 0                0   \n",
       "13892                 1                0                 0                0   \n",
       "\n",
       "       max_features_40  max_features_50  max_features_auto  \n",
       "0                    0                0                  1  \n",
       "1                    0                0                  1  \n",
       "2                    0                0                  0  \n",
       "3                    0                1                  0  \n",
       "4                    0                1                  0  \n",
       "5                    0                1                  0  \n",
       "6                    0                0                  0  \n",
       "7                    0                0                  1  \n",
       "8                    0                1                  0  \n",
       "9                    0                1                  0  \n",
       "10                   0                0                  0  \n",
       "11                   0                0                  1  \n",
       "12                   0                0                  0  \n",
       "13                   0                1                  0  \n",
       "14                   0                0                  0  \n",
       "15                   0                0                  0  \n",
       "16                   0                0                  1  \n",
       "17                   0                1                  0  \n",
       "18                   0                0                  1  \n",
       "19                   0                1                  0  \n",
       "20                   0                1                  0  \n",
       "21                   0                0                  1  \n",
       "22                   0                1                  0  \n",
       "23                   0                0                  1  \n",
       "24                   0                0                  1  \n",
       "25                   0                0                  0  \n",
       "26                   0                0                  0  \n",
       "27                   0                0                  0  \n",
       "28                   0                0                  0  \n",
       "29                   0                0                  0  \n",
       "...                ...              ...                ...  \n",
       "13863                0                0                  0  \n",
       "13864                0                1                  0  \n",
       "13865                0                1                  0  \n",
       "13866                0                0                  1  \n",
       "13867                0                0                  0  \n",
       "13868                0                0                  0  \n",
       "13869                0                0                  0  \n",
       "13870                0                0                  0  \n",
       "13871                0                0                  0  \n",
       "13872                0                0                  1  \n",
       "13873                0                0                  0  \n",
       "13874                0                0                  0  \n",
       "13875                0                1                  0  \n",
       "13876                0                0                  0  \n",
       "13877                0                1                  0  \n",
       "13878                0                0                  0  \n",
       "13879                0                0                  0  \n",
       "13880                0                0                  0  \n",
       "13881                0                0                  0  \n",
       "13882                0                1                  0  \n",
       "13883                0                0                  0  \n",
       "13884                0                0                  1  \n",
       "13885                0                0                  0  \n",
       "13886                0                0                  0  \n",
       "13887                0                0                  0  \n",
       "13888                0                1                  0  \n",
       "13889                0                1                  0  \n",
       "13890                0                0                  1  \n",
       "13891                0                0                  0  \n",
       "13892                0                0                  0  \n",
       "\n",
       "[13893 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Desktop/scikest/scikest\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/scikest/scikest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('RandomForestRegressor_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Trainer(verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = t.params['other_params'] + list(t.params['external_params'].keys()) + list(t.params['internal_params'].keys()) + ['output']\n",
    "df_2.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Downloads\n"
     ]
    }
   ],
   "source": [
    "cd Downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_csv('RandomForestRegressor_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = t.params['other_params'] + list(t.params['external_params'].keys()) + list(t.params['internal_params'].keys()) + ['output']\n",
    "df_3.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_final = pd.concat([df_1,df_2,df_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_final.to_csv('new_new_final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_final = final_final[final_final.output<2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_final['is_max_depth_na'] = final_final.max_depth.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_final['is_impurity_split_na'] = final_final.min_impurity_split.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>available_memory</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_impurity_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>...</th>\n",
       "      <th>min_weight_fraction_leaf</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>num_cpu</th>\n",
       "      <th>num_features</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>oob_score</th>\n",
       "      <th>output</th>\n",
       "      <th>total_memory</th>\n",
       "      <th>is_max_depth_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Unnamed: 0.1, available_memory, bootstrap, max_depth, max_features, max_leaf_nodes, min_impurity_decrease, min_impurity_split, min_samples_leaf, min_samples_split, min_weight_fraction_leaf, n_estimators, n_jobs, num_cpu, num_features, num_rows, oob_score, output, total_memory, is_max_depth_na]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_final[final_final.is_max_depth_na.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = final_final[t.params['other_params'] + list(t.params['external_params'].keys()) + list(t.params['internal_params'].keys())+['is_max_depth_na']+['is_impurity_split_na']]\n",
    "outputs = final_final[['output']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(inputs.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = (data\n",
    "             ._get_numeric_data()\n",
    "             .dropna(axis=0, how='any')\n",
    "             .as_matrix())\n",
    "y = outputs['output'].dropna(axis=0, how='any').as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_algo = RandomForestRegressor(criterion='mse', max_depth=100, max_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=100,\n",
       "           max_features=10, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_algo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikest.estimate import Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features=10, max_leaf_nodes=None, min_impurity_decrease=10,\n",
    "           min_impurity_split=None, min_samples_leaf=10,\n",
    "           min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
    "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
    "           verbose=2, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf, X, y = RandomForestRegressor(max_depth=10),np.random.rand(100000,10),np.random.rand(100000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n",
      "CPU times: user 8.64 s, sys: 127 ms, total: 8.76 s\n",
      "Wall time: 8.66 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=10, max_leaf_nodes=None, min_impurity_decrease=10,\n",
       "           min_impurity_split=None, min_samples_leaf=10,\n",
       "           min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikest.estimate.Estimator:INFO:The model would fit. Moving on\n",
      "scikest.estimate.Estimator:INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "scikest.estimate.Estimator:INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4606062592], 'num_cpu': [8], 'num_rows': [100000], 'num_features': [10], 'n_estimators': [10], 'max_depth': [0], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.0], 'max_features': ['auto'], 'max_leaf_nodes': [0], 'min_impurity_decrease': [0.0], 'min_impurity_split': [0], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(163)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    162 \u001b[0;31m        \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 163 \u001b[0;31m        \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    164 \u001b[0;31m        \u001b[0mforgotten_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimation_original_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(164)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    163 \u001b[0;31m        \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 164 \u001b[0;31m        \u001b[0mforgotten_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimation_original_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    165 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(166)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    165 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 166 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforgotten_inputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    167 \u001b[0;31m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{forgotten_inputs} parameters missing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> forgotten_inputs\n",
      "[]\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(169)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    168 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 169 \u001b[0;31m        \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    170 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(172)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    171 \u001b[0;31m        \u001b[0;31m# adding 0 columns for columns that are not in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 172 \u001b[0;31m        \u001b[0mdummy_inputs_to_fill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    173 \u001b[0;31m        \u001b[0mmissing_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(173)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    172 \u001b[0;31m        \u001b[0mdummy_inputs_to_fill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 173 \u001b[0;31m        \u001b[0mmissing_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    174 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_inputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(174)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    173 \u001b[0;31m        \u001b[0mmissing_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 174 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_inputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    175 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Parameters {missing_inputs} will not be accounted for'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(178)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> dummy_inputs_to_fill\n",
      "['max_features_10', 'max_features_4', 'max_features_200', 'max_features_2', 'max_features_1', 'max_features_30', 'max_features_100', 'max_features_20', 'max_features_50', 'max_features_3', 'max_features_5', 'max_features_40']\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(178)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(178)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(178)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(178)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(178)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(178)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(178)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(178)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(178)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(178)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(178)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(177)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_inputs_to_fill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(180)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 180 \u001b[0;31m        \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimation_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    181 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(182)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    181 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 182 \u001b[0;31m        X = (df[estimation_inputs]\n",
      "\u001b[0m\u001b[0;32m    183 \u001b[0;31m                 \u001b[0;34m.\u001b[0m\u001b[0m_get_numeric_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(184)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    183 \u001b[0;31m                 \u001b[0;34m.\u001b[0m\u001b[0m_get_numeric_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 184 \u001b[0;31m                 \u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    185 \u001b[0;31m                 .as_matrix())\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> n\n",
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/estimate.py\u001b[0m(186)\u001b[0;36m_estimate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    185 \u001b[0;31m                 .as_matrix())\n",
      "\u001b[0m\u001b[0;32m--> 186 \u001b[0;31m        \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    187 \u001b[0;31m        \u001b[0mlower_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimate_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> estimation_inputs\n",
      "['total_memory', 'available_memory', 'num_cpu', 'num_rows', 'num_features', 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'min_weight_fraction_leaf', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'bootstrap', 'oob_score', 'n_jobs', 'max_features_1', 'max_features_10', 'max_features_100', 'max_features_2', 'max_features_20', 'max_features_200', 'max_features_3', 'max_features_30', 'max_features_4', 'max_features_40', 'max_features_5', 'max_features_50', 'max_features_auto']\n",
      "ipdb> exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/scikest/scikest/estimate.py\u001b[0m in \u001b[0;36mestimate_duration\u001b[0;34m(self, algo, X, y)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/estimate.py\u001b[0m in \u001b[0;36m_fit_start\u001b[0;34m(self, algo, X, y)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/utils.py\u001b[0m in \u001b[0;36m_handle_timeout\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_handle_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: STREAM ioctl timeout",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-485bbc38cd5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_duration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/scikest/scikest/estimate.py\u001b[0m in \u001b[0;36mestimate_duration\u001b[0;34m(self, algo, X, y)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The model would fit. Moving on'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/scikest/scikest/estimate.py\u001b[0m in \u001b[0;36m_estimate\u001b[0;34m(self, algo, X, y, percentile)\u001b[0m\n\u001b[1;32m    184\u001b[0m                  \u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                  .as_matrix())\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mlower_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimate_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/estimate.py\u001b[0m in \u001b[0;36m_estimate\u001b[0;34m(self, algo, X, y, percentile)\u001b[0m\n\u001b[1;32m    184\u001b[0m                  \u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                  .as_matrix())\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mlower_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimate_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Estimator().estimate_duration(RandomForestRegressor(),np.random.rand(100000,10),np.random.rand(100000,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=200,\n",
       "           max_features=10, max_leaf_nodes=10, min_impurity_decrease=10,\n",
       "           min_impurity_split=10, min_samples_leaf=10,\n",
       "           min_samples_split=10, min_weight_fraction_leaf=0.5,\n",
       "           n_estimators=100, n_jobs=10, oob_score=False, random_state=None,\n",
       "           verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'available_memory': [4532969472],\n",
       " 'bootstrap': [True],\n",
       " 'is_max_depth_na': [False],\n",
       " 'max_depth': [200],\n",
       " 'max_features': ['10'],\n",
       " 'max_leaf_nodes': [10],\n",
       " 'min_impurity_decrease': [10],\n",
       " 'min_impurity_split': [10],\n",
       " 'min_samples_leaf': [10],\n",
       " 'min_samples_split': [10],\n",
       " 'min_weight_fraction_leaf': [0.5],\n",
       " 'n_estimators': [100],\n",
       " 'n_jobs': [1],\n",
       " 'num_cpu': [8],\n",
       " 'num_features': [10],\n",
       " 'num_rows': [100000],\n",
       " 'oob_score': [False],\n",
       " 'total_memory': [17179869184]}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features=10, max_leaf_nodes=10, min_impurity_decrease=10,\n",
       "           min_impurity_split=10, min_samples_leaf=10,\n",
       "           min_samples_split=10, min_weight_fraction_leaf=0.5,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic = {'total_memory': [17179869184], 'available_memory': [4532969472], \n",
    "       'num_cpu': [8], 'num_rows': [100000], 'num_features': [10], \n",
    "       'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], \n",
    "       'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], \n",
    "       'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], \n",
    "       'min_impurity_split': [10], \n",
    "       'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1], \n",
    "       'is_max_depth_na': [False], 'is_impurity_split_na':[False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_list = ['total_memory', 'available_memory', 'num_cpu', 'num_rows', 'num_features', 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'min_weight_fraction_leaf', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'bootstrap', 'oob_score', 'n_jobs', 'is_max_depth_na', 'is_impurity_split_na']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " df = pd.DataFrame(dic, columns=param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_memory</th>\n",
       "      <th>available_memory</th>\n",
       "      <th>num_cpu</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>num_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_weight_fraction_leaf</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_impurity_split</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>oob_score</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>is_max_depth_na</th>\n",
       "      <th>is_impurity_split_na</th>\n",
       "      <th>max_features_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4532969472</td>\n",
       "      <td>8</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_memory  available_memory  num_cpu  num_rows  num_features  \\\n",
       "0   17179869184        4532969472        8    100000            10   \n",
       "\n",
       "   n_estimators  max_depth  min_samples_split  min_samples_leaf  \\\n",
       "0           100         10                 10                10   \n",
       "\n",
       "   min_weight_fraction_leaf  max_leaf_nodes  min_impurity_decrease  \\\n",
       "0                       0.5              10                     10   \n",
       "\n",
       "   min_impurity_split  bootstrap  oob_score  n_jobs  is_max_depth_na  \\\n",
       "0                  10       True      False       1            False   \n",
       "\n",
       "   is_impurity_split_na  max_features_10  \n",
       "0                 False                1  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_inputs_to_fill = ['max_features_auto', 'max_features_4', 'max_features_200', 'max_features_2', 'max_features_1', 'max_features_30', 'max_features_100', 'max_features_20', 'max_features_50', 'max_features_3', 'max_features_5', 'max_features_40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dummy_inputs_to_fill:\n",
    "    df[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_memory', 'available_memory', 'num_cpu', 'num_rows',\n",
       "       'num_features', 'n_estimators', 'max_depth', 'min_samples_split',\n",
       "       'min_samples_leaf', 'min_weight_fraction_leaf', 'max_leaf_nodes',\n",
       "       'min_impurity_decrease', 'min_impurity_split', 'bootstrap', 'oob_score',\n",
       "       'n_jobs', 'is_max_depth_na', 'is_impurity_split_na', 'max_features_10',\n",
       "       'max_features_auto', 'max_features_4', 'max_features_200',\n",
       "       'max_features_2', 'max_features_1', 'max_features_30',\n",
       "       'max_features_100', 'max_features_20', 'max_features_50',\n",
       "       'max_features_3', 'max_features_5', 'max_features_40'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df [['total_memory', 'available_memory', 'num_cpu', 'num_rows', 'num_features', 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'min_weight_fraction_leaf', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'bootstrap', 'oob_score', 'n_jobs', 'max_features_1', 'max_features_10', 'max_features_100', 'max_features_2', 'max_features_20', 'max_features_200', 'max_features_3', 'max_features_30', 'max_features_4', 'max_features_40', 'max_features_5', 'max_features_50', 'max_features_auto', 'is_max_depth_na', 'is_impurity_split_na']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_memory</th>\n",
       "      <th>available_memory</th>\n",
       "      <th>num_cpu</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>num_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_weight_fraction_leaf</th>\n",
       "      <th>...</th>\n",
       "      <th>max_features_200</th>\n",
       "      <th>max_features_3</th>\n",
       "      <th>max_features_30</th>\n",
       "      <th>max_features_4</th>\n",
       "      <th>max_features_40</th>\n",
       "      <th>max_features_5</th>\n",
       "      <th>max_features_50</th>\n",
       "      <th>max_features_auto</th>\n",
       "      <th>is_max_depth_na</th>\n",
       "      <th>is_impurity_split_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4532969472</td>\n",
       "      <td>8</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_memory  available_memory  num_cpu  num_rows  num_features  \\\n",
       "0   17179869184        4532969472        8    100000            10   \n",
       "\n",
       "   n_estimators  max_depth  min_samples_split  min_samples_leaf  \\\n",
       "0           100         10                 10                10   \n",
       "\n",
       "   min_weight_fraction_leaf          ...           max_features_200  \\\n",
       "0                       0.5          ...                          0   \n",
       "\n",
       "   max_features_3  max_features_30  max_features_4  max_features_40  \\\n",
       "0               0                0               0                0   \n",
       "\n",
       "   max_features_5  max_features_50  max_features_auto  is_max_depth_na  \\\n",
       "0               0                0                  0            False   \n",
       "\n",
       "   is_impurity_split_na  \n",
       "0                 False  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (df\n",
    "                 ._get_numeric_data()\n",
    "                 .dropna(axis=0, how='any')\n",
    "                 .as_matrix())\n",
    "prediction = meta_algo.predict(X)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/nathantoubiana/Desktop/scikest/scikest/train.py\u001b[0m(232)\u001b[0;36m_transform_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    231 \u001b[0;31m        \u001b[0;31m#we then fill artifical (and natural) NAs with -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 232 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    233 \u001b[0;31m        \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "t.model_fit(generate_data=False, inputs=inputs, outputs=outputs, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.89250188])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikest.train.Trainer:INFO:Model inputs: ['total_memory', 'available_memory', 'num_cpu', 'num_rows', 'num_features', 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'min_weight_fraction_leaf', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'bootstrap', 'oob_score', 'n_jobs', 'max_features_1', 'max_features_10', 'max_features_100', 'max_features_2', 'max_features_20', 'max_features_200', 'max_features_3', 'max_features_30', 'max_features_4', 'max_features_40', 'max_features_5', 'max_features_50', 'max_features_auto']\n",
      "scikest.train.Trainer:INFO:Fitting RF to estimate training durations for model RandomForestRegressor\n",
      "scikest.train.Trainer:INFO:Saving RF to RF_RandomForestRegressor_estimator.pkl\n",
      "scikest.train.Trainer:INFO:R squared on train set is 0.9204946679019796\n",
      "scikest.train.Trainer:INFO:\n",
      "            MAPE on train set is: 23.130322570053853\n",
      "            MAPE on test set is: 67.96116933900537\n",
      "            RMSE on train set is 7.709868798569779\n",
      "            RMSE on test set is 14.673700917564517 \n",
      "scikest.utils.LogMixin:INFO:Trainer.model_fit took 0.451s seconds\n"
     ]
    }
   ],
   "source": [
    "skl = t.model_fit(generate_data=False, inputs=inputs, outputs=outputs, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skl.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.mlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f523fb86c4b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m nn = Regressor(\n\u001b[1;32m      4\u001b[0m     layers=[\n\u001b[1;32m      5\u001b[0m         \u001b[0mLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rectifier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.mlp'"
     ]
    }
   ],
   "source": [
    "from sklearn.mlp import Regressor, Layer\n",
    "\n",
    "nn = Regressor(\n",
    "    layers=[\n",
    "        Layer(\"Rectifier\", units=100),\n",
    "        Layer(\"Linear\")],\n",
    "    learning_rate=0.02, verbose=3,\n",
    "    n_iter=10)\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.neural_network' has no attribute 'Layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-514a7bc08539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.neural_network' has no attribute 'Layer'"
     ]
    }
   ],
   "source": [
    "sklearn.neural_network.multilayer_perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Desktop/RFDATA\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/RFDATA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Model inputs: ['total_memory', 'available_memory', 'num_cpu', 'num_rows', 'num_features', 'n_estimators', 'min_samples_split', 'min_samples_leaf', 'min_weight_fraction_leaf', 'min_impurity_decrease', 'bootstrap', 'oob_score', 'n_jobs', 'max_features_auto']\n"
     ]
    }
   ],
   "source": [
    "X, y , cols = trainer._transform_data(dfs[0], dfs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_memory</th>\n",
       "      <th>available_memory</th>\n",
       "      <th>num_cpu</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>num_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_weight_fraction_leaf</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_impurity_split</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>oob_score</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>max_features_auto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5739671552</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5739732992</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_memory  available_memory  num_cpu  num_rows  num_features  \\\n",
       "0   17179869184        5739671552        8      1000             2   \n",
       "1   17179869184        5739732992        8      1000             2   \n",
       "\n",
       "   n_estimators  max_depth  min_samples_split  min_samples_leaf  \\\n",
       "0            10          0                  2                 1   \n",
       "1            10          0                  2                 1   \n",
       "\n",
       "   min_weight_fraction_leaf  max_leaf_nodes  min_impurity_decrease  \\\n",
       "0                       0.1               0                      1   \n",
       "1                       0.1               0                      1   \n",
       "\n",
       "   min_impurity_split  bootstrap  oob_score  n_jobs  max_features_auto  \n",
       "0                   0       True      False       1                  1  \n",
       "1                   0       True      False       2                  1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(dfs[0].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Desktop/RFDATA\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/RFDATA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('scikest/result_latest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('data_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('RandomForestRegressor_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=Trainer(verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Desktop/RFDATA\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/RFDATA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = t.params['other_params'] + list(t.params['external_params'].keys()) + list(t.params['internal_params'].keys()) + ['output']\n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "invalid type comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-517758da27c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'k-means++'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    798\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type comparison\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid type comparison"
     ]
    }
   ],
   "source": [
    "df = df[(df.min_samples_split!='k-means++')&(df.min_weight_fraction_leaf!='ovr')].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=pd.read_csv('RandomForestRegressor_result.csv')\n",
    "df2=pd.read_csv('data_2.csv')\n",
    "df3=pd.read_csv('data_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Desktop/RFDATA\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/RFDATA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat([df1,df2,df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13893, 19)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('new_final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.output<2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df_train[t.params['other_params'] + list(t.params['external_params'].keys()) + list(t.params['internal_params'].keys())]\n",
    "outputs = df_train[['output']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(inputs.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (data\n",
    "             ._get_numeric_data()\n",
    "             .dropna(axis=0, how='any')\n",
    "             .as_matrix())\n",
    "y = outputs['output'].dropna(axis=0, how='any').as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17179869184, 7036096512, 8, ..., 0, 0, 1],\n",
       "       [17179869184, 6761955328, 8, ..., 0, 0, 1],\n",
       "       [17179869184, 6267830272, 8, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [8375676928, 7716155392, 4, ..., 0, 0, 1],\n",
       "       [8375676928, 7721082880, 4, ..., 0, 0, 0],\n",
       "       [8375676928, 7728533504, 4, ..., 0, 0, 0]], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "met = RandomForestRegressor(max_depth=50, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=50,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=3, warm_start=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 230268859815651.46875000\n",
      "Iteration 2, loss = 1551138717506.81958008\n",
      "Iteration 3, loss = 801743660166.40515137\n",
      "Iteration 4, loss = 250794487528.79629517\n",
      "Iteration 5, loss = 84727203884.21383667\n",
      "Iteration 6, loss = 38815300807.85484314\n",
      "Iteration 7, loss = 24848478464.60313797\n",
      "Iteration 8, loss = 18627600021.75519180\n",
      "Iteration 9, loss = 15583685788.64236641\n",
      "Iteration 10, loss = 14345309370.19285011\n",
      "Iteration 11, loss = 35458134278.28961945\n",
      "Iteration 12, loss = 21432488439.64672852\n",
      "Iteration 13, loss = 8028829282.35724831\n",
      "Iteration 14, loss = 7029890978.08890820\n",
      "Iteration 15, loss = 6099437223.35181046\n",
      "Iteration 16, loss = 5150419427.86404896\n",
      "Iteration 17, loss = 4348122645.23123741\n",
      "Iteration 18, loss = 3708075306.45903778\n",
      "Iteration 19, loss = 3344455269.09296513\n",
      "Iteration 20, loss = 2690644850.05693483\n",
      "Iteration 21, loss = 2267077640.47261238\n",
      "Iteration 22, loss = 1830160410.03306770\n",
      "Iteration 23, loss = 1610857485.16748667\n",
      "Iteration 24, loss = 1418937561.26717615\n",
      "Iteration 25, loss = 1115338400.14279628\n",
      "Iteration 26, loss = 972989752.04128277\n",
      "Iteration 27, loss = 848063744.06797349\n",
      "Iteration 28, loss = 730956551.86835527\n",
      "Iteration 29, loss = 651539224.97225976\n",
      "Iteration 30, loss = 1483288487.74840522\n",
      "Iteration 31, loss = 810699718.58384836\n",
      "Iteration 32, loss = 505169554.69995970\n",
      "Iteration 33, loss = 487333167.59543657\n",
      "Iteration 34, loss = 452714321.39909333\n",
      "Iteration 35, loss = 424543032.63153023\n",
      "Iteration 36, loss = 443267927.06099325\n",
      "Iteration 37, loss = 391199703.18500113\n",
      "Iteration 38, loss = 377678704.30024737\n",
      "Iteration 39, loss = 362085177.32399440\n",
      "Iteration 40, loss = 343064994.22072130\n",
      "Iteration 41, loss = 347429425.73934370\n",
      "Iteration 42, loss = 333517599.02103692\n",
      "Iteration 43, loss = 349467042.75899416\n",
      "Iteration 44, loss = 27220440065.14770889\n",
      "Iteration 45, loss = 1581455865.21399617\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=[8, 6, 50], learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=8000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=3, warm_start=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPRegressor(alpha=1,max_iter=8000, hidden_layer_sizes=[8,6, 50], activation='relu', early_stopping=False, verbose=3)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE is the mean absolute percentage error https://en.wikipedia.org/wiki/Mean_absolute_percentage_error\n",
    "y_pred_test = mlp.predict(X_test)\n",
    "mape_test = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "mape_train = np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# MAPE is the mean absolute percentage error https://en.wikipedia.org/wiki/Mean_absolute_percentage_error\n",
    "y_pred_test = met.predict(X_test)\n",
    "mape_test = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
    "y_pred_train = met.predict(X_train)\n",
    "mape_train = np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.249897718429565,\n",
       " 0.15244483947753906,\n",
       " 0.70097613334655762,\n",
       " 29.783414125442505,\n",
       " 0.12485194206237793,\n",
       " 0.4076998233795166,\n",
       " 1.2481603622436523,\n",
       " 0.34185695648193359,\n",
       " 0.1329798698425293,\n",
       " 0.15473198890686035,\n",
       " 0.30125284194946289,\n",
       " 0.1179511547088623,\n",
       " 1.2948095798492432,\n",
       " 2.1393077373504643,\n",
       " 0.17349410057067871,\n",
       " 0.26413893699646002,\n",
       " 0.13718461990356445,\n",
       " 1.1358950138092041,\n",
       " 0.8994138240814209,\n",
       " 0.97905182838439941,\n",
       " 2.7655630111694336,\n",
       " 38.596691846847527,\n",
       " 0.13196778297424314,\n",
       " 0.21607398986816406,\n",
       " 0.27251887321472168,\n",
       " 0.31124997138977051,\n",
       " 0.14966034889221191,\n",
       " 0.12562704086303711,\n",
       " 0.16122078895568848,\n",
       " 0.14399003982543945,\n",
       " 0.23832893371582031,\n",
       " 41.570933103561394,\n",
       " 1.6620097160339355,\n",
       " 0.22727608680725089,\n",
       " 0.17354917526245114,\n",
       " 0.97647881507873535,\n",
       " 0.8871910572052002,\n",
       " 0.6263422966003418,\n",
       " 1.2156040668487549,\n",
       " 0.42975926399230963,\n",
       " 0.21661090850830081,\n",
       " 0.14194512367248535,\n",
       " 0.2304229736328125,\n",
       " 0.13614511489868164,\n",
       " 0.15067911148071289,\n",
       " 0.07629919052124022,\n",
       " 1.4664363861083984,\n",
       " 3.9430310726165767,\n",
       " 1.1290264129638672,\n",
       " 0.89656400680541992,\n",
       " 0.52323627471923828,\n",
       " 0.12788772583007812,\n",
       " 2.8545362949371338,\n",
       " 0.12760186195373535,\n",
       " 0.084779024124145508,\n",
       " 32.117615938186653,\n",
       " 0.29121780395507812,\n",
       " 2.2143309116363525,\n",
       " 0.29480981826782232,\n",
       " 1.9656331539154053,\n",
       " 0.14223408699035645,\n",
       " 0.2754290103912353,\n",
       " 0.1252439022064209,\n",
       " 1.2307600975036621,\n",
       " 0.13632011413574219,\n",
       " 9.0443220138549805,\n",
       " 3.8962388038635249,\n",
       " 1.1773691177368164,\n",
       " 0.21944332122802729,\n",
       " 1.2888410091400146,\n",
       " 1.5421347618103027,\n",
       " 0.50091075897216797,\n",
       " 0.19626998901367188,\n",
       " 0.83676505088806152,\n",
       " 0.14510917663574219,\n",
       " 0.19074273109436035,\n",
       " 0.97064304351806641,\n",
       " 0.11408090591430665,\n",
       " 0.11432600021362305,\n",
       " 1.1957130432128906,\n",
       " 0.16803407669067386,\n",
       " 1.2259800434112549,\n",
       " 0.15960097312927246,\n",
       " 0.1131722927093506,\n",
       " 0.033751010894775391,\n",
       " 0.43865084648132319,\n",
       " 35.312801837921143,\n",
       " 0.89076995849609375,\n",
       " 0.086497783660888672,\n",
       " 10.372770071029665,\n",
       " 0.1315760612487793,\n",
       " 0.117401123046875,\n",
       " 0.6848292350769043,\n",
       " 0.14075088500976562,\n",
       " 0.13819241523742676,\n",
       " 0.11171984672546388,\n",
       " 0.15687394142150879,\n",
       " 7.4313068389892578,\n",
       " 0.11886310577392578,\n",
       " 0.17241334915161133,\n",
       " 226.09169888496399,\n",
       " 0.11912775039672853,\n",
       " 0.26341009140014648,\n",
       " 0.04006505012512207,\n",
       " 0.54734611511230469,\n",
       " 0.29032087326049805,\n",
       " 0.46927094459533691,\n",
       " 0.060984849929809577,\n",
       " 0.17386078834533691,\n",
       " 1.0299351215362549,\n",
       " 0.17185091972351074,\n",
       " 0.30697822570800781,\n",
       " 2.3802056312561035,\n",
       " 3.7310969829559326,\n",
       " 0.17443704605102539,\n",
       " 0.074094057083129869,\n",
       " 0.14828610420227051,\n",
       " 1.0121748447418213,\n",
       " 0.13890528678894046,\n",
       " 0.12665271759033206,\n",
       " 11.035293102264404,\n",
       " 0.12775826454162598,\n",
       " 0.14290928840637207,\n",
       " 0.17292404174804688,\n",
       " 0.17343711853027344,\n",
       " 1.4775121212005615,\n",
       " 1.5559549331665039,\n",
       " 7.6896450519561776,\n",
       " 0.031611919403076172,\n",
       " 0.15243792533874512,\n",
       " 0.1671149730682373,\n",
       " 13.671304225921631,\n",
       " 0.24574804306030279,\n",
       " 0.14060115814208984,\n",
       " 17.291254758834839,\n",
       " 0.14021706581115725,\n",
       " 0.10943508148193359,\n",
       " 0.12583303451538086,\n",
       " 0.97427105903625477,\n",
       " 0.16731905937194824,\n",
       " 14.426770925521851,\n",
       " 0.21889400482177729,\n",
       " 1.2209830284118652,\n",
       " 0.1181490421295166,\n",
       " 0.45196437835693359,\n",
       " 2.1673047542572017,\n",
       " 0.014066934585571287,\n",
       " 0.32700204849243164,\n",
       " 0.19080114364624026,\n",
       " 1.2709214687347412,\n",
       " 9.5447039604186994,\n",
       " 0.17270064353942871,\n",
       " 0.1086289882659912,\n",
       " 0.019701004028320312,\n",
       " 0.17453789710998535,\n",
       " 3.3080639839172363,\n",
       " 0.11088442802429199,\n",
       " 0.13793134689331055,\n",
       " 0.13624787330627439,\n",
       " 0.81639003753662109,\n",
       " 0.1261138916015625,\n",
       " 0.13682818412780762,\n",
       " 232.17589092254642,\n",
       " 0.67120647430419922,\n",
       " 0.20549106597900391,\n",
       " 0.13255810737609866,\n",
       " 0.9089710712432858,\n",
       " 49.951301097869866,\n",
       " 0.11157608032226562,\n",
       " 3.0420479774475098,\n",
       " 0.91838073730468761,\n",
       " 0.12556099891662598,\n",
       " 0.1719050407409668,\n",
       " 0.17225790023803711,\n",
       " 2.7679316997528081,\n",
       " 0.32267642021179199,\n",
       " 0.13787579536437988,\n",
       " 11.972468137741089,\n",
       " 0.18177103996276853,\n",
       " 0.13724517822265625,\n",
       " 0.1101377010345459,\n",
       " 0.1216740608215332,\n",
       " 0.13777756690979004,\n",
       " 0.25150704383850103,\n",
       " 0.13698983192443848,\n",
       " 0.254241943359375,\n",
       " 0.21378016471862801,\n",
       " 3.2576756477355961,\n",
       " 0.11066579818725586,\n",
       " 0.6990206241607666,\n",
       " 0.17201685905456546,\n",
       " 0.14783787727355954,\n",
       " 0.17857599258422852,\n",
       " 0.27114081382751465,\n",
       " 0.22095298767089844,\n",
       " 1.0346822738647461,\n",
       " 0.14480900764465332,\n",
       " 3.3453309535980225,\n",
       " 0.2312891483306885,\n",
       " 4.1179573535919189,\n",
       " 3.4960479736328125,\n",
       " 0.90528488159179676,\n",
       " 1.1912450790405271,\n",
       " 0.55677604675292969,\n",
       " 0.86308884620666504,\n",
       " 0.44962096214294428,\n",
       " 0.055850028991699219,\n",
       " 0.13345003128051758,\n",
       " 0.23675704002380371,\n",
       " 1.1484789848327637,\n",
       " 14.178531169891356,\n",
       " 0.039877891540527344,\n",
       " 3.1861310005187988,\n",
       " 137.13296484947205,\n",
       " 0.10898733139038086,\n",
       " 0.67293190956115723,\n",
       " 1.2039728164672852,\n",
       " 2.3433992862701416,\n",
       " 0.37267899513244629,\n",
       " 0.36913204193115229,\n",
       " 0.88900852203369141,\n",
       " 1.3201069831848145,\n",
       " 0.4714891910552978,\n",
       " 0.31308388710021973,\n",
       " 0.11072468757629396,\n",
       " 11.382328987121582,\n",
       " 0.11586689949035645,\n",
       " 0.039359092712402337,\n",
       " 0.17790007591247561,\n",
       " 0.1680760383605957,\n",
       " 0.16463804244995114,\n",
       " 4.2240655422210684,\n",
       " 1.3719727993011477,\n",
       " 2.7040770053863525,\n",
       " 2.1120786666870122,\n",
       " 0.13166117668151855,\n",
       " 0.16466927528381348,\n",
       " 2.4042220115661621,\n",
       " 0.17287731170654294,\n",
       " 0.15933394432067871,\n",
       " 1.2253668308258057,\n",
       " 0.99173688888549805,\n",
       " 2.1429224014282227,\n",
       " 0.14215183258056641,\n",
       " 0.096360921859741197,\n",
       " 3.900467157363892,\n",
       " 1.1280298233032229,\n",
       " 2.176923513412476,\n",
       " 0.13464570045471191,\n",
       " 9.0627839565277117,\n",
       " 3.8077738285064697,\n",
       " 0.14017724990844727,\n",
       " 1.4276978969573977,\n",
       " 0.14599013328552246,\n",
       " 0.13340282440185547,\n",
       " 0.85398983955383301,\n",
       " 1.2849726676940918,\n",
       " 16.94891881942749,\n",
       " 0.51169276237487793,\n",
       " 0.052411794662475586,\n",
       " 0.41498899459838873,\n",
       " 0.12261700630187987,\n",
       " 0.11407303810119628,\n",
       " 0.1759040355682373,\n",
       " 1.5003693103790283,\n",
       " 0.30350399017333984,\n",
       " 0.2296071052551269,\n",
       " 0.13544774055480954,\n",
       " 0.67755270004272461,\n",
       " 0.13721394538879395,\n",
       " 1.7793200016021729,\n",
       " 2.0555038452148442,\n",
       " 0.18154287338256839,\n",
       " 0.16276097297668454,\n",
       " 0.23035335540771484,\n",
       " 1.2470200061798096,\n",
       " 7.6243889331817627,\n",
       " 0.13246393203735352,\n",
       " 2.2961671352386475,\n",
       " 0.16506528854370114,\n",
       " 0.22674894332885745,\n",
       " 1.3556039333343506,\n",
       " 0.02456974983215332,\n",
       " 0.17389988899230954,\n",
       " 0.22196793556213379,\n",
       " 2.3809583187103267,\n",
       " 1.0128488540649414,\n",
       " 0.12397313117980956,\n",
       " 0.15390801429748535,\n",
       " 0.22133803367614746,\n",
       " 0.14331483840942386,\n",
       " 4.4556148052215594,\n",
       " 0.12281489372253418,\n",
       " 0.12589597702026367,\n",
       " 1.0619230270385742,\n",
       " 0.040663003921508789,\n",
       " 0.27982711791992188,\n",
       " 0.98260784149169922,\n",
       " 0.12996292114257812,\n",
       " 0.31244802474975586,\n",
       " 0.12958312034606936,\n",
       " 0.72634577751159668,\n",
       " 0.10975503921508788,\n",
       " 0.12604713439941406,\n",
       " 2.1930820941925049,\n",
       " 0.081058740615844727,\n",
       " 1.0748159885406494,\n",
       " 4.3515279293060294,\n",
       " 0.11555933952331544,\n",
       " 0.79547429084777832,\n",
       " 1.2503440380096436,\n",
       " 3.2611339092254639,\n",
       " 0.75324869155883789,\n",
       " 0.17517733573913574,\n",
       " 0.30050516128540039,\n",
       " 1.8647451400756843,\n",
       " 0.36860013008117681,\n",
       " 0.51530098915100109,\n",
       " 0.16677689552307129,\n",
       " 13.237015962600708,\n",
       " 3.1011061668396001,\n",
       " 0.039685726165771484,\n",
       " 1.9559218883514404,\n",
       " 1.0241611003875732,\n",
       " 0.22709417343139651,\n",
       " 0.15580987930297852,\n",
       " 0.051692008972167969,\n",
       " 0.67462921142578125,\n",
       " 0.17792582511901855,\n",
       " 0.1354978084564209,\n",
       " 0.77239513397216797,\n",
       " 0.13286805152893064,\n",
       " 0.12942790985107422,\n",
       " 0.27609109878540039,\n",
       " 3.5329389572143555,\n",
       " 8.6540801525115985,\n",
       " 0.1366126537322998,\n",
       " 0.13858389854431152,\n",
       " 0.1590421199798584,\n",
       " 0.95774793624877919,\n",
       " 0.54486393928527832,\n",
       " 0.67553806304931641,\n",
       " 0.1178278923034668,\n",
       " 0.13595008850097656,\n",
       " 0.13906145095825195,\n",
       " 0.13400602340698242,\n",
       " 0.17346000671386719,\n",
       " 1.6257719993591309,\n",
       " 0.1921539306640625,\n",
       " 1.2961046695709229,\n",
       " 0.19431018829345706,\n",
       " 4.0743050575256348,\n",
       " 0.17308855056762695,\n",
       " 0.1280059814453125,\n",
       " 0.1555330753326416,\n",
       " 0.93622088432312001,\n",
       " 0.14660501480102539,\n",
       " 9.4898476600646955,\n",
       " 0.13859415054321289,\n",
       " 0.34190607070922852,\n",
       " 0.10955500602722168,\n",
       " 0.48180413246154791,\n",
       " 1.6983659267425537,\n",
       " 1.5116863250732422,\n",
       " 1.2733902931213379,\n",
       " 0.3092188835144043,\n",
       " 10.554783821105957,\n",
       " 0.13174080848693848,\n",
       " 1.3637063503265381,\n",
       " 0.1189250946044922,\n",
       " 0.45448803901672358,\n",
       " 0.13659167289733887,\n",
       " 1.161160945892334,\n",
       " 0.23912501335144051,\n",
       " 1.1078290939331057,\n",
       " 0.33534383773803711,\n",
       " 0.14458394050598145,\n",
       " 0.28560781478881841,\n",
       " 0.044338703155517578,\n",
       " 0.13755202293395996,\n",
       " 0.13368797302246094,\n",
       " 0.01459503173828125,\n",
       " 0.13680505752563474,\n",
       " 0.17301011085510254,\n",
       " 3.5602495670318604,\n",
       " 0.77536702156066906,\n",
       " 1.3724591732025146,\n",
       " 0.42259883880615229,\n",
       " 0.12087702751159668,\n",
       " 7.9628167152404785,\n",
       " 2.9082880020141602,\n",
       " 2.104896068572998,\n",
       " 0.42447900772094732,\n",
       " 0.13475298881530762,\n",
       " 0.14440226554870605,\n",
       " 0.20610380172729487,\n",
       " 0.093743085861206041,\n",
       " 0.13411092758178711,\n",
       " 0.58989286422729492,\n",
       " 0.52819204330444336,\n",
       " 0.17172455787658691,\n",
       " 1.6141419410705566,\n",
       " 1.751528263092041,\n",
       " 0.36544990539550781,\n",
       " 0.12083697319030764,\n",
       " 2.6425836086273198,\n",
       " 6.8820102214813224,\n",
       " 1.6038997173309326,\n",
       " 0.13019418716430664,\n",
       " 7.5125417709350586,\n",
       " 0.16808295249938965,\n",
       " 0.17224884033203125,\n",
       " 0.15337610244750974,\n",
       " 1.4466991424560549,\n",
       " 1.925309896469116,\n",
       " 0.14895105361938474,\n",
       " 0.91185188293457042,\n",
       " 0.76667594909667969,\n",
       " 0.1193373203277588,\n",
       " 2.3405249118804932,\n",
       " 0.19202899932861328,\n",
       " 0.17487883567810061,\n",
       " 0.32436466217041016,\n",
       " 0.20524406433105469,\n",
       " 0.59372067451477051,\n",
       " 2.3253030776977539,\n",
       " 4.5464413166046134,\n",
       " 0.15177273750305176,\n",
       " 0.0096325874328613281,\n",
       " 0.0095155239105224592,\n",
       " 1.5937259197235107,\n",
       " 0.1121041774749756,\n",
       " 0.25029087066650391,\n",
       " 0.1379244327545166,\n",
       " 1.771080493927002,\n",
       " 0.33057212829589844,\n",
       " 0.13759994506835938,\n",
       " 2.6121904850006104,\n",
       " 0.14574289321899414,\n",
       " 1.5376710891723633,\n",
       " 0.13978910446166992,\n",
       " 0.43648719787597656,\n",
       " 0.11914992332458495,\n",
       " 3.8808760643005371,\n",
       " 0.14215683937072754,\n",
       " 3.8682949542999268,\n",
       " 0.80686211585998535,\n",
       " 0.99109768867492676,\n",
       " 2.1103701591491699,\n",
       " 0.173004150390625,\n",
       " 2.0623140335083008,\n",
       " 0.15963411331176758,\n",
       " 0.65080165863037109,\n",
       " 55.025911092758179,\n",
       " 1.1878950595855713,\n",
       " 0.14414572715759275,\n",
       " 0.14588189125061035,\n",
       " 17.204079866409302,\n",
       " 0.11846399307250975,\n",
       " 0.47056698799133301,\n",
       " 2.5072360038757324,\n",
       " 0.93846607208251964,\n",
       " 0.95684099197387718,\n",
       " 9.1351191997528058,\n",
       " 0.16492009162902832,\n",
       " 0.1316380500793457,\n",
       " 0.15383100509643555,\n",
       " 39.122199058532722,\n",
       " 2.1953222751617432,\n",
       " 0.65017867088317871,\n",
       " 0.32284784317016602,\n",
       " 0.12125587463378905,\n",
       " 9.4498558044433594,\n",
       " 4.7391419410705566,\n",
       " 3.2993850708007812,\n",
       " 9.6498339176177961,\n",
       " 1.1682584285736084,\n",
       " 1.4086437225341797,\n",
       " 0.1125028133392334,\n",
       " 0.17166709899902344,\n",
       " 0.62569379806518555,\n",
       " 1.9606378078460689,\n",
       " 0.67429614067077637,\n",
       " 1.4483711719512939,\n",
       " 1.9414310455322263,\n",
       " 0.11749482154846193,\n",
       " 7.8293693065643311,\n",
       " 3.2526822090148926,\n",
       " 2.0290181636810303,\n",
       " 0.16852402687072754,\n",
       " 0.14757418632507324,\n",
       " 0.14759016036987305,\n",
       " 1.0392298698425293,\n",
       " 0.237048864364624,\n",
       " 1.7292270660400391,\n",
       " 2.8428955078125,\n",
       " 0.0441741943359375,\n",
       " 0.11783576011657715,\n",
       " 1.1588840484619141,\n",
       " 0.21577692031860352,\n",
       " 7.1290051937103271,\n",
       " 0.13853263854980469,\n",
       " 0.18378710746765131,\n",
       " 0.19523811340332031,\n",
       " 0.30994081497192383,\n",
       " 1.4156479835510254,\n",
       " 1.5822296142578125,\n",
       " 2.4086911678314209,\n",
       " 1.1349098682403564,\n",
       " 2.0789501667022705,\n",
       " 0.17218804359436035,\n",
       " 5.0061800479888916,\n",
       " 1.5368874073028564,\n",
       " 9.1538889408111555,\n",
       " 1.1831669807434082,\n",
       " 0.12917804718017578,\n",
       " 3.7240068912506095,\n",
       " 0.12089991569519044,\n",
       " 0.31460094451904297,\n",
       " 0.33368492126464844,\n",
       " 0.11364459991455078,\n",
       " 0.16055202484130859,\n",
       " 0.088495016098022461,\n",
       " 4.1390569210052481,\n",
       " 3.0544314384460449,\n",
       " 0.43110775947570801,\n",
       " 0.13115286827087402,\n",
       " 0.16367721557617188,\n",
       " 0.3369290828704834,\n",
       " 2.2035179138183598,\n",
       " 0.12704110145568848,\n",
       " 0.23206591606140131,\n",
       " 0.24171710014343264,\n",
       " 1.8596999645233161,\n",
       " 1.3574957847595217,\n",
       " 0.14106583595275879,\n",
       " 2.7858190536499023,\n",
       " 0.31570601463317871,\n",
       " 0.12937664985656738,\n",
       " 29.13314509391785,\n",
       " 0.84342384338378906,\n",
       " 0.85068225860595703,\n",
       " 2.8207707405090332,\n",
       " 0.79838109016418457,\n",
       " 0.15672779083251953,\n",
       " 0.16857004165649414,\n",
       " 1.0394139289855957,\n",
       " 1.2814130783081057,\n",
       " 1.3586370944976809,\n",
       " 0.14744901657104492,\n",
       " 0.29539799690246582,\n",
       " 2.8479185104370117,\n",
       " 0.47406101226806641,\n",
       " 3.670647144317627,\n",
       " 1.2393252849578855,\n",
       " 4.4810624122619629,\n",
       " 3.2406744956970215,\n",
       " 0.29943513870239258,\n",
       " 0.67802953720092773,\n",
       " 9.2181267738342267,\n",
       " 0.33613920211791992,\n",
       " 0.10865259170532228,\n",
       " 0.16698193550109866,\n",
       " 0.13655662536621094,\n",
       " 1.1607770919799805,\n",
       " 2.2520589828491211,\n",
       " 0.13947105407714844,\n",
       " 0.89651226997375488,\n",
       " 0.12352085113525391,\n",
       " 0.84804320335388184,\n",
       " 0.028428077697753906,\n",
       " 3.9671118259429932,\n",
       " 0.30963397026062012,\n",
       " 0.64149808883666992,\n",
       " 0.16795492172241211,\n",
       " 0.45300889015197759,\n",
       " 0.04896998405456543,\n",
       " 0.13742208480834961,\n",
       " 0.17257261276245114,\n",
       " 9.588186979293825,\n",
       " 0.12447786331176758,\n",
       " 15.760344266891479,\n",
       " 17.639203071594238,\n",
       " 0.12255620956420896,\n",
       " 0.12051105499267578,\n",
       " 5.5528011322021484,\n",
       " 0.1383059024810791,\n",
       " 0.69026589393615723,\n",
       " 1.3599390983581543,\n",
       " 0.23630785942077639,\n",
       " 13.645934820175171,\n",
       " 0.13694000244140625,\n",
       " 0.0092513561248779297,\n",
       " 1.2248873710632324,\n",
       " 6.0799789428710938,\n",
       " 0.13287115097045898,\n",
       " 0.10895681381225586,\n",
       " 0.54628419876098633,\n",
       " 4.0129220485687274,\n",
       " 0.22174692153930664,\n",
       " 1.2426958084106443,\n",
       " 0.10924434661865234,\n",
       " 3.7611639499664311,\n",
       " 0.66176581382751465,\n",
       " 0.30467987060546875,\n",
       " 0.45328092575073242,\n",
       " 0.16257405281066895,\n",
       " 0.17261409759521484,\n",
       " 0.18449521064758301,\n",
       " 0.1117560863494873,\n",
       " 0.25480914115905762,\n",
       " 0.2826621532440185,\n",
       " 0.10960936546325684,\n",
       " 5.1367769241333008,\n",
       " 3.0073728561401367,\n",
       " 0.66555905342102051,\n",
       " 0.12427306175231935,\n",
       " 0.23549294471740725,\n",
       " 1.3894999027252195,\n",
       " 0.15046787261962891,\n",
       " 0.94797682762145996,\n",
       " 2.5129361152648926,\n",
       " 3.4464907646179199,\n",
       " 0.15088701248168945,\n",
       " 0.1173548698425293,\n",
       " 0.16494297981262207,\n",
       " 0.14293932914733887,\n",
       " 0.21277189254760745,\n",
       " 0.12301397323608396,\n",
       " 0.22254323959350586,\n",
       " 2.0871074199676518,\n",
       " 0.38618016242980963,\n",
       " 1.5788657665252686,\n",
       " 0.72104620933532715,\n",
       " 1.0526509284973145,\n",
       " 0.14411687850952148,\n",
       " 0.76671624183654785,\n",
       " 0.13281822204589844,\n",
       " 1.5809788703918457,\n",
       " 0.23789215087890625,\n",
       " 0.17336511611938474,\n",
       " 0.16732096672058105,\n",
       " 0.40079188346862787,\n",
       " 0.1089470386505127,\n",
       " 19.49015116691589,\n",
       " 0.16729998588562012,\n",
       " 28.97629284858704,\n",
       " 8.0267803668975812,\n",
       " 0.16868972778320312,\n",
       " 0.22980380058288569,\n",
       " 0.2740788459777832,\n",
       " 0.13823914527893064,\n",
       " 1.5907089710235596,\n",
       " 0.22141003608703613,\n",
       " 0.13112807273864746,\n",
       " 0.10978841781616212,\n",
       " 1.0450530052185061,\n",
       " 0.92203664779663075,\n",
       " 1.4037578105926514,\n",
       " 2.4926638603210449,\n",
       " 0.16839385032653809,\n",
       " 3.2240726947784424,\n",
       " 3.5973689556121826,\n",
       " 0.079496860504150391,\n",
       " 0.13773202896118164,\n",
       " 20.819805860519409,\n",
       " 0.14603877067565918,\n",
       " 0.13582897186279294,\n",
       " 0.60626792907714844,\n",
       " 0.27385687828063965,\n",
       " 0.28248786926269531,\n",
       " 1.4207940101623535,\n",
       " 0.4747469425201416,\n",
       " 0.13692879676818848,\n",
       " 0.15974187850952148,\n",
       " 0.94787931442260742,\n",
       " 0.47319602966308588,\n",
       " 0.079195737838745131,\n",
       " 0.67954683303833008,\n",
       " 0.03978276252746582,\n",
       " 0.12471604347229005,\n",
       " 1.1320977210998535,\n",
       " 1.2574090957641602,\n",
       " 0.43908476829528809,\n",
       " 0.11350727081298828,\n",
       " 0.40626287460327148,\n",
       " 0.14427018165588379,\n",
       " 0.11644911766052245,\n",
       " 0.11184000968933104,\n",
       " 0.1198570728302002,\n",
       " 2.7643890380859371,\n",
       " 0.16707706451416016,\n",
       " 0.15242195129394531,\n",
       " 0.17210960388183594,\n",
       " 0.11073064804077147,\n",
       " 0.75001621246337891,\n",
       " 0.13779067993164062,\n",
       " 0.41006302833557129,\n",
       " 0.12656998634338379,\n",
       " 1.1039829254150391,\n",
       " 0.17256522178649902,\n",
       " 0.11252474784851074,\n",
       " 0.13177895545959473,\n",
       " 0.13345003128051758,\n",
       " 0.13874983787536621,\n",
       " 2.9548833370208736,\n",
       " 1.5303535461425781,\n",
       " 0.041467428207397461,\n",
       " 0.17444658279418945,\n",
       " 0.13738107681274414,\n",
       " 4.012855052947998,\n",
       " 0.14286708831787109,\n",
       " 0.16885089874267578,\n",
       " 0.12707901000976562,\n",
       " 0.11944007873535155,\n",
       " 0.1691899299621582,\n",
       " 2.0282943248748784,\n",
       " 0.3357689380645752,\n",
       " 0.27534580230712891,\n",
       " 1.1052942276000977,\n",
       " 0.16276907920837402,\n",
       " 0.32994699478149409,\n",
       " 0.11313295364379886,\n",
       " 0.044926881790161133,\n",
       " 0.30423688888549805,\n",
       " 0.11685895919799805,\n",
       " 1.1840882301330566,\n",
       " 0.28810477256774897,\n",
       " 0.11958026885986328,\n",
       " 0.45493006706237787,\n",
       " 0.12902212142944336,\n",
       " 0.010753393173217772,\n",
       " 4.9395179748535165,\n",
       " 0.21106696128845207,\n",
       " 0.31884193420410162,\n",
       " 41.232418060302734,\n",
       " 0.30370211601257324,\n",
       " 0.17930245399475098,\n",
       " 0.1090223789215088,\n",
       " 1.0275988578796389,\n",
       " 0.13888335227966309,\n",
       " 0.12888979911804199,\n",
       " 1.3594424724578855,\n",
       " 0.081393003463745131,\n",
       " 0.22097110748291016,\n",
       " 0.11106061935424803,\n",
       " 8.8355231285095215,\n",
       " 0.76506948471069336,\n",
       " 0.11773014068603516,\n",
       " 0.11793375015258788,\n",
       " 0.81832528114318848,\n",
       " 3.1674787998199463,\n",
       " 0.17408967018127439,\n",
       " 0.44213676452636719,\n",
       " 0.11307787895202635,\n",
       " 2.7200043201446533,\n",
       " 1.7130076885223389,\n",
       " 0.64767694473266602,\n",
       " 2.2670145034790039,\n",
       " 13.866419792175293,\n",
       " 0.4456398487091065,\n",
       " 6.6472241878509521,\n",
       " 0.1781611442565918,\n",
       " 3.4140939712524414,\n",
       " 0.33191919326782232,\n",
       " 0.65488004684448242,\n",
       " 0.88889479637145996,\n",
       " 1.0303769111633301,\n",
       " 0.13298606872558594,\n",
       " 0.17200708389282227,\n",
       " 0.1996610164642334,\n",
       " 0.14013814926147461,\n",
       " 1.7999765872955322,\n",
       " 0.17796611785888672,\n",
       " 0.90621590614318837,\n",
       " 0.42991399765014648,\n",
       " 0.16933488845825195,\n",
       " 0.17274689674377439,\n",
       " 0.27811193466186523,\n",
       " 2.0711932182312007,\n",
       " 3.9653277397155762,\n",
       " 0.15391993522644046,\n",
       " 0.14097714424133301,\n",
       " 0.15150094032287598,\n",
       " 0.48836898803710938,\n",
       " 2.2927520275115967,\n",
       " 6.2573409080505371,\n",
       " 15.316533088684082,\n",
       " 0.0094676017761230486,\n",
       " 3.7379651069641113,\n",
       " 1.2498950958251951,\n",
       " 1.578066349029541,\n",
       " 1.4782371520996094,\n",
       " 0.20360779762268064,\n",
       " 0.12515377998352051,\n",
       " 1.83706283569336,\n",
       " 0.22178983688354487,\n",
       " 0.12247490882873535,\n",
       " 1.6291658878326416,\n",
       " 0.15684294700622561,\n",
       " 2.569787740707397,\n",
       " 0.17486906051635742,\n",
       " 0.44843697547912598,\n",
       " 0.30101394653320312,\n",
       " 0.63335394859313965,\n",
       " 0.14365386962890625,\n",
       " 0.12736892700195312,\n",
       " 0.4274051189422608,\n",
       " 0.13723087310791016,\n",
       " 4.5163850784301758,\n",
       " 0.14528465270996094,\n",
       " 0.14842391014099121,\n",
       " 0.17642331123352051,\n",
       " 0.37286281585693359,\n",
       " 1.3183972835540771,\n",
       " 0.039703369140625,\n",
       " 6.7197000980377197,\n",
       " 0.14988589286804199,\n",
       " 16.163385152816772,\n",
       " 0.31807279586791992,\n",
       " 2.5687460899353027,\n",
       " 1.518700122833252,\n",
       " 1.5740132331848145,\n",
       " 0.91263484954833984,\n",
       " 4.2260909080505371,\n",
       " 0.14388084411621094,\n",
       " 0.17400503158569336,\n",
       " 0.25871944427490234,\n",
       " 0.13148999214172366,\n",
       " 0.17425203323364258,\n",
       " 0.051063060760498047,\n",
       " 0.16991829872131348,\n",
       " 0.20317387580871585,\n",
       " 0.16452503204345706,\n",
       " 5.3045978546142578,\n",
       " 0.3845126628875733,\n",
       " 0.11483216285705565,\n",
       " 1.8607871532440183,\n",
       " 0.28259992599487305,\n",
       " 3.8167517185211182,\n",
       " 0.39263200759887695,\n",
       " 0.36884093284606928,\n",
       " 0.13939213752746582,\n",
       " 0.13795852661132812,\n",
       " 0.44036507606506348,\n",
       " 1.1339719295501709,\n",
       " 0.73805093765258789,\n",
       " 0.55002593994140625,\n",
       " 0.47199606895446777,\n",
       " 0.48451709747314448,\n",
       " 0.32485485076904297,\n",
       " 23.759759902954102,\n",
       " 0.87462615966796875,\n",
       " 0.26538681983947754,\n",
       " 0.66613221168518066,\n",
       " 0.19864892959594727,\n",
       " 2.2518541812896733,\n",
       " 0.079372406005859375,\n",
       " 0.13715147972106936,\n",
       " 0.56596827507019043,\n",
       " 0.14027023315429688,\n",
       " 6.1184771060943604,\n",
       " 0.10939812660217284,\n",
       " 0.72352385520935059,\n",
       " 0.042916297912597656,\n",
       " 0.11138653755187987,\n",
       " 4.1267449855804434,\n",
       " 0.11240220069885254,\n",
       " 7.7588088512420654,\n",
       " 0.13905477523803711,\n",
       " 0.14049720764160156,\n",
       " 0.16627597808837891,\n",
       " 0.1416780948638916,\n",
       " 0.85675597190856934,\n",
       " 0.14605307579040527,\n",
       " 0.17186880111694336,\n",
       " 5.7179319858551025,\n",
       " 3.8497121334075928,\n",
       " 0.21940517425537109,\n",
       " 2.6084380149841309,\n",
       " 0.14070701599121094,\n",
       " 0.13170003890991211,\n",
       " 27.91105580329895,\n",
       " 0.17394280433654785,\n",
       " 0.14266610145568848,\n",
       " 2.2933330535888667,\n",
       " 0.13649106025695801,\n",
       " 0.12084698677062987,\n",
       " 0.14736318588256836,\n",
       " 0.96544718742370605,\n",
       " 3.2351219654083252,\n",
       " 0.16020393371582031,\n",
       " 3.0455260276794438,\n",
       " 19.118928909301761,\n",
       " 0.13306021690368652,\n",
       " 0.14338016510009766,\n",
       " 0.1369478702545166,\n",
       " 28.461919784545898,\n",
       " 0.13218808174133301,\n",
       " 2.6006960868835449,\n",
       " 0.11916494369506835,\n",
       " 3.6351258754730233,\n",
       " 7.6959133148193359,\n",
       " 1.028834342956543,\n",
       " 0.14957690238952634,\n",
       " 0.12140011787414552,\n",
       " 0.11815786361694335,\n",
       " 0.1100609302520752,\n",
       " 8.3339231014251709,\n",
       " 0.14627718925476074,\n",
       " 2.2079699039459237,\n",
       " 8.503633975982666,\n",
       " 1.3308429718017578,\n",
       " 0.10985851287841797,\n",
       " 1.1329808235168457,\n",
       " 0.17315340042114258,\n",
       " 0.22539234161376959,\n",
       " 0.10999345779418944,\n",
       " 0.014364004135131838,\n",
       " 0.48910093307495123,\n",
       " 1.9708521366119385,\n",
       " 0.1441810131072998,\n",
       " 2.1335961818695068,\n",
       " 1.5365371704101562,\n",
       " 0.13154721260070801,\n",
       " 5.1106472015380859,\n",
       " 0.3928520679473877,\n",
       " 0.13854312896728516,\n",
       " 1.7034811973571775,\n",
       " 16.747059106826782,\n",
       " 0.22433614730834961,\n",
       " 0.21993398666381839,\n",
       " 0.14046001434326172,\n",
       " 0.87565493583679199,\n",
       " 0.20620608329772949,\n",
       " 0.27543497085571289,\n",
       " 12.17692494392395,\n",
       " 0.12647104263305664,\n",
       " 0.11495518684387207,\n",
       " 17.805920124053952,\n",
       " 0.52758049964904785,\n",
       " 0.15807223320007324,\n",
       " 2.5053584575653081,\n",
       " 1.1652050018310549,\n",
       " 0.17300271987915039,\n",
       " 0.1794588565826416,\n",
       " 0.74289798736572266,\n",
       " 1.2688839435577393,\n",
       " 3.6707267761230469,\n",
       " 0.13683772087097168,\n",
       " 0.70705103874206543,\n",
       " 0.13699579238891602,\n",
       " 0.64898395538330078,\n",
       " 0.70913386344909668,\n",
       " 0.1320030689239502,\n",
       " 0.17416977882385254,\n",
       " 0.039869546890258789,\n",
       " 1.874783992767334,\n",
       " 0.25043511390686035,\n",
       " 4.1164128780364981,\n",
       " 0.22147822380065921,\n",
       " 0.13967514038085938,\n",
       " 0.14382290840148926,\n",
       " 0.059817075729370124,\n",
       " 18.869106769561764,\n",
       " 2.2287070751190186,\n",
       " 0.72059106826782227,\n",
       " 14.07593297958374,\n",
       " 0.11457204818725585,\n",
       " 0.049098968505859375,\n",
       " 0.69906377792358398,\n",
       " 11.72321081161499,\n",
       " 0.46376705169677729,\n",
       " 0.16641879081726074,\n",
       " 57.856354951858521,\n",
       " 0.11934590339660645,\n",
       " 0.41542601585388172,\n",
       " 0.13683676719665527,\n",
       " 0.13472390174865725,\n",
       " 0.13961529731750488,\n",
       " 1.3544530868530271,\n",
       " 0.1341712474822998,\n",
       " 0.36394500732421881,\n",
       " 0.10940194129943848,\n",
       " 0.11090469360351562,\n",
       " 0.80408310890197754,\n",
       " 1.5694503784179688,\n",
       " 0.31566905975341802,\n",
       " 1.1814498901367188,\n",
       " 5.8271617889404297,\n",
       " 0.22892594337463379,\n",
       " 0.12670278549194336,\n",
       " 0.1411740779876709,\n",
       " 0.1723625659942627,\n",
       " 0.81961989402770996,\n",
       " 1.582751989364624,\n",
       " 0.059659004211425774,\n",
       " 0.17293095588684082,\n",
       " 1.721747875213623,\n",
       " 0.1303718090057373,\n",
       " ...]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0058874368667601,\n",
       " 0.14848671317100523,\n",
       " 0.84742407798767094,\n",
       " 30.356426572799684,\n",
       " 0.13258464097976685,\n",
       " 0.42881906032562256,\n",
       " 1.241151785850525,\n",
       " 0.34961926937103271,\n",
       " 0.13258918126424152,\n",
       " 0.14935721158981324,\n",
       " 0.28399198055267333,\n",
       " 0.11978869338830311,\n",
       " 1.3519865870475769,\n",
       " 2.2422451972961426,\n",
       " 0.17293913602828978,\n",
       " 0.26573232611020403,\n",
       " 0.13716419648767378,\n",
       " 1.2899055719375609,\n",
       " 0.87579162120819087,\n",
       " 0.81189932823181155,\n",
       " 2.7756701827049257,\n",
       " 45.194205570220944,\n",
       " 0.13306645393371583,\n",
       " 0.21429554820060731,\n",
       " 0.29065177440643308,\n",
       " 0.3245049059391022,\n",
       " 0.15751095533370971,\n",
       " 0.13357597986857098,\n",
       " 0.15985664526621501,\n",
       " 0.22942783037821454,\n",
       " 0.23858470916748048,\n",
       " 44.143500947952269,\n",
       " 1.3066205501556396,\n",
       " 0.22927765051523843,\n",
       " 0.17357821464538575,\n",
       " 0.90147397518157957,\n",
       " 0.81732745170593257,\n",
       " 0.58849344253540037,\n",
       " 1.2086253881454467,\n",
       " 0.47443237304687502,\n",
       " 0.22366241931915284,\n",
       " 0.14232261180877687,\n",
       " 0.24993460178375243,\n",
       " 0.13949095240006079,\n",
       " 0.1434897154569626,\n",
       " 0.080424332618713373,\n",
       " 1.412558344999949,\n",
       " 3.8433400392532349,\n",
       " 1.0679648160934447,\n",
       " 0.86243917942047121,\n",
       " 0.53191445469856258,\n",
       " 0.12561877171198527,\n",
       " 2.7859936356544495,\n",
       " 0.1324642817179362,\n",
       " 0.082591648896535225,\n",
       " 31.82977476119995,\n",
       " 0.301516850789388,\n",
       " 2.2637915372848516,\n",
       " 0.30969836711883547,\n",
       " 2.0997011423110963,\n",
       " 0.14293083866437276,\n",
       " 0.25825006961822511,\n",
       " 0.12014253934224448,\n",
       " 1.2723089170455932,\n",
       " 0.14156856934229531,\n",
       " 9.1432217121124264,\n",
       " 3.6232098102569581,\n",
       " 1.069524383544922,\n",
       " 0.37366123199462892,\n",
       " 1.8769610166549682,\n",
       " 1.73804771900177,\n",
       " 0.61225442886352544,\n",
       " 0.15014592806498211,\n",
       " 0.92969458103179936,\n",
       " 0.13563245932261148,\n",
       " 0.1686268150806427,\n",
       " 1.0151856660842895,\n",
       " 0.11125659942626953,\n",
       " 0.11442325472831727,\n",
       " 1.2510095834732056,\n",
       " 0.17849251270294192,\n",
       " 1.2353359142939251,\n",
       " 0.1698134422302246,\n",
       " 0.11241349240144094,\n",
       " 0.035972245534261066,\n",
       " 0.48687417507171632,\n",
       " 35.196038103103646,\n",
       " 0.86857783794403076,\n",
       " 0.085988684495290124,\n",
       " 9.5074809789657593,\n",
       " 0.12376580238342286,\n",
       " 0.117856684923172,\n",
       " 0.66445345401763922,\n",
       " 0.14220385392506915,\n",
       " 0.13869277394953228,\n",
       " 0.11217413862546285,\n",
       " 0.1566982388496399,\n",
       " 4.5931427240371701,\n",
       " 0.12017255147298175,\n",
       " 0.17260211204315398,\n",
       " 204.62509348392487,\n",
       " 0.11917753338813783,\n",
       " 0.32724196116129561,\n",
       " 0.039980962497216679,\n",
       " 0.57903251647949217,\n",
       " 0.28704213301340742,\n",
       " 0.46562913060188293,\n",
       " 0.060706833518031744,\n",
       " 0.17417159113016994,\n",
       " 1.3948049497604369,\n",
       " 0.17643211285273233,\n",
       " 0.28641240596771239,\n",
       " 2.3658589124679565,\n",
       " 3.7882782220840454,\n",
       " 0.16949034849802652,\n",
       " 0.098912286758422854,\n",
       " 0.15119072221574331,\n",
       " 0.99795417785644536,\n",
       " 0.039773938607805953,\n",
       " 0.12991644382476808,\n",
       " 12.062405776977538,\n",
       " 0.12355211893717448,\n",
       " 0.14345661401748658,\n",
       " 0.17263167698622306,\n",
       " 0.17590688467025756,\n",
       " 1.875954556465149,\n",
       " 1.1043405055999755,\n",
       " 5.3613926887512209,\n",
       " 0.028818031152089439,\n",
       " 0.14856350024541221,\n",
       " 0.16080467700958251,\n",
       " 17.066611242294311,\n",
       " 0.25186777114868164,\n",
       " 0.19383052587509156,\n",
       " 17.848935675621032,\n",
       " 0.1389773678779602,\n",
       " 0.10891324301072189,\n",
       " 0.12079208427005343,\n",
       " 1.1202641487121583,\n",
       " 0.14452266454696655,\n",
       " 12.598684072494507,\n",
       " 0.22134725025721957,\n",
       " 1.2920273780822753,\n",
       " 0.12071899731953939,\n",
       " 0.45669798851013182,\n",
       " 2.2623532295227049,\n",
       " 0.014668809241718714,\n",
       " 0.35102968215942382,\n",
       " 0.17791067560513812,\n",
       " 1.1787050247192383,\n",
       " 9.7153904676437381,\n",
       " 0.21520048336549236,\n",
       " 0.10891324301072189,\n",
       " 0.017075306006840298,\n",
       " 0.17060373028119405,\n",
       " 3.8926903486251829,\n",
       " 0.11111245431941311,\n",
       " 0.13782671244851347,\n",
       " 0.14094287037849426,\n",
       " 0.82798612117767334,\n",
       " 0.12905050516128541,\n",
       " 0.1369490269731819,\n",
       " 212.19729747772217,\n",
       " 0.68949812253316245,\n",
       " 0.22710054874420166,\n",
       " 0.14136871019999186,\n",
       " 1.0325815677642822,\n",
       " 53.735920047760011,\n",
       " 0.1113137784458342,\n",
       " 2.7080272912979124,\n",
       " 0.92064328193664546,\n",
       " 0.12498219609260561,\n",
       " 0.17259150720777966,\n",
       " 0.17264059757019257,\n",
       " 2.7784757137298586,\n",
       " 0.27163658142089842,\n",
       " 0.13817691008249919,\n",
       " 12.270768189430237,\n",
       " 0.19007587432861328,\n",
       " 0.13680771509806317,\n",
       " 0.10977623203129863,\n",
       " 0.11768369572503228,\n",
       " 0.13841748584916583,\n",
       " 0.26595956802368165,\n",
       " 0.1376899250325572,\n",
       " 0.2508064270019531,\n",
       " 0.21473530769348143,\n",
       " 3.312049961090088,\n",
       " 0.11227665969303675,\n",
       " 0.65783710479736324,\n",
       " 0.17426126797993979,\n",
       " 0.15699570178985595,\n",
       " 0.1751376469930013,\n",
       " 0.28866815567016602,\n",
       " 0.23744112650553384,\n",
       " 1.036524017651876,\n",
       " 0.17739316225051879,\n",
       " 9.2155799627304074,\n",
       " 0.23601685047149656,\n",
       " 4.1359815359115597,\n",
       " 2.8802862882614138,\n",
       " 0.88788653612136836,\n",
       " 1.3306470394134522,\n",
       " 0.52620298862457271,\n",
       " 0.81163539290428166,\n",
       " 0.44156700372695923,\n",
       " 0.052524367968241378,\n",
       " 0.13970025221506754,\n",
       " 0.26983301639556884,\n",
       " 1.1831246137619018,\n",
       " 12.214825820922851,\n",
       " 0.039843130659693464,\n",
       " 2.6648189306259153,\n",
       " 68.063592362403867,\n",
       " 0.10891324301072189,\n",
       " 0.88529274463653562,\n",
       " 1.2098229646682739,\n",
       " 2.3705103826522826,\n",
       " 0.40944647789001465,\n",
       " 0.38136368989944458,\n",
       " 0.8986450731754303,\n",
       " 1.2613526105880737,\n",
       " 0.38079503774642942,\n",
       " 0.32335171699523924,\n",
       " 0.11079345835524113,\n",
       " 28.261652255058287,\n",
       " 0.11888120075066885,\n",
       " 0.041267280578613279,\n",
       " 0.17181061903635658,\n",
       " 0.16298899650573731,\n",
       " 0.16449335098266601,\n",
       " 4.2546057510375972,\n",
       " 1.3687594515936714,\n",
       " 2.7574727058410646,\n",
       " 2.0734991788864137,\n",
       " 0.13290669236864364,\n",
       " 0.16796935081481934,\n",
       " 2.3418828010559083,\n",
       " 0.19819805896643433,\n",
       " 0.14954196612040199,\n",
       " 1.2834241151809693,\n",
       " 0.49073429107666017,\n",
       " 2.1852534770965577,\n",
       " 0.14210661013921103,\n",
       " 0.094125914573669436,\n",
       " 4.3561614274978639,\n",
       " 1.8997302055358887,\n",
       " 2.2774738550186155,\n",
       " 0.13948234028286405,\n",
       " 9.8464809656143188,\n",
       " 3.3351758956909179,\n",
       " 0.1371864402294159,\n",
       " 1.4540468931198121,\n",
       " 0.09989519119262695,\n",
       " 0.13506491263707482,\n",
       " 0.86038630803426097,\n",
       " 0.76985611915588381,\n",
       " 15.583176994323731,\n",
       " 0.48036228418350219,\n",
       " 0.058971311648686728,\n",
       " 0.57648613452911379,\n",
       " 0.12548389434814453,\n",
       " 0.11424837986628215,\n",
       " 0.17695604165395101,\n",
       " 1.4120014607906342,\n",
       " 0.30329744021097821,\n",
       " 0.22961168289184569,\n",
       " 0.13699644009272255,\n",
       " 0.68107401132583623,\n",
       " 0.13377544482549031,\n",
       " 2.123505640029907,\n",
       " 2.1149176120758058,\n",
       " 0.17349677585420153,\n",
       " 0.16629909873008727,\n",
       " 0.23924225568771362,\n",
       " 1.2556455373764037,\n",
       " 7.6045106410980221,\n",
       " 0.13038508892059325,\n",
       " 2.9378095626831056,\n",
       " 0.16596059884343828,\n",
       " 0.2158758481343587,\n",
       " 1.7328622579574584,\n",
       " 0.029518135388692225,\n",
       " 0.17380208725020999,\n",
       " 0.20108309984207154,\n",
       " 2.382059860229492,\n",
       " 1.2206139087677002,\n",
       " 0.12298077027002971,\n",
       " 0.15272791385650636,\n",
       " 0.22823629379272456,\n",
       " 0.13919444084167482,\n",
       " 4.6992468357086183,\n",
       " 0.12433364192644754,\n",
       " 0.12299628257751465,\n",
       " 0.47343862056732178,\n",
       " 0.048300023873647055,\n",
       " 0.28498966693878175,\n",
       " 0.90251286029815669,\n",
       " 0.2979169599215189,\n",
       " 0.34168408711751302,\n",
       " 0.13838109970092774,\n",
       " 0.77869875431060787,\n",
       " 0.10988480827709168,\n",
       " 0.13050817449887592,\n",
       " 3.6135563611984254,\n",
       " 0.081547676182928547,\n",
       " 1.0121840238571167,\n",
       " 4.261927604675293,\n",
       " 0.12420842647552491,\n",
       " 0.64724702835083003,\n",
       " 1.2427480118615288,\n",
       " 3.4326114892959594,\n",
       " 0.77615615924199433,\n",
       " 0.17241254776924642,\n",
       " 0.38975961208343507,\n",
       " 1.9886956453323363,\n",
       " 0.44499635696411133,\n",
       " 0.59251716136932375,\n",
       " 0.17709606488545734,\n",
       " 14.141746878623962,\n",
       " 1.9894765377044679,\n",
       " 0.038209523889753551,\n",
       " 2.0869236230850223,\n",
       " 1.0671041250228881,\n",
       " 0.23049744963645935,\n",
       " 0.26002612113952639,\n",
       " 0.074543313185373938,\n",
       " 0.68089204271634418,\n",
       " 0.17787248889605203,\n",
       " 0.14217851658662159,\n",
       " 0.75739293098449711,\n",
       " 0.1382631344454629,\n",
       " 0.13029880523681642,\n",
       " 0.29781172275543211,\n",
       " 3.3555714368820189,\n",
       " 7.1606889009475712,\n",
       " 0.13716597922487578,\n",
       " 0.13700462460517882,\n",
       " 0.16080300013224286,\n",
       " 0.9173553943634033,\n",
       " 0.50653569698333745,\n",
       " 0.74513645172119136,\n",
       " 0.11379803845376679,\n",
       " 0.13234626531600951,\n",
       " 0.13830423375113826,\n",
       " 0.13544788360595703,\n",
       " 0.1791010618209839,\n",
       " 1.7437688827514648,\n",
       " 0.1985340654850006,\n",
       " 1.3155158758163452,\n",
       " 0.21894813219706216,\n",
       " 4.216700100898743,\n",
       " 0.17404629256990223,\n",
       " 0.12506245904498631,\n",
       " 0.15895350319998605,\n",
       " 0.84101755619049068,\n",
       " 0.1411572535832723,\n",
       " 8.3361054182052605,\n",
       " 0.12875665227572125,\n",
       " 0.30114402770996096,\n",
       " 0.10948316579764172,\n",
       " 0.45598560333251958,\n",
       " 2.9656785249710085,\n",
       " 1.5634748935699463,\n",
       " 1.3338725566864014,\n",
       " 0.30944375991821288,\n",
       " 5.0979093313217163,\n",
       " 0.13258039610726494,\n",
       " 1.3753448486328126,\n",
       " 0.11709454854329426,\n",
       " 0.47635724544525149,\n",
       " 0.13730761477971137,\n",
       " 1.212139892578125,\n",
       " 0.32582848072052001,\n",
       " 0.99192945957183842,\n",
       " 0.24517976284027099,\n",
       " 0.14080174922943117,\n",
       " 0.3786227345466614,\n",
       " 0.044499904343060087,\n",
       " 0.14057486409232728,\n",
       " 0.12673120896021525,\n",
       " 0.012684642190024967,\n",
       " 0.13690275103130992,\n",
       " 0.16928170919418334,\n",
       " 3.3247706651687623,\n",
       " 0.82002575397491451,\n",
       " 1.3762814164161683,\n",
       " 0.37561988830566406,\n",
       " 0.12291350682576496,\n",
       " 7.5330953836441044,\n",
       " 3.3827990770339964,\n",
       " 2.2061201910177863,\n",
       " 0.24576213359832763,\n",
       " 0.13657126506169637,\n",
       " 0.13880467812220254,\n",
       " 0.21574732065200805,\n",
       " 0.098580288887023929,\n",
       " 0.13671497469856625,\n",
       " 0.51025147438049312,\n",
       " 0.57132601737976074,\n",
       " 0.17306207255883649,\n",
       " 1.7040090481440224,\n",
       " 1.6971639553705853,\n",
       " 0.34964785575866697,\n",
       " 0.11559344768524168,\n",
       " 2.6968611478805542,\n",
       " 6.9298519849777218,\n",
       " 1.545686388015747,\n",
       " 0.13050551414489747,\n",
       " 7.3747957229614256,\n",
       " 0.17927765846252441,\n",
       " 0.17288333125186689,\n",
       " 0.17320418357849121,\n",
       " 1.5290544271469115,\n",
       " 1.9861682653427124,\n",
       " 0.15034986495971681,\n",
       " 1.1981045722961425,\n",
       " 0.75447995662689205,\n",
       " 0.11848897854487102,\n",
       " 2.3758090925216675,\n",
       " 0.19881972074508669,\n",
       " 0.16808506382836236,\n",
       " 0.35784597396850587,\n",
       " 0.20256770451863604,\n",
       " 0.67747254371643062,\n",
       " 2.3905963182449339,\n",
       " 4.144331693649292,\n",
       " 0.15305219093958539,\n",
       " 0.02958922872908612,\n",
       " 0.0094289120009669655,\n",
       " 1.631985354423523,\n",
       " 0.11241945226987202,\n",
       " 0.22460851510365804,\n",
       " 0.13969097364516483,\n",
       " 1.6290990511576335,\n",
       " 0.2409121910730998,\n",
       " 0.13767283314372553,\n",
       " 2.6836305141448973,\n",
       " 0.14183700084686279,\n",
       " 1.4742272317409515,\n",
       " 0.15755952994028727,\n",
       " 0.45332357883453367,\n",
       " 0.1176917584737142,\n",
       " 3.9572584867477416,\n",
       " 0.13927787674797903,\n",
       " 4.2165321826934816,\n",
       " 0.91950943470001223,\n",
       " 2.2729708433151243,\n",
       " 3.5563289403915403,\n",
       " 0.17391527891159059,\n",
       " 2.7815365076065062,\n",
       " 0.16869956811269124,\n",
       " 0.60069596767425537,\n",
       " 52.094446873664857,\n",
       " 1.1825594902038574,\n",
       " 0.14682574272155763,\n",
       " 0.14826670527458191,\n",
       " 20.308962464332581,\n",
       " 0.11920175909996031,\n",
       " 0.51677296161651609,\n",
       " 2.367473530769348,\n",
       " 0.95793118476867678,\n",
       " 0.9782691955566406,\n",
       " 10.110715889930725,\n",
       " 0.17593715985616049,\n",
       " 0.12966975490252178,\n",
       " 0.15580650568008422,\n",
       " 38.04988076686859,\n",
       " 2.1467900753021243,\n",
       " 0.68830015659332278,\n",
       " 0.52909734249114992,\n",
       " 0.12077905436356862,\n",
       " 7.8346666336059574,\n",
       " 4.7627797412872308,\n",
       " 3.8690705299377441,\n",
       " 9.9595374107360843,\n",
       " 1.1764894723892212,\n",
       " 1.381649374961853,\n",
       " 0.11810479164123536,\n",
       " 0.18355696201324462,\n",
       " 0.65598447322845455,\n",
       " 2.098939561843872,\n",
       " 0.67816674908002228,\n",
       " 1.4552985445658366,\n",
       " 1.7537004232406617,\n",
       " 0.12132819652557374,\n",
       " 7.7529045820236204,\n",
       " 3.3987029075622557,\n",
       " 1.9166244983673095,\n",
       " 0.16684626976648964,\n",
       " 0.14316401481628419,\n",
       " 0.14186204978397915,\n",
       " 1.1649665832519531,\n",
       " 0.13611969323385328,\n",
       " 1.4198394060134887,\n",
       " 2.749132251739502,\n",
       " 0.041542987028757736,\n",
       " 0.12218102784383864,\n",
       " 0.54316349029541011,\n",
       " 0.21885077953338622,\n",
       " 7.0529639959335331,\n",
       " 0.13964182615280152,\n",
       " 0.17955689430236815,\n",
       " 0.20849029223124188,\n",
       " 0.30747213999430334,\n",
       " 1.3494700908660888,\n",
       " 1.4718276262283325,\n",
       " 2.4397672057151794,\n",
       " 1.2149341344833373,\n",
       " 2.1408988654613497,\n",
       " 0.17239213656811486,\n",
       " 5.6165735721588135,\n",
       " 1.6055968284606934,\n",
       " 10.142833852767945,\n",
       " 1.4684890747070312,\n",
       " 0.13050787925720214,\n",
       " 3.5781602382659914,\n",
       " 0.11868271231651306,\n",
       " 0.29259561300277709,\n",
       " 0.39304943084716798,\n",
       " 0.11592366894086201,\n",
       " 0.15871472358703614,\n",
       " 0.090097828706105554,\n",
       " 4.1986656188964844,\n",
       " 3.0427805185317993,\n",
       " 0.47002626657485963,\n",
       " 0.13574228684107462,\n",
       " 0.16622815926869711,\n",
       " 0.34418189525604248,\n",
       " 2.2057313124338784,\n",
       " 0.1289618174235026,\n",
       " 0.25360172748565674,\n",
       " 0.23895986676216124,\n",
       " 1.9685658931732177,\n",
       " 1.3878067493438722,\n",
       " 0.13830414622549025,\n",
       " 2.7748503923416137,\n",
       " 0.30684206883112586,\n",
       " 0.1294689671198527,\n",
       " 30.887801289558411,\n",
       " 0.97083911895751951,\n",
       " 0.81226618289947505,\n",
       " 2.8790176391601561,\n",
       " 0.82287914752960201,\n",
       " 0.15916592280069985,\n",
       " 0.26232995986938479,\n",
       " 1.8187385320663452,\n",
       " 1.2903280019760133,\n",
       " 1.3260999917984009,\n",
       " 0.16419336795806885,\n",
       " 0.31783922513326013,\n",
       " 2.7756910800933836,\n",
       " 0.42537587165832519,\n",
       " 3.6175806283950807,\n",
       " 1.1159199953079224,\n",
       " 4.1133749008178713,\n",
       " 3.1656540632247925,\n",
       " 0.30754523277282714,\n",
       " 0.72391135692596431,\n",
       " 9.0364240407943726,\n",
       " 0.24777615070343018,\n",
       " 0.10891324301072189,\n",
       " 0.17087744871775307,\n",
       " 0.12403513193130493,\n",
       " 1.242210292816162,\n",
       " 2.2539381186167402,\n",
       " 0.14507328033447267,\n",
       " 0.89362649520238246,\n",
       " 0.13105311592419941,\n",
       " 0.86420032978057859,\n",
       " 0.028678961594899494,\n",
       " 5.7134831666946413,\n",
       " 0.34439630508422853,\n",
       " 0.65618898868560793,\n",
       " 0.180925714969635,\n",
       " 0.37623259067535397,\n",
       " 0.050862876574198412,\n",
       " 0.13290015816688538,\n",
       " 0.17248656706376508,\n",
       " 9.6811564683914177,\n",
       " 0.12576880216598513,\n",
       " 9.862538909912109,\n",
       " 15.702495336532593,\n",
       " 0.12748038768768311,\n",
       " 0.11994370539983112,\n",
       " 8.0194415092468265,\n",
       " 0.13564109484354656,\n",
       " 0.70827534198760989,\n",
       " 1.367993950843811,\n",
       " 0.32760109106699631,\n",
       " 12.141588377952576,\n",
       " 0.1377571520544853,\n",
       " 0.02958922872908612,\n",
       " 1.2987187314033508,\n",
       " 6.0096789956092831,\n",
       " 0.12910127679506939,\n",
       " 0.10891324301072189,\n",
       " 0.52433021068572994,\n",
       " 4.1664622306823729,\n",
       " 0.23285212516784667,\n",
       " 1.2305758953094483,\n",
       " 0.10891324301072189,\n",
       " 3.8963612794876097,\n",
       " 0.52394545078277588,\n",
       " 0.31232467492421467,\n",
       " 0.40512063503265383,\n",
       " 0.16823561588923136,\n",
       " 0.173472410970264,\n",
       " 0.15428709983825684,\n",
       " 0.11339350757144746,\n",
       " 0.21875102519989015,\n",
       " 0.28310660521189374,\n",
       " 0.1113123279840178,\n",
       " 5.1460204124450684,\n",
       " 6.3837975740432737,\n",
       " 0.69036712646484377,\n",
       " 0.12673479557037354,\n",
       " 0.21931939125061034,\n",
       " 1.4347195863723754,\n",
       " 0.17047834396362305,\n",
       " 0.95247918367385864,\n",
       " 2.9405117511749266,\n",
       " 3.5812856674194338,\n",
       " 0.14426609675089516,\n",
       " 0.11566211836678642,\n",
       " 0.17139999667803446,\n",
       " 0.1432923430488223,\n",
       " 0.23545512199401858,\n",
       " 0.12834842403729757,\n",
       " 0.23425436019897461,\n",
       " 2.139484930038452,\n",
       " 0.42658162911732989,\n",
       " 1.7241570790608722,\n",
       " 0.76000137329101558,\n",
       " 1.0532124360402426,\n",
       " 0.15351977348327636,\n",
       " 0.7593640804290771,\n",
       " 0.1333903888861338,\n",
       " 1.5824016094207765,\n",
       " 0.3937580347061157,\n",
       " 0.17152751684188844,\n",
       " 0.14766977628072103,\n",
       " 0.36835758686065673,\n",
       " 0.10891324301072189,\n",
       " 16.142723846435548,\n",
       " 0.17447729110717775,\n",
       " 25.462366533279418,\n",
       " 7.5343820095062259,\n",
       " 0.18588689168294273,\n",
       " 0.23737374146779375,\n",
       " 0.28627204895019531,\n",
       " 0.13286654194196065,\n",
       " 1.8215856313705445,\n",
       " 0.23748081445693972,\n",
       " 0.136066464583079,\n",
       " 0.11012086250293027,\n",
       " 1.0077685117721558,\n",
       " 0.90191909472147636,\n",
       " 1.4234718418121337,\n",
       " 2.3701513290405272,\n",
       " 0.17045747041702269,\n",
       " 3.2189375162124634,\n",
       " 3.4503541946411134,\n",
       " 0.090267380078633636,\n",
       " 0.13789239675832718,\n",
       " 19.646995091438292,\n",
       " 0.15190585374832152,\n",
       " 0.13684891859690348,\n",
       " 0.64732200503349302,\n",
       " 0.30588929653167723,\n",
       " 0.43183245658874514,\n",
       " 1.3385555028915406,\n",
       " 0.44283070564270022,\n",
       " 0.13692602224584796,\n",
       " 0.15217804463136766,\n",
       " 0.9573680798212687,\n",
       " 0.50126988093058267,\n",
       " 0.078867974669280444,\n",
       " 0.78595747947692873,\n",
       " 0.039768450808161486,\n",
       " 0.10490586757659912,\n",
       " 1.2505060195922852,\n",
       " 1.1813329458236694,\n",
       " 0.47865197658538816,\n",
       " 0.11466116428375243,\n",
       " 0.39664998054504397,\n",
       " 0.14347348610560098,\n",
       " 0.11843042373657227,\n",
       " 0.11064840257167816,\n",
       " 0.12180262009302775,\n",
       " 2.7753025770187376,\n",
       " 0.16600253582000732,\n",
       " 0.16324163436889649,\n",
       " 0.17882470030051012,\n",
       " 0.11117018333107227,\n",
       " 0.8036786794662476,\n",
       " 0.13820595936766708,\n",
       " 0.65193266868591304,\n",
       " 0.12261013984680176,\n",
       " 1.1050933122634887,\n",
       " 0.17265367904743115,\n",
       " 0.12184457778930664,\n",
       " 0.13713720185416084,\n",
       " 0.13744131752422878,\n",
       " 0.13126083050455367,\n",
       " 2.8759408791859946,\n",
       " 1.5202886581420898,\n",
       " 0.041302702457013764,\n",
       " 0.17461846470316766,\n",
       " 0.13629022598266602,\n",
       " 2.5206636905670168,\n",
       " 0.13999459266662598,\n",
       " 0.17012138287226358,\n",
       " 0.12846249898274739,\n",
       " 0.12041128079096478,\n",
       " 0.17159111658732096,\n",
       " 1.7334844589233398,\n",
       " 0.35306358337402344,\n",
       " 0.27426989674568175,\n",
       " 1.0970052480697632,\n",
       " 0.17312867244084676,\n",
       " 0.31108127435048422,\n",
       " 0.11152250925699872,\n",
       " 0.048329574267069506,\n",
       " 0.30721440553665158,\n",
       " 0.11898889938990276,\n",
       " 2.412029814720154,\n",
       " 0.30088122487068175,\n",
       " 0.117894606590271,\n",
       " 0.45184247493743895,\n",
       " 0.13839203119277954,\n",
       " 0.011075152730384069,\n",
       " 4.5229269504547123,\n",
       " 0.21593792438507081,\n",
       " 0.29819077253341675,\n",
       " 34.76359241008759,\n",
       " 0.31936657428741455,\n",
       " 0.17432679196198783,\n",
       " 0.10891324301072189,\n",
       " 1.0020426750183105,\n",
       " 0.13925880273373314,\n",
       " 0.13049939208560518,\n",
       " 1.3728553831577301,\n",
       " 0.081293132163229448,\n",
       " 0.25362209479014081,\n",
       " 0.11117961405288605,\n",
       " 16.405177235603333,\n",
       " 0.75742870966593423,\n",
       " 0.11829657316207884,\n",
       " 0.11870346466700236,\n",
       " 0.78277823925018308,\n",
       " 2.0605212926864622,\n",
       " 0.17754570179515416,\n",
       " 0.46532930334409084,\n",
       " 0.11172727942466736,\n",
       " 2.7078610181808473,\n",
       " 1.8514994621276855,\n",
       " 0.76407764979771209,\n",
       " 2.1655837535858153,\n",
       " 15.257564473152161,\n",
       " 0.51266560554504392,\n",
       " 7.170300388336182,\n",
       " 0.17906164328257243,\n",
       " 5.4695986747741703,\n",
       " 0.3420437812805176,\n",
       " 0.65782318115234373,\n",
       " 0.88020524978637693,\n",
       " 1.0457776880264282,\n",
       " 0.13438006838162739,\n",
       " 0.17274536606156346,\n",
       " 0.23979127407073975,\n",
       " 0.14328457105727421,\n",
       " 1.720611349741618,\n",
       " 0.16791011095046998,\n",
       " 0.9246041059494019,\n",
       " 0.52880594730377195,\n",
       " 0.17259591420491538,\n",
       " 0.17158774137496949,\n",
       " 0.31326243877410886,\n",
       " 1.29274582862854,\n",
       " 4.6395373106002804,\n",
       " 0.15040736198425292,\n",
       " 0.14543388287226358,\n",
       " 0.14220436811447143,\n",
       " 0.46848149299621583,\n",
       " 2.1711107015609743,\n",
       " 8.2182845592498772,\n",
       " 20.277920341491701,\n",
       " 0.0094289120009669655,\n",
       " 3.9423068761825562,\n",
       " 1.3649941444396974,\n",
       " 1.5629660367965699,\n",
       " 1.5870118498802186,\n",
       " 0.22225635846455893,\n",
       " 0.12257661382357279,\n",
       " 1.3160329043865204,\n",
       " 0.22579726696014407,\n",
       " 0.12276130119959514,\n",
       " 1.3345615148544312,\n",
       " 0.16633885025978087,\n",
       " 2.6249531924724581,\n",
       " 0.17529985109965007,\n",
       " 0.46765394210815431,\n",
       " 0.25968904097874962,\n",
       " 0.62399861812591551,\n",
       " 0.13759167739323208,\n",
       " 0.13317253589630126,\n",
       " 0.44315242767333984,\n",
       " 0.13793086160686696,\n",
       " 4.7452096223831175,\n",
       " 0.13961980115799674,\n",
       " 0.1409178853034973,\n",
       " 0.17423792712616198,\n",
       " 0.41130924224853516,\n",
       " 1.2699191808700561,\n",
       " 0.039768450808161486,\n",
       " 6.8367966651916507,\n",
       " 0.14339822292327883,\n",
       " 11.88691475391388,\n",
       " 0.35226016044616698,\n",
       " 2.6891796350479127,\n",
       " 1.3662267208099366,\n",
       " 1.5551008780797324,\n",
       " 1.97652268409729,\n",
       " 3.6829365253448487,\n",
       " 0.13839146931966145,\n",
       " 0.18938416639963787,\n",
       " 0.27566577196121217,\n",
       " 0.13020167135056995,\n",
       " 0.19073454856872557,\n",
       " 0.05637971758842468,\n",
       " 0.16504003365834552,\n",
       " 0.20203078985214235,\n",
       " 0.17128976583480834,\n",
       " 6.5765086889266966,\n",
       " 0.50971581935882571,\n",
       " 0.11342296322186787,\n",
       " 1.9151651859283447,\n",
       " 0.40927290916442871,\n",
       " 4.3402514219284054,\n",
       " 0.43778045177459718,\n",
       " 0.33044700622558593,\n",
       " 0.14170281887054442,\n",
       " 0.13870467196325628,\n",
       " 0.49364315271377562,\n",
       " 1.3369162321090697,\n",
       " 0.72955985069274898,\n",
       " 0.60265934467315674,\n",
       " 0.50801155567169187,\n",
       " 0.43540916442871092,\n",
       " 0.37231212854385376,\n",
       " 28.700051975250243,\n",
       " 1.0412526607513428,\n",
       " 0.28163986365000404,\n",
       " 0.66218457221984861,\n",
       " 0.19716176986694336,\n",
       " 0.87999734878540037,\n",
       " 0.078025299739214321,\n",
       " 0.13805071713432432,\n",
       " 0.65568897724151609,\n",
       " 0.13977159102757769,\n",
       " 6.4979187965393068,\n",
       " 0.10972809746611749,\n",
       " 0.60918536186218264,\n",
       " 0.0428685170532477,\n",
       " 0.11158974191831102,\n",
       " 2.991883397102356,\n",
       " 0.11119288404782612,\n",
       " 7.6623272418975832,\n",
       " 0.14521225293477377,\n",
       " 0.13611773014068601,\n",
       " 0.1641213634279039,\n",
       " 0.1430019348859787,\n",
       " 0.77095010280609133,\n",
       " 0.14344087441762288,\n",
       " 0.17209705379274154,\n",
       " 5.6429747819900511,\n",
       " 3.8321995735168457,\n",
       " 0.23981984456380206,\n",
       " 2.4256109237670898,\n",
       " 0.14617154359817505,\n",
       " 0.12989266435305277,\n",
       " 26.147851347923279,\n",
       " 0.19103178580602012,\n",
       " 0.13001062870025634,\n",
       " 2.3589648485183714,\n",
       " 0.13109342654546102,\n",
       " 0.12087979714075725,\n",
       " 0.15076418320337931,\n",
       " 1.8075018882751466,\n",
       " 3.6960857629776003,\n",
       " 0.16750722527503967,\n",
       " 2.9536630868911744,\n",
       " 15.894688701629638,\n",
       " 0.13333886623382568,\n",
       " 0.15651577313741047,\n",
       " 0.13480342427889508,\n",
       " 28.962198662757874,\n",
       " 0.13624176740646363,\n",
       " 2.6020349264144897,\n",
       " 0.12091155704997836,\n",
       " 3.8332046985626222,\n",
       " 7.5708379268646242,\n",
       " 1.0596362352371216,\n",
       " 0.14526435690266745,\n",
       " 0.11937316338221231,\n",
       " 0.11831840475400288,\n",
       " 0.10960007915076668,\n",
       " 6.8273223876953129,\n",
       " 0.14937351942062377,\n",
       " 2.5293068170547484,\n",
       " 8.3029282999038703,\n",
       " 1.2502231995264688,\n",
       " 0.11202031712963681,\n",
       " 0.9048509359359741,\n",
       " 0.17329299052000602,\n",
       " 0.26903970241546632,\n",
       " 0.11024794960432102,\n",
       " 0.01432372247916755,\n",
       " 0.5003612279891968,\n",
       " 2.386655640602112,\n",
       " 0.14216308593749999,\n",
       " 2.0120414972305296,\n",
       " 1.3407602787017823,\n",
       " 0.1308377782503764,\n",
       " 2.3345929384231567,\n",
       " 0.35569911797841386,\n",
       " 0.13818817536036171,\n",
       " 1.7046972274780274,\n",
       " 15.511705684661866,\n",
       " 0.23516345818837486,\n",
       " 0.22210550308227539,\n",
       " 0.14063344677289327,\n",
       " 0.97015686035156246,\n",
       " 0.21266157627105714,\n",
       " 0.26909095048904419,\n",
       " 12.560598659515382,\n",
       " 0.12427979442808364,\n",
       " 0.1147809127966563,\n",
       " 20.824727797508238,\n",
       " 0.53468752503395078,\n",
       " 0.15303881565729777,\n",
       " 2.4716924905776976,\n",
       " 1.1709043407440185,\n",
       " 0.17311115596029492,\n",
       " 0.17316401799519859,\n",
       " 0.80991324186325075,\n",
       " 0.75120799541473393,\n",
       " 3.7219208478927612,\n",
       " 0.13708106287815686,\n",
       " 0.89212713241577146,\n",
       " 0.13863641699155171,\n",
       " 0.8830246210098267,\n",
       " 0.7298613309860229,\n",
       " 0.13808510303497315,\n",
       " 0.17425121731228299,\n",
       " 0.039650288510220968,\n",
       " 1.9973309755325317,\n",
       " 0.14180818796157837,\n",
       " 4.2145224094390867,\n",
       " 0.25886394977569582,\n",
       " 0.13919440848486764,\n",
       " 0.13958010196685791,\n",
       " 0.055894788901011148,\n",
       " 18.801499843597412,\n",
       " 1.8263587951660156,\n",
       " 0.85012757778167725,\n",
       " 9.5808262586593624,\n",
       " 0.13264680107434593,\n",
       " 0.04165122111638387,\n",
       " 0.80103271007537846,\n",
       " 10.100853323936462,\n",
       " 0.51854331493377681,\n",
       " 0.16595420837402344,\n",
       " 61.078008842468265,\n",
       " 0.12155389746030172,\n",
       " 0.3464091420173645,\n",
       " 0.13695982772934626,\n",
       " 0.13826033115386963,\n",
       " 0.13945618653882288,\n",
       " 1.2981074810028077,\n",
       " 0.13215616146723427,\n",
       " 0.40308570861816406,\n",
       " 0.10948327146992742,\n",
       " 0.11226809024810791,\n",
       " 0.85081362724304199,\n",
       " 1.5846258163452149,\n",
       " 0.33121641079584763,\n",
       " 1.1313807725906373,\n",
       " 5.9439894676208498,\n",
       " 0.22916377385457359,\n",
       " 0.12604283491770427,\n",
       " 0.1377249342486972,\n",
       " 0.1731846790894484,\n",
       " 0.87877748012542722,\n",
       " 1.6953017473220826,\n",
       " 0.059110585848490396,\n",
       " 0.17344010065644333,\n",
       " 0.82471015453338625,\n",
       " 0.12410562038421631,\n",
       " ...]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384408.57927002618"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_algo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('RandomForestRegressor_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Desktop/scikest\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/scikest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13893, 19)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df_train[t.params['other_params'] + list(t.params['external_params'].keys()) + list(t.params['internal_params'].keys())]\n",
    "outputs = df_train[['output']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2096.488789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9847</th>\n",
       "      <td>7814.358503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>35978.942474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>4318.426775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            output\n",
       "221    2096.488789\n",
       "9847   7814.358503\n",
       "117   35978.942474\n",
       "345    4318.426775"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[outputs.output>1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>total_memory</th>\n",
       "      <th>available_memory</th>\n",
       "      <th>num_cpu</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>num_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_weight_fraction_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_impurity_split</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>oob_score</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3043074048</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35978.942474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  total_memory  available_memory  num_cpu  num_rows  \\\n",
       "117         117   17179869184        3043074048        8  10000000   \n",
       "\n",
       "     num_features  n_estimators  max_depth  min_samples_split  \\\n",
       "117            10            40         30                 10   \n",
       "\n",
       "     min_samples_leaf  min_weight_fraction_leaf max_features  max_leaf_nodes  \\\n",
       "117               1.0                      0.25           10               2   \n",
       "\n",
       "     min_impurity_decrease  min_impurity_split  bootstrap  oob_score  n_jobs  \\\n",
       "117                      5                 1.0       True      False     8.0   \n",
       "\n",
       "           output  \n",
       "117  35978.942474  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.output>35000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>total_memory</th>\n",
       "      <th>available_memory</th>\n",
       "      <th>num_cpu</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>num_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_weight_fraction_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_impurity_split</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>oob_score</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7036096512</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.639697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6761955328</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.990652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6267830272</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.976542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5694320640</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.501601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5679689728</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.001720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5683245056</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.732058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4346757120</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4284518400</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.959365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4335284224</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.449856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4384038912</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.359353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4358402048</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.446605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3759247360</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.755734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3329490944</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.696814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7016251392</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.661148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6637260800</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.485538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5078642688</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.698586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4386443264</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.270306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4390096896</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.133462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3443556352</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.416343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6981324800</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.100406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5074989056</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.148093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6246006784</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.530122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>4871557120</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.347198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6153269248</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.399691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3435200512</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.410973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>3112235008</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.491263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7535542272</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.912246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7481905152</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.150266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7407673344</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.101918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6718763008</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.191413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7027191808</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.071397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6996914176</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.270467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6996914176</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.657162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7017476096</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.412782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>7180689408</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.915857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6960017408</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.732304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6628024320</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.021583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6610661376</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.364841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6535221248</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.543236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6508658688</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.516718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6569197568</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6600826880</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.369132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6650564608</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.343565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6649995264</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.357473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6650638336</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.471489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6990123008</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.380466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6690574336</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.389828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6681247744</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.184362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6717546496</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.736137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6673174528</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.488650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6520762368</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.283912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6355615744</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.422510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6003351552</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.163062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5824782336</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.799652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>5414928384</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.575576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>8404090880</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.503634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6950543360</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.820043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6216048640</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.988748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>10592800768</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.003482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>6755418112</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.292340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  total_memory  available_memory  num_cpu  num_rows  \\\n",
       "0             0   17179869184        7036096512        8   5000000   \n",
       "1             1   17179869184        6761955328        8   5000000   \n",
       "2             2   17179869184        6267830272        8   5000000   \n",
       "3             3   17179869184        5694320640        8   5000000   \n",
       "4             4   17179869184        5679689728        8   5000000   \n",
       "5             5   17179869184        5683245056        8   5000000   \n",
       "6             6   17179869184        4346757120        8   5000000   \n",
       "7             7   17179869184        4284518400        8   5000000   \n",
       "8             8   17179869184        4335284224        8   5000000   \n",
       "9             9   17179869184        4384038912        8   5000000   \n",
       "10           10   17179869184        4358402048        8   5000000   \n",
       "11           11   17179869184        3759247360        8   5000000   \n",
       "12           12   17179869184        3329490944        8   5000000   \n",
       "13           13   17179869184        7016251392        8   5000000   \n",
       "14           14   17179869184        6637260800        8   5000000   \n",
       "15           15   17179869184        5078642688        8   5000000   \n",
       "16           16   17179869184        4386443264        8   5000000   \n",
       "17           17   17179869184        4390096896        8   5000000   \n",
       "18           18   17179869184        3443556352        8   5000000   \n",
       "19           19   17179869184        6981324800        8   5000000   \n",
       "20           20   17179869184        5074989056        8   5000000   \n",
       "21           21   17179869184        6246006784        8   5000000   \n",
       "22           22   17179869184        4871557120        8   5000000   \n",
       "23           23   17179869184        6153269248        8   5000000   \n",
       "24           24   17179869184        3435200512        8   5000000   \n",
       "25           25   17179869184        3112235008        8   5000000   \n",
       "26           26   17179869184        7535542272        8   5000000   \n",
       "27           27   17179869184        7481905152        8   5000000   \n",
       "28           28   17179869184        7407673344        8   5000000   \n",
       "29           29   17179869184        6718763008        8   5000000   \n",
       "..          ...           ...               ...      ...       ...   \n",
       "88           88   17179869184        7027191808        8   1000000   \n",
       "89           89   17179869184        6996914176        8   1000000   \n",
       "90           90   17179869184        6996914176        8   1000000   \n",
       "91           91   17179869184        7017476096        8   1000000   \n",
       "92           92   17179869184        7180689408        8   1000000   \n",
       "93           93   17179869184        6960017408        8   1000000   \n",
       "94           94   17179869184        6628024320        8   1000000   \n",
       "95           95   17179869184        6610661376        8   1000000   \n",
       "96           96   17179869184        6535221248        8   1000000   \n",
       "97           97   17179869184        6508658688        8   1000000   \n",
       "98           98   17179869184        6569197568        8   1000000   \n",
       "99           99   17179869184        6600826880        8   1000000   \n",
       "100         100   17179869184        6650564608        8   1000000   \n",
       "101         101   17179869184        6649995264        8   1000000   \n",
       "102         102   17179869184        6650638336        8   1000000   \n",
       "103         103   17179869184        6990123008        8   1000000   \n",
       "104         104   17179869184        6690574336        8   1000000   \n",
       "105         105   17179869184        6681247744        8   1000000   \n",
       "106         106   17179869184        6717546496        8   1000000   \n",
       "107         107   17179869184        6673174528        8   1000000   \n",
       "108         108   17179869184        6520762368        8   1000000   \n",
       "109         109   17179869184        6355615744        8   1000000   \n",
       "110         110   17179869184        6003351552        8   1000000   \n",
       "111         111   17179869184        5824782336        8   1000000   \n",
       "112         112   17179869184        5414928384        8   1000000   \n",
       "113         113   17179869184        8404090880        8  10000000   \n",
       "114         114   17179869184        6950543360        8  10000000   \n",
       "115         115   17179869184        6216048640        8  10000000   \n",
       "116         116   17179869184       10592800768        8  10000000   \n",
       "117         117   17179869184        6755418112        8  10000000   \n",
       "\n",
       "     num_features  n_estimators  max_depth  min_samples_split  \\\n",
       "0              50            10         10                  2   \n",
       "1              50            10         10                  2   \n",
       "2              50            10         10                  2   \n",
       "3              50            10         10                  2   \n",
       "4              50            10         50                  4   \n",
       "5              50            10         50                 10   \n",
       "6              50            10        100                  2   \n",
       "7              50            10        100                  4   \n",
       "8              50            50         10                  2   \n",
       "9              50            50         10                 10   \n",
       "10             50            50         50                  4   \n",
       "11             50            50         50                 10   \n",
       "12             50            50        100                  2   \n",
       "13             50            50        100                  4   \n",
       "14             50            50        100                 10   \n",
       "15             50           100         10                  2   \n",
       "16             50           100         10                  4   \n",
       "17             50           100         10                 10   \n",
       "18             50           100         50                  4   \n",
       "19             50           100         50                 10   \n",
       "20             50           100         50                 10   \n",
       "21             50           100         50                 10   \n",
       "22             50           100        100                  2   \n",
       "23             50           100        100                  4   \n",
       "24             25            10         50                  4   \n",
       "25             25            10        100                 10   \n",
       "26             25            50         10                 10   \n",
       "27             25            50         10                 10   \n",
       "28             25            50         50                  4   \n",
       "29             25            50         50                  4   \n",
       "..            ...           ...        ...                ...   \n",
       "88             50            50         10                 10   \n",
       "89             50            50         50                 10   \n",
       "90             50            50        100                  2   \n",
       "91             50           100         10                  2   \n",
       "92             50           100         10                 10   \n",
       "93             50           100         50                  2   \n",
       "94             50           100         50                 10   \n",
       "95             50           100         50                 10   \n",
       "96             50           100         50                 10   \n",
       "97             50           100        100                  4   \n",
       "98             25            10         10                  2   \n",
       "99             25            10         10                 10   \n",
       "100            25            10         50                  4   \n",
       "101            25            10         50                  4   \n",
       "102            25            10         50                 10   \n",
       "103            25            10        100                  4   \n",
       "104            25            10        100                 10   \n",
       "105            25            50         10                  4   \n",
       "106            25            50         50                  2   \n",
       "107            25            50         50                 10   \n",
       "108            25            50        100                  2   \n",
       "109            25           100         50                  4   \n",
       "110            25           100        100                  2   \n",
       "111            25           100        100                  4   \n",
       "112            25           100        100                  4   \n",
       "113            50            10         10                  2   \n",
       "114            50            10         10                  2   \n",
       "115            50            10         10                  2   \n",
       "116            50            10         10                  4   \n",
       "117            50            10         10                  4   \n",
       "\n",
       "     min_samples_leaf  min_weight_fraction_leaf max_features  max_leaf_nodes  \\\n",
       "0                 1.0                      0.10         auto               2   \n",
       "1                 1.0                      0.10         auto               4   \n",
       "2                 5.0                      0.25           10               2   \n",
       "3                10.0                      0.10           50               4   \n",
       "4                 1.0                      0.10           50              10   \n",
       "5                10.0                      0.25           50              10   \n",
       "6                 1.0                      0.50           10               2   \n",
       "7                 5.0                      0.50         auto              10   \n",
       "8                 5.0                      0.25           50               2   \n",
       "9                 5.0                      0.10           50               4   \n",
       "10               10.0                      0.50           20               2   \n",
       "11                1.0                      0.25         auto               2   \n",
       "12                5.0                      0.10           10               2   \n",
       "13                1.0                      0.50           50               4   \n",
       "14                5.0                      0.25           10               2   \n",
       "15                1.0                      0.25           10               2   \n",
       "16                1.0                      0.25         auto              10   \n",
       "17                5.0                      0.50           50               2   \n",
       "18               10.0                      0.25         auto               4   \n",
       "19                1.0                      0.10           50               4   \n",
       "20                5.0                      0.10           50               4   \n",
       "21                5.0                      0.25         auto               4   \n",
       "22                1.0                      0.10           50               4   \n",
       "23               10.0                      0.25         auto              10   \n",
       "24                5.0                      0.25         auto               2   \n",
       "25                1.0                      0.25           20               2   \n",
       "26                1.0                      0.25           10               2   \n",
       "27                5.0                      0.10           10               4   \n",
       "28                1.0                      0.10           10              10   \n",
       "29                5.0                      0.50           10               4   \n",
       "..                ...                       ...          ...             ...   \n",
       "88                1.0                      0.25           20              10   \n",
       "89                5.0                      0.25         auto               4   \n",
       "90                5.0                      0.25           20              10   \n",
       "91                5.0                      0.10           10              10   \n",
       "92                5.0                      0.50         auto               4   \n",
       "93                1.0                      0.10           10               4   \n",
       "94                1.0                      0.25           10               2   \n",
       "95                5.0                      0.25           10               2   \n",
       "96               10.0                      0.25           20              10   \n",
       "97                5.0                      0.25           50               2   \n",
       "98                1.0                      0.10           10               2   \n",
       "99                1.0                      0.25           10               4   \n",
       "100               5.0                      0.10         auto               2   \n",
       "101               5.0                      0.10           10              10   \n",
       "102               5.0                      0.10         auto               2   \n",
       "103               1.0                      0.25         auto               4   \n",
       "104               1.0                      0.10           10               2   \n",
       "105               1.0                      0.25         auto               4   \n",
       "106              10.0                      0.50           20               2   \n",
       "107               1.0                      0.25           20               2   \n",
       "108               1.0                      0.10           20               4   \n",
       "109               5.0                      0.10         auto               4   \n",
       "110               1.0                      0.50           20               2   \n",
       "111               1.0                      0.25           10               2   \n",
       "112               5.0                      0.50           10               4   \n",
       "113               1.0                      0.10         auto               2   \n",
       "114               1.0                      0.10         auto               2   \n",
       "115               5.0                      0.50           20               4   \n",
       "116               5.0                      0.10           20               4   \n",
       "117              10.0                      0.25           20               2   \n",
       "\n",
       "     min_impurity_decrease  min_impurity_split  bootstrap  oob_score  n_jobs  \\\n",
       "0                        1                 1.0       True      False     2.0   \n",
       "1                        5                 5.0      False      False     2.0   \n",
       "2                        1                 1.0       True      False     5.0   \n",
       "3                       10                 5.0       True      False     2.0   \n",
       "4                        1                 1.0      False      False     2.0   \n",
       "5                        1                 5.0       True      False     2.0   \n",
       "6                        1                 1.0      False      False     1.0   \n",
       "7                        5                10.0      False      False     5.0   \n",
       "8                        5                10.0       True      False     2.0   \n",
       "9                        1                 1.0       True      False     2.0   \n",
       "10                      10                 1.0       True      False     1.0   \n",
       "11                      10                 5.0       True      False     8.0   \n",
       "12                       1                 5.0       True      False     1.0   \n",
       "13                       5                10.0      False      False     8.0   \n",
       "14                      10                 5.0      False      False     5.0   \n",
       "15                       5                 5.0       True      False     2.0   \n",
       "16                       5                 1.0      False      False     2.0   \n",
       "17                       5                10.0      False      False     5.0   \n",
       "18                       1                 5.0      False      False     2.0   \n",
       "19                      10                 5.0       True      False     2.0   \n",
       "20                       5                 5.0       True      False     8.0   \n",
       "21                       1                 5.0      False      False     1.0   \n",
       "22                      10                 1.0      False      False     2.0   \n",
       "23                       5                 1.0      False      False     8.0   \n",
       "24                       5                10.0       True      False     2.0   \n",
       "25                      10                 5.0      False      False     8.0   \n",
       "26                       5                 5.0      False      False     1.0   \n",
       "27                      10                 1.0      False      False     2.0   \n",
       "28                      10                10.0       True      False     2.0   \n",
       "29                       5                10.0      False      False     5.0   \n",
       "..                     ...                 ...        ...        ...     ...   \n",
       "88                       5                 1.0       True      False     8.0   \n",
       "89                       5                 1.0      False      False     5.0   \n",
       "90                       1                 5.0       True      False     1.0   \n",
       "91                       5                10.0      False      False     5.0   \n",
       "92                      10                10.0       True      False     8.0   \n",
       "93                       1                10.0       True      False     1.0   \n",
       "94                       1                10.0       True      False     8.0   \n",
       "95                      10                 1.0       True      False     2.0   \n",
       "96                       5                10.0       True      False     8.0   \n",
       "97                      10                 1.0      False      False     2.0   \n",
       "98                       5                 5.0       True      False     1.0   \n",
       "99                       5                10.0       True      False     2.0   \n",
       "100                      1                 5.0       True      False     1.0   \n",
       "101                      1                 1.0       True      False     2.0   \n",
       "102                      1                 1.0       True      False     5.0   \n",
       "103                      1                 5.0       True      False     1.0   \n",
       "104                      5                 5.0       True      False     1.0   \n",
       "105                      5                 5.0      False      False     5.0   \n",
       "106                      1                 5.0       True      False     2.0   \n",
       "107                     10                 1.0      False      False     1.0   \n",
       "108                     10                10.0      False      False     5.0   \n",
       "109                      5                 1.0      False      False     2.0   \n",
       "110                      1                 5.0       True      False     5.0   \n",
       "111                      1                10.0       True      False     8.0   \n",
       "112                      5                 5.0      False      False     8.0   \n",
       "113                      1                 1.0       True      False     1.0   \n",
       "114                      1                 1.0       True      False     2.0   \n",
       "115                     10                 1.0      False      False     5.0   \n",
       "116                     10                 1.0      False      False     1.0   \n",
       "117                      5                 5.0       True      False     5.0   \n",
       "\n",
       "        output  \n",
       "0     2.639697  \n",
       "1     0.990652  \n",
       "2     1.976542  \n",
       "3     2.501601  \n",
       "4     1.001720  \n",
       "5     2.732058  \n",
       "6     0.948835  \n",
       "7     0.959365  \n",
       "8     9.449856  \n",
       "9     9.359353  \n",
       "10   16.446605  \n",
       "11    6.755734  \n",
       "12   16.696814  \n",
       "13    1.661148  \n",
       "14    1.485538  \n",
       "15   19.698586  \n",
       "16    2.270306  \n",
       "17    2.133462  \n",
       "18    2.416343  \n",
       "19   20.100406  \n",
       "20   11.148093  \n",
       "21    3.530122  \n",
       "22    2.347198  \n",
       "23    2.399691  \n",
       "24    2.410973  \n",
       "25    1.491263  \n",
       "26    1.912246  \n",
       "27    1.150266  \n",
       "28    9.101918  \n",
       "29    1.191413  \n",
       "..         ...  \n",
       "88    1.071397  \n",
       "89    0.270467  \n",
       "90    1.657162  \n",
       "91    0.412782  \n",
       "92    1.915857  \n",
       "93    3.732304  \n",
       "94    2.021583  \n",
       "95    4.364841  \n",
       "96    2.543236  \n",
       "97    0.516718  \n",
       "98    0.409951  \n",
       "99    0.369132  \n",
       "100   0.343565  \n",
       "101   0.357473  \n",
       "102   0.471489  \n",
       "103   0.380466  \n",
       "104   0.389828  \n",
       "105   0.184362  \n",
       "106   1.736137  \n",
       "107   0.488650  \n",
       "108   0.283912  \n",
       "109   0.422510  \n",
       "110   2.163062  \n",
       "111   1.799652  \n",
       "112   0.575576  \n",
       "113   8.503634  \n",
       "114   7.820043  \n",
       "115   1.988748  \n",
       "116   2.003482  \n",
       "117   4.292340  \n",
       "\n",
       "[118 rows x 19 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13893.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.365156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>315.201019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.008392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.138187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.299435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.377948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35978.942474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             output\n",
       "count  13893.000000\n",
       "mean       6.365156\n",
       "std      315.201019\n",
       "min        0.008392\n",
       "25%        0.138187\n",
       "50%        0.299435\n",
       "75%        1.377948\n",
       "max    35978.942474"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_memory', 'available_memory', 'num_cpu', 'num_rows',\n",
       "       'num_features', 'n_estimators', 'max_depth', 'min_samples_split',\n",
       "       'min_samples_leaf', 'min_weight_fraction_leaf', 'max_features',\n",
       "       'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split',\n",
       "       'bootstrap', 'oob_score', 'n_jobs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_memory</th>\n",
       "      <th>available_memory</th>\n",
       "      <th>num_cpu</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>num_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_weight_fraction_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_impurity_split</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>oob_score</th>\n",
       "      <th>n_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>7036096512</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6761955328</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6267830272</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5694320640</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5679689728</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5683245056</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4346757120</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4284518400</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4335284224</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4384038912</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4358402048</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3759247360</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3329490944</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>7016251392</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6637260800</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5078642688</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4386443264</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4390096896</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3443556352</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6981324800</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5074989056</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6246006784</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4871557120</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6153269248</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3435200512</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3112235008</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>7535542272</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>7481905152</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>7407673344</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6718763008</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7737450496</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7737171968</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7737393152</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7743938560</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7743918080</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7722721280</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7708467200</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7721271296</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7728721920</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7720828928</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7713673216</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7713808384</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7714541568</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7702306816</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7682064384</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7700299776</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7699615744</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7696257024</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7716163584</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7724032000</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7708397568</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7672819712</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7721512960</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7713689600</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7721811968</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7708086272</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7672541184</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7716155392</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7721082880</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7728533504</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13893 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_memory  available_memory  num_cpu  num_rows  num_features  \\\n",
       "0      17179869184        7036096512        8   5000000            50   \n",
       "1      17179869184        6761955328        8   5000000            50   \n",
       "2      17179869184        6267830272        8   5000000            50   \n",
       "3      17179869184        5694320640        8   5000000            50   \n",
       "4      17179869184        5679689728        8   5000000            50   \n",
       "5      17179869184        5683245056        8   5000000            50   \n",
       "6      17179869184        4346757120        8   5000000            50   \n",
       "7      17179869184        4284518400        8   5000000            50   \n",
       "8      17179869184        4335284224        8   5000000            50   \n",
       "9      17179869184        4384038912        8   5000000            50   \n",
       "10     17179869184        4358402048        8   5000000            50   \n",
       "11     17179869184        3759247360        8   5000000            50   \n",
       "12     17179869184        3329490944        8   5000000            50   \n",
       "13     17179869184        7016251392        8   5000000            50   \n",
       "14     17179869184        6637260800        8   5000000            50   \n",
       "15     17179869184        5078642688        8   5000000            50   \n",
       "16     17179869184        4386443264        8   5000000            50   \n",
       "17     17179869184        4390096896        8   5000000            50   \n",
       "18     17179869184        3443556352        8   5000000            50   \n",
       "19     17179869184        6981324800        8   5000000            50   \n",
       "20     17179869184        5074989056        8   5000000            50   \n",
       "21     17179869184        6246006784        8   5000000            50   \n",
       "22     17179869184        4871557120        8   5000000            50   \n",
       "23     17179869184        6153269248        8   5000000            50   \n",
       "24     17179869184        3435200512        8   5000000            25   \n",
       "25     17179869184        3112235008        8   5000000            25   \n",
       "26     17179869184        7535542272        8   5000000            25   \n",
       "27     17179869184        7481905152        8   5000000            25   \n",
       "28     17179869184        7407673344        8   5000000            25   \n",
       "29     17179869184        6718763008        8   5000000            25   \n",
       "...            ...               ...      ...       ...           ...   \n",
       "3522    8375676928        7737450496        4   1000000           600   \n",
       "3523    8375676928        7737171968        4   1000000           600   \n",
       "3524    8375676928        7737393152        4   1000000           600   \n",
       "3525    8375676928        7743938560        4   1000000           600   \n",
       "3526    8375676928        7743918080        4   1000000           600   \n",
       "3527    8375676928        7722721280        4   1000000           600   \n",
       "3528    8375676928        7708467200        4   1000000           600   \n",
       "3529    8375676928        7721271296        4   1000000           600   \n",
       "3530    8375676928        7728721920        4   1000000           600   \n",
       "3531    8375676928        7720828928        4   1000000           600   \n",
       "3532    8375676928        7713673216        4   1000000           600   \n",
       "3533    8375676928        7713808384        4   1000000           600   \n",
       "3534    8375676928        7714541568        4   1000000           600   \n",
       "3535    8375676928        7702306816        4   1000000           600   \n",
       "3536    8375676928        7682064384        4   1000000           600   \n",
       "3537    8375676928        7700299776        4   1000000           600   \n",
       "3538    8375676928        7699615744        4   1000000           600   \n",
       "3539    8375676928        7696257024        4   1000000           600   \n",
       "3540    8375676928        7716163584        4   1000000           600   \n",
       "3541    8375676928        7724032000        4   1000000           600   \n",
       "3542    8375676928        7708397568        4   1000000           600   \n",
       "3543    8375676928        7672819712        4   1000000           600   \n",
       "3544    8375676928        7721512960        4   1000000           600   \n",
       "3545    8375676928        7713689600        4   1000000           600   \n",
       "3546    8375676928        7721811968        4   1000000           600   \n",
       "3547    8375676928        7708086272        4   1000000           600   \n",
       "3548    8375676928        7672541184        4   1000000           600   \n",
       "3549    8375676928        7716155392        4   1000000           600   \n",
       "3550    8375676928        7721082880        4   1000000           600   \n",
       "3551    8375676928        7728533504        4   1000000           600   \n",
       "\n",
       "      n_estimators  max_depth  min_samples_split  min_samples_leaf  \\\n",
       "0               10         10                  2               1.0   \n",
       "1               10         10                  2               1.0   \n",
       "2               10         10                  2               5.0   \n",
       "3               10         10                  2              10.0   \n",
       "4               10         50                  4               1.0   \n",
       "5               10         50                 10              10.0   \n",
       "6               10        100                  2               1.0   \n",
       "7               10        100                  4               5.0   \n",
       "8               50         10                  2               5.0   \n",
       "9               50         10                 10               5.0   \n",
       "10              50         50                  4              10.0   \n",
       "11              50         50                 10               1.0   \n",
       "12              50        100                  2               5.0   \n",
       "13              50        100                  4               1.0   \n",
       "14              50        100                 10               5.0   \n",
       "15             100         10                  2               1.0   \n",
       "16             100         10                  4               1.0   \n",
       "17             100         10                 10               5.0   \n",
       "18             100         50                  4              10.0   \n",
       "19             100         50                 10               1.0   \n",
       "20             100         50                 10               5.0   \n",
       "21             100         50                 10               5.0   \n",
       "22             100        100                  2               1.0   \n",
       "23             100        100                  4              10.0   \n",
       "24              10         50                  4               5.0   \n",
       "25              10        100                 10               1.0   \n",
       "26              50         10                 10               1.0   \n",
       "27              50         10                 10               5.0   \n",
       "28              50         50                  4               1.0   \n",
       "29              50         50                  4               5.0   \n",
       "...            ...        ...                ...               ...   \n",
       "3522           100         50                 10              10.0   \n",
       "3523           100         50                 10              10.0   \n",
       "3524           100         50                 10              10.0   \n",
       "3525           100        100                  2               1.0   \n",
       "3526           100        100                  2               1.0   \n",
       "3527           100        100                  2               5.0   \n",
       "3528           100        100                  2              10.0   \n",
       "3529           100        100                  2              10.0   \n",
       "3530           100        100                  2              10.0   \n",
       "3531           100        100                  4               1.0   \n",
       "3532           100        100                  4               1.0   \n",
       "3533           100        100                  4               1.0   \n",
       "3534           100        100                  4               1.0   \n",
       "3535           100        100                  4               1.0   \n",
       "3536           100        100                  4               1.0   \n",
       "3537           100        100                  4               1.0   \n",
       "3538           100        100                  4               1.0   \n",
       "3539           100        100                  4               5.0   \n",
       "3540           100        100                  4               5.0   \n",
       "3541           100        100                  4              10.0   \n",
       "3542           100        100                  4              10.0   \n",
       "3543           100        100                  4              10.0   \n",
       "3544           100        100                  4              10.0   \n",
       "3545           100        100                  4              10.0   \n",
       "3546           100        100                 10               1.0   \n",
       "3547           100        100                 10               1.0   \n",
       "3548           100        100                 10               1.0   \n",
       "3549           100        100                 10               5.0   \n",
       "3550           100        100                 10               5.0   \n",
       "3551           100        100                 10               5.0   \n",
       "\n",
       "      min_weight_fraction_leaf max_features  max_leaf_nodes  \\\n",
       "0                         0.10         auto               2   \n",
       "1                         0.10         auto               4   \n",
       "2                         0.25           10               2   \n",
       "3                         0.10           50               4   \n",
       "4                         0.10           50              10   \n",
       "5                         0.25           50              10   \n",
       "6                         0.50           10               2   \n",
       "7                         0.50         auto              10   \n",
       "8                         0.25           50               2   \n",
       "9                         0.10           50               4   \n",
       "10                        0.50           20               2   \n",
       "11                        0.25         auto               2   \n",
       "12                        0.10           10               2   \n",
       "13                        0.50           50               4   \n",
       "14                        0.25           10               2   \n",
       "15                        0.25           10               2   \n",
       "16                        0.25         auto              10   \n",
       "17                        0.50           50               2   \n",
       "18                        0.25         auto               4   \n",
       "19                        0.10           50               4   \n",
       "20                        0.10           50               4   \n",
       "21                        0.25         auto               4   \n",
       "22                        0.10           50               4   \n",
       "23                        0.25         auto              10   \n",
       "24                        0.25         auto               2   \n",
       "25                        0.25           20               2   \n",
       "26                        0.25           10               2   \n",
       "27                        0.10           10               4   \n",
       "28                        0.10           10              10   \n",
       "29                        0.50           10               4   \n",
       "...                        ...          ...             ...   \n",
       "3522                      0.25          100              10   \n",
       "3523                      0.50           50               4   \n",
       "3524                      0.50           50               4   \n",
       "3525                      0.10         auto               4   \n",
       "3526                      0.25           10              10   \n",
       "3527                      0.25           10               2   \n",
       "3528                      0.10           20               2   \n",
       "3529                      0.25          100              10   \n",
       "3530                      0.50          100               2   \n",
       "3531                      0.10         auto               4   \n",
       "3532                      0.10           10               4   \n",
       "3533                      0.10           20              10   \n",
       "3534                      0.10           50               4   \n",
       "3535                      0.25           20               4   \n",
       "3536                      0.25           50               2   \n",
       "3537                      0.25          100               4   \n",
       "3538                      0.50           10              10   \n",
       "3539                      0.10           10              10   \n",
       "3540                      0.50           10               4   \n",
       "3541                      0.10           50               4   \n",
       "3542                      0.10          100               4   \n",
       "3543                      0.25         auto              10   \n",
       "3544                      0.50           20               4   \n",
       "3545                      0.50          100               2   \n",
       "3546                      0.50           20              10   \n",
       "3547                      0.50           50               4   \n",
       "3548                      0.50           50              10   \n",
       "3549                      0.10         auto               4   \n",
       "3550                      0.50           20              10   \n",
       "3551                      0.50          100               4   \n",
       "\n",
       "      min_impurity_decrease  min_impurity_split  bootstrap  oob_score  n_jobs  \n",
       "0                         1                 1.0       True      False     2.0  \n",
       "1                         5                 5.0      False      False     2.0  \n",
       "2                         1                 1.0       True      False     5.0  \n",
       "3                        10                 5.0       True      False     2.0  \n",
       "4                         1                 1.0      False      False     2.0  \n",
       "5                         1                 5.0       True      False     2.0  \n",
       "6                         1                 1.0      False      False     1.0  \n",
       "7                         5                10.0      False      False     5.0  \n",
       "8                         5                10.0       True      False     2.0  \n",
       "9                         1                 1.0       True      False     2.0  \n",
       "10                       10                 1.0       True      False     1.0  \n",
       "11                       10                 5.0       True      False     8.0  \n",
       "12                        1                 5.0       True      False     1.0  \n",
       "13                        5                10.0      False      False     8.0  \n",
       "14                       10                 5.0      False      False     5.0  \n",
       "15                        5                 5.0       True      False     2.0  \n",
       "16                        5                 1.0      False      False     2.0  \n",
       "17                        5                10.0      False      False     5.0  \n",
       "18                        1                 5.0      False      False     2.0  \n",
       "19                       10                 5.0       True      False     2.0  \n",
       "20                        5                 5.0       True      False     8.0  \n",
       "21                        1                 5.0      False      False     1.0  \n",
       "22                       10                 1.0      False      False     2.0  \n",
       "23                        5                 1.0      False      False     8.0  \n",
       "24                        5                10.0       True      False     2.0  \n",
       "25                       10                 5.0      False      False     8.0  \n",
       "26                        5                 5.0      False      False     1.0  \n",
       "27                       10                 1.0      False      False     2.0  \n",
       "28                       10                10.0       True      False     2.0  \n",
       "29                        5                10.0      False      False     5.0  \n",
       "...                     ...                 ...        ...        ...     ...  \n",
       "3522                     10                 1.0       True      False     1.0  \n",
       "3523                      1                10.0       True      False     1.0  \n",
       "3524                     10                 5.0       True      False     8.0  \n",
       "3525                      1                 1.0       True      False     1.0  \n",
       "3526                     10                 5.0       True      False     8.0  \n",
       "3527                      1                10.0      False      False     2.0  \n",
       "3528                     10                10.0      False      False     8.0  \n",
       "3529                      5                 5.0      False      False     1.0  \n",
       "3530                     10                 5.0       True      False     1.0  \n",
       "3531                     10                 1.0      False      False     5.0  \n",
       "3532                     10                10.0       True      False     1.0  \n",
       "3533                      5                 5.0       True      False     8.0  \n",
       "3534                      5                 5.0       True      False     2.0  \n",
       "3535                      5                10.0       True      False     2.0  \n",
       "3536                      5                 1.0      False      False     5.0  \n",
       "3537                      5                 1.0       True      False     2.0  \n",
       "3538                     10                 1.0       True      False     2.0  \n",
       "3539                     10                 5.0      False      False     8.0  \n",
       "3540                      1                 1.0      False      False     1.0  \n",
       "3541                      5                 1.0      False      False     8.0  \n",
       "3542                      1                10.0       True      False     2.0  \n",
       "3543                      5                 1.0      False      False     5.0  \n",
       "3544                      5                10.0      False      False     8.0  \n",
       "3545                      1                 5.0      False      False     1.0  \n",
       "3546                     10                 1.0       True      False     5.0  \n",
       "3547                      5                 1.0       True      False     2.0  \n",
       "3548                      5                 1.0       True      False     5.0  \n",
       "3549                      5                 5.0      False      False     5.0  \n",
       "3550                     10                 5.0       True      False     5.0  \n",
       "3551                     10                10.0      False      False     5.0  \n",
       "\n",
       "[13893 rows x 17 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Model inputs: ['total_memory', 'available_memory', 'num_cpu', 'num_rows', 'num_features', 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'min_weight_fraction_leaf', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'bootstrap', 'oob_score', 'n_jobs', 'max_features_10', 'max_features_100', 'max_features_20', 'max_features_200', 'max_features_30', 'max_features_40', 'max_features_50', 'max_features_auto']\n",
      "INFO:Fitting RF to estimate training durations for model RandomForestRegressor\n",
      "INFO:Saving RF to RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:R squared on train set is 0.9261720529707264\n",
      "INFO:\n",
      "            MAPE on train set is: 27.71976019237124\n",
      "            MAPE on test set is: 198.56785176652278\n",
      "            RMSE on train set is 95.5878337868876\n",
      "            RMSE on test set is 79.96970504644341 \n",
      "INFO:Trainer.model_fit took 0.417s seconds\n"
     ]
    }
   ],
   "source": [
    "skl = t.model_fit(generate_data=False, inputs=inputs, outputs=outputs, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=Trainer(verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Generating dummy training durations to create a training set\n",
      "INFO:data added for {'num_rows': 30000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': True, 'n_jobs': 1} which outputs 53.4832878112793 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3094949888], 'num_cpu': [8], 'num_rows': [30000000], 'num_features': [10], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [True], 'n_jobs': [1]}\n",
      "WARNING:model fit for {'num_rows': 30000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': True, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 30000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': True, 'n_jobs': 2} which outputs 42.88536810874939 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [7995469824], 'num_cpu': [8], 'num_rows': [30000000], 'num_features': [10], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [True], 'n_jobs': [2]}\n",
      "WARNING:model fit for {'num_rows': 30000000, 'num_features': 10, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': True, 'n_jobs': 2} throws a ValueError\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-619c1e3d2d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/scikest/scikest/utils.py\u001b[0m in \u001b[0;36mtimed\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{method.__qualname__} took {round(te - ts, 3)}s seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36mmodel_validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimated_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mactual_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/utils.py\u001b[0m in \u001b[0;36mtimed\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{method.__qualname__} took {round(te - ts, 3)}s seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36m_generate_data\u001b[0;34m(self, validation)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         inputs, outputs, estimated_outputs = self._permute(concat_dic, parameters_list, external_parameters_list,\n\u001b[0;32m--> 215\u001b[0;31m                                                            meta_params, algo_type, validation)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/utils.py\u001b[0m in \u001b[0;36mtimed\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{method.__qualname__} took {round(te - ts, 3)}s seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36m_permute\u001b[0;34m(self, concat_dic, parameters_list, external_parameters_list, meta_params, algo_type, validation)\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0mrow_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_cpu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                     \u001b[0mrow_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_measure_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36m_measure_time\u001b[0;34m(model, X, y, meta_params)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melapsed_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vals = t.model_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('RandomForestRegressor_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_memory</th>\n",
       "      <th>available_memory</th>\n",
       "      <th>num_cpu</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>num_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_weight_fraction_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_impurity_split</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>oob_score</th>\n",
       "      <th>n_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3787419648</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5700849664</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6070771712</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6187642880</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6436646912</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4733095936</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3341742080</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5878607872</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>7042084864</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6003449856</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>9076871168</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5709496320</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4229275648</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3652423680</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3302092800</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6126456832</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5767450624</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3628257280</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3357614080</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4549545984</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6416617472</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4308393984</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>2590838784</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>1847721984</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>1986232320</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>2403229696</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>2768633856</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>2515693568</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>9744068608</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>7455846400</td>\n",
       "      <td>8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6863077376</td>\n",
       "      <td>8</td>\n",
       "      <td>3000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5948588032</td>\n",
       "      <td>8</td>\n",
       "      <td>3000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4608700416</td>\n",
       "      <td>8</td>\n",
       "      <td>3000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4401692672</td>\n",
       "      <td>8</td>\n",
       "      <td>3000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4733165568</td>\n",
       "      <td>8</td>\n",
       "      <td>3000000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4504645632</td>\n",
       "      <td>8</td>\n",
       "      <td>3000000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5105221632</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4832825344</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4833808384</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4830466048</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4860198912</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4859625472</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4837457920</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4637003776</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4237914112</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>4237967360</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3981004800</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3576840192</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3600494592</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3570102272</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3579211776</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3578355712</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3576852480</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>3294666752</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>7127769088</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6825058304</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>6488399872</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5421322240</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5016326144</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>17179869184</td>\n",
       "      <td>5013934080</td>\n",
       "      <td>8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_memory  available_memory  num_cpu  num_rows  num_features  \\\n",
       "0    17179869184        3787419648        8   5000000            50   \n",
       "1    17179869184        5700849664        8   5000000            50   \n",
       "2    17179869184        6070771712        8   5000000            50   \n",
       "3    17179869184        6187642880        8   5000000            50   \n",
       "4    17179869184        6436646912        8   5000000            50   \n",
       "5    17179869184        4733095936        8   5000000            50   \n",
       "6    17179869184        3341742080        8   5000000            50   \n",
       "7    17179869184        5878607872        8   5000000            50   \n",
       "8    17179869184        7042084864        8   5000000            50   \n",
       "9    17179869184        6003449856        8   5000000            50   \n",
       "10   17179869184        9076871168        8   5000000            50   \n",
       "11   17179869184        5709496320        8   5000000            50   \n",
       "12   17179869184        4229275648        8   5000000            50   \n",
       "13   17179869184        3652423680        8   5000000            50   \n",
       "14   17179869184        3302092800        8   5000000            50   \n",
       "15   17179869184        6126456832        8   5000000            50   \n",
       "16   17179869184        5767450624        8   5000000            50   \n",
       "17   17179869184        3628257280        8   5000000            50   \n",
       "18   17179869184        3357614080        8   5000000            50   \n",
       "19   17179869184        4549545984        8   5000000            50   \n",
       "20   17179869184        6416617472        8   5000000            50   \n",
       "21   17179869184        4308393984        8   5000000            25   \n",
       "22   17179869184        2590838784        8   5000000            25   \n",
       "23   17179869184        1847721984        8   5000000            25   \n",
       "24   17179869184        1986232320        8   5000000            25   \n",
       "25   17179869184        2403229696        8   5000000            25   \n",
       "26   17179869184        2768633856        8   5000000            25   \n",
       "27   17179869184        2515693568        8   5000000            25   \n",
       "28   17179869184        9744068608        8   5000000            25   \n",
       "29   17179869184        7455846400        8   5000000            25   \n",
       "..           ...               ...      ...       ...           ...   \n",
       "60   17179869184        6863077376        8   3000000            25   \n",
       "61   17179869184        5948588032        8   3000000            25   \n",
       "62   17179869184        4608700416        8   3000000            25   \n",
       "63   17179869184        4401692672        8   3000000            25   \n",
       "64   17179869184        4733165568        8   3000000            25   \n",
       "65   17179869184        4504645632        8   3000000            25   \n",
       "66   17179869184        5105221632        8   1000000            50   \n",
       "67   17179869184        4832825344        8   1000000            50   \n",
       "68   17179869184        4833808384        8   1000000            50   \n",
       "69   17179869184        4830466048        8   1000000            50   \n",
       "70   17179869184        4860198912        8   1000000            50   \n",
       "71   17179869184        4859625472        8   1000000            50   \n",
       "72   17179869184        4837457920        8   1000000            50   \n",
       "73   17179869184        4637003776        8   1000000            50   \n",
       "74   17179869184        4237914112        8   1000000            50   \n",
       "75   17179869184        4237967360        8   1000000            50   \n",
       "76   17179869184        3981004800        8   1000000            25   \n",
       "77   17179869184        3576840192        8   1000000            25   \n",
       "78   17179869184        3600494592        8   1000000            25   \n",
       "79   17179869184        3570102272        8   1000000            25   \n",
       "80   17179869184        3579211776        8   1000000            25   \n",
       "81   17179869184        3578355712        8   1000000            25   \n",
       "82   17179869184        3576852480        8   1000000            25   \n",
       "83   17179869184        3294666752        8   1000000            25   \n",
       "84   17179869184        7127769088        8   1000000            25   \n",
       "85   17179869184        6825058304        8   1000000            25   \n",
       "86   17179869184        6488399872        8   1000000            25   \n",
       "87   17179869184        5421322240        8   1000000            25   \n",
       "88   17179869184        5016326144        8   1000000            25   \n",
       "89   17179869184        5013934080        8   1000000            25   \n",
       "\n",
       "    n_estimators  max_depth  min_samples_split  min_samples_leaf  \\\n",
       "0             10         10                  2                 1   \n",
       "1             10         10                  2                 1   \n",
       "2             10         10                  2                 1   \n",
       "3             10         10                  4                10   \n",
       "4             10         10                 10                 1   \n",
       "5             10         50                  2                 5   \n",
       "6             10         50                  4                 1   \n",
       "7             10         50                 10                10   \n",
       "8             10        100                  4                10   \n",
       "9             10        100                 10                 5   \n",
       "10            50         10                  4                 5   \n",
       "11            50         50                 10                 1   \n",
       "12            50         50                 10                 5   \n",
       "13            50        100                  4                 1   \n",
       "14            50        100                  4                 5   \n",
       "15            50        100                 10                 5   \n",
       "16           100         10                 10                 5   \n",
       "17           100         10                 10                10   \n",
       "18           100         50                 10                 1   \n",
       "19           100        100                  4                 5   \n",
       "20           100        100                 10                 1   \n",
       "21            10         10                  2                10   \n",
       "22            10         50                  2                 5   \n",
       "23            50         50                  2                 1   \n",
       "24            50         50                  2                 5   \n",
       "25            50         50                  2                10   \n",
       "26            50         50                 10                 5   \n",
       "27            50        100                  2                10   \n",
       "28           100         10                  2                 1   \n",
       "29           100         10                  2                10   \n",
       "..           ...        ...                ...               ...   \n",
       "60            50         50                  2                 5   \n",
       "61            50         50                 10                 5   \n",
       "62            50        100                  2                10   \n",
       "63            50        100                 10                 5   \n",
       "64           100         50                  4                10   \n",
       "65           100        100                  2                10   \n",
       "66            10         10                  4                10   \n",
       "67            10         50                  2                 1   \n",
       "68            10         50                  4                 1   \n",
       "69            50         10                  2                10   \n",
       "70            50         10                 10                 1   \n",
       "71            50         50                  2                10   \n",
       "72           100         10                 10                 5   \n",
       "73           100         50                  4                 5   \n",
       "74           100        100                  2                 5   \n",
       "75           100        100                  2                10   \n",
       "76            10         50                  4                10   \n",
       "77            10         50                 10                 5   \n",
       "78            10        100                  2                 1   \n",
       "79            10        100                  2                10   \n",
       "80            10        100                  4                 1   \n",
       "81            10        100                 10                 1   \n",
       "82            10        100                 10                 5   \n",
       "83            50         10                  2                10   \n",
       "84            50         50                  4                 1   \n",
       "85            50         50                 10                 1   \n",
       "86            50         50                 10                 5   \n",
       "87           100         50                  2                 5   \n",
       "88           100         50                  4                 1   \n",
       "89           100        100                  4                 1   \n",
       "\n",
       "    min_weight_fraction_leaf max_features  max_leaf_nodes  \\\n",
       "0                       0.10         auto               2   \n",
       "1                       0.10         auto               2   \n",
       "2                       0.50           50              10   \n",
       "3                       0.50           20               2   \n",
       "4                       0.50         auto              10   \n",
       "5                       0.50           20               2   \n",
       "6                       0.10           50               2   \n",
       "7                       0.50         auto              10   \n",
       "8                       0.25           10               4   \n",
       "9                       0.10           20               2   \n",
       "10                      0.25         auto               2   \n",
       "11                      0.10         auto               2   \n",
       "12                      0.50           10               2   \n",
       "13                      0.50         auto               2   \n",
       "14                      0.25           20              10   \n",
       "15                      0.25           10              10   \n",
       "16                      0.25           50               2   \n",
       "17                      0.25           10               4   \n",
       "18                      0.50           10               4   \n",
       "19                      0.25         auto              10   \n",
       "20                      0.25           20              10   \n",
       "21                      0.50           10               4   \n",
       "22                      0.50         auto               4   \n",
       "23                      0.50           10               2   \n",
       "24                      0.50         auto               2   \n",
       "25                      0.25           20               4   \n",
       "26                      0.10           10              10   \n",
       "27                      0.50         auto               4   \n",
       "28                      0.25           10              10   \n",
       "29                      0.10           20               4   \n",
       "..                       ...          ...             ...   \n",
       "60                      0.25         auto               4   \n",
       "61                      0.25         auto               2   \n",
       "62                      0.10           10               4   \n",
       "63                      0.50           20               2   \n",
       "64                      0.50         auto               2   \n",
       "65                      0.50         auto               2   \n",
       "66                      0.25         auto               2   \n",
       "67                      0.25           10               2   \n",
       "68                      0.10           50               2   \n",
       "69                      0.50           10               4   \n",
       "70                      0.10           20              10   \n",
       "71                      0.25           10              10   \n",
       "72                      0.10           50               4   \n",
       "73                      0.50           50               4   \n",
       "74                      0.25           50              10   \n",
       "75                      0.25         auto               2   \n",
       "76                      0.10         auto              10   \n",
       "77                      0.25           20               4   \n",
       "78                      0.25         auto               2   \n",
       "79                      0.10         auto               4   \n",
       "80                      0.50         auto               4   \n",
       "81                      0.10           20              10   \n",
       "82                      0.50         auto               2   \n",
       "83                      0.50         auto              10   \n",
       "84                      0.50         auto              10   \n",
       "85                      0.10         auto              10   \n",
       "86                      0.25           10               2   \n",
       "87                      0.25           10              10   \n",
       "88                      0.25         auto               2   \n",
       "89                      0.10           10               2   \n",
       "\n",
       "    min_impurity_decrease  min_impurity_split  bootstrap  oob_score  n_jobs  \n",
       "0                       1                   1       True      False       1  \n",
       "1                       1                   1       True      False       2  \n",
       "2                      10                   1       True      False       8  \n",
       "3                       1                   1       True      False       1  \n",
       "4                       1                   5       True      False       1  \n",
       "5                       5                  10      False      False       2  \n",
       "6                       5                  10       True      False       8  \n",
       "7                      10                   1      False      False       5  \n",
       "8                      10                  10       True      False       5  \n",
       "9                       1                   1       True      False       1  \n",
       "10                      5                   5      False      False       5  \n",
       "11                      5                  10      False      False       1  \n",
       "12                      1                  10      False      False       2  \n",
       "13                      1                   1       True      False       1  \n",
       "14                     10                   5       True      False       2  \n",
       "15                     10                  10      False      False       8  \n",
       "16                      5                   1      False      False       5  \n",
       "17                      5                   1      False      False       8  \n",
       "18                      5                   5       True      False       5  \n",
       "19                      1                   1      False      False       5  \n",
       "20                      5                   1      False      False       5  \n",
       "21                     10                   1       True      False       8  \n",
       "22                      1                  10      False      False       2  \n",
       "23                      5                   1      False      False       1  \n",
       "24                      1                   1      False      False       8  \n",
       "25                     10                  10      False      False       1  \n",
       "26                     10                  10       True      False       8  \n",
       "27                      5                  10      False      False       1  \n",
       "28                      5                   1       True      False       1  \n",
       "29                      1                   1      False      False       2  \n",
       "..                    ...                 ...        ...        ...     ...  \n",
       "60                      5                   5      False      False       1  \n",
       "61                     10                  10       True      False       8  \n",
       "62                      5                   5      False      False       1  \n",
       "63                      5                   1       True      False       2  \n",
       "64                     10                  10      False      False       5  \n",
       "65                      5                   5       True      False       2  \n",
       "66                     10                  10       True      False       8  \n",
       "67                     10                   1      False      False       1  \n",
       "68                      1                   1       True      False       8  \n",
       "69                      5                  10      False      False       5  \n",
       "70                      1                  10       True      False       1  \n",
       "71                     10                   1       True      False       5  \n",
       "72                     10                   1      False      False       1  \n",
       "73                      1                   1       True      False       2  \n",
       "74                     10                   1      False      False       1  \n",
       "75                     10                   1       True      False       1  \n",
       "76                      5                   5       True      False       5  \n",
       "77                     10                   5      False      False       5  \n",
       "78                      1                  10       True      False       8  \n",
       "79                      5                   5       True      False       2  \n",
       "80                     10                   5       True      False       8  \n",
       "81                      1                   5       True      False       1  \n",
       "82                      1                   5      False      False       5  \n",
       "83                      1                   5      False      False       8  \n",
       "84                     10                  10      False      False       8  \n",
       "85                     10                  10       True      False       2  \n",
       "86                     10                   5      False      False       8  \n",
       "87                      5                  10       True      False       5  \n",
       "88                      5                  10      False      False       1  \n",
       "89                     10                  10      False      False       5  \n",
       "\n",
       "[90 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Generating dummy training durations to create a training set\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.009751081466674805 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6415974400], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.229172220826149 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.11379003524780273 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6415974400], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.8974488894144693 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.13472700119018555 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6377897984], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.5831335306167602 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.1369779109954834 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6376165376], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 1.3997940301895142 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.16620206832885742 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6379315200], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0949193120002747 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.16028308868408203 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6379315200], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.9227452874183655 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.1681218147277832 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6374334464], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0545708497365316 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.10922598838806152 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6358867968], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8882567445437113 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.1086280345916748 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6359031808], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8823947576376108 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.008353948593139648 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6359031808], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.075416126847267 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.11247801780700684 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6359625728], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8903067735525279 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11281394958496094 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6358970368], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8846173433157114 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.006822109222412109 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6363598848], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9505608230829239 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.10689091682434082 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6363598848], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8762464550825266 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.11085176467895508 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6363598848], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8791331013043722 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11143112182617188 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6363598848], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8986314853032431 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.03308415412902832 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6364827648], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9478551650047302 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.13747406005859375 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362537984], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.390262246131897 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.06374812126159668 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362054656], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9164487719535828 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.06643295288085938 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362054656], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9359072637557982 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.06963491439819336 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362054656], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.943109432133761 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.15832233428955078 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362054656], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.0836520195007324 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.06401491165161133 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362054656], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 1.0375168275833129 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.16004586219787598 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362001408], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.9887159645557404 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.06293869018554688 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6364639232], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0388170194625854 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.11042213439941406 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6364639232], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9394232728264548 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.007590055465698242 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6364639232], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['100'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0685050159692764 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.10939693450927734 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6364639232], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.906745813109658 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.11085295677185059 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6364639232], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.945224372545878 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.10830402374267578 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362566656], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8717211723327637 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13304781913757324 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362566656], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9360133290290833 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.033135175704956055 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362566656], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.945233919620514 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.03057694435119629 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362566656], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9823167824745178 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.12824606895446777 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362566656], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9330027767590113 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.16037821769714355 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362566656], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.108676290512085 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.15905308723449707 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6362566656], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.0972434043884278 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.16194391250610352 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6360666112], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0810548424720765 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.16253900527954102 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6360498176], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.9231247186660767 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.16359615325927734 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6360498176], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.9187102556228637 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.0704193115234375 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6360498176], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.8943581732836634 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.1621401309967041 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6360498176], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.9208987474441528 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.158829927444458 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6360498176], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['100'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.10366370677948 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.06708979606628418 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6360498176], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['100'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.8881259759267173 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.1584010124206543 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6413746176], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 2.0137947742755595 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11067986488342285 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6439260160], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.895895536740621 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.16366100311279297 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6407335936], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0680601716041564 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.16274309158325195 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [6407335936], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.0907725981303624 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-619c1e3d2d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/scikest/scikest/utils.py\u001b[0m in \u001b[0;36mtimed\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{method.__qualname__} took {round(te - ts, 3)}s seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36mmodel_validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \"\"\"\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimated_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mactual_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/utils.py\u001b[0m in \u001b[0;36mtimed\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{method.__qualname__} took {round(te - ts, 3)}s seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36m_generate_data\u001b[0;34m(self, validation)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         inputs, outputs, estimated_outputs = self._permute(concat_dic, parameters_list, external_parameters_list,\n\u001b[0;32m--> 213\u001b[0;31m                                                            meta_params, algo_type, validation)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/utils.py\u001b[0m in \u001b[0;36mtimed\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{method.__qualname__} took {round(te - ts, 3)}s seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36m_permute\u001b[0;34m(self, concat_dic, parameters_list, external_parameters_list, meta_params, algo_type, validation)\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0;31m# fitting the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                     \u001b[0mrow_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_measure_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m                     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/scikest/scikest/train.py\u001b[0m in \u001b[0;36m_measure_time\u001b[0;34m(model, X, y, meta_params)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melapsed_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vals = t.model_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Model inputs: ['total_memory', 'available_memory', 'num_cpu', 'num_rows', 'num_features', 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'min_weight_fraction_leaf', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'bootstrap', 'oob_score', 'n_jobs', 'max_features_10', 'max_features_100', 'max_features_20', 'max_features_50', 'max_features_auto']\n",
      "INFO:Fitting RF to estimate training durations for model RandomForestRegressor\n",
      "INFO:Saving RF to RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:R squared on train set is 0.9984747742862128\n",
      "INFO:\n",
      "            MAPE on train set is: 1.3378946210973879\n",
      "            MAPE on test set is: 3.2378133529797197\n",
      "            RMSE on train set is 0.051796786926116924\n",
      "            RMSE on test set is 0.08702920558349414 \n",
      "INFO:Trainer.model_fit took 0.149s seconds\n",
      "INFO:Generating dummy training durations to create a training set\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.010277986526489258 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3685388288], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.229172220826149 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.11057686805725098 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3705651200], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.8974488894144693 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11267995834350586 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3738312704], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8780644801946786 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.10976529121398926 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3780300800], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8725266536076864 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.1388862133026123 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3868626944], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9310358047485352 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.16695594787597656 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3868827648], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0679359257221221 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.10758709907531738 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3853631488], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.8816580692927042 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.10959362983703613 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3853012992], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.8901442448298136 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.11223506927490234 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3853012992], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.8700877348581949 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.13360905647277832 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3853512704], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.4257331371307373 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.13255071640014648 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3855007744], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9518595743179322 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.1346290111541748 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3855007744], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9433617234230042 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.1823899745941162 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3828944896], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.9803361654281617 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.17159390449523926 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847581696], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.0789128224054974 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.17113804817199707 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847581696], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 1.8726195812225341 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.2374110221862793 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847581696], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 2.219358777999878 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.1609489917755127 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847516160], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0516432642936706 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.06135702133178711 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849748480], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9335763645172118 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.06299591064453125 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849748480], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9637652111053466 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.16113996505737305 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847536640], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.9468223810195924 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.1649327278137207 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848265728], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.9522496581077575 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.16162419319152832 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849764864], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0382028047855083 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.11832904815673828 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849764864], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 0.8908956744454123 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.010307073593139648 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849764864], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.917036023736 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11684107780456543 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849764864], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8846173433157114 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.11089110374450684 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849764864], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.8782523848793723 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.007890939712524414 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848544256], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9471921116113663 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.11362886428833008 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848511488], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8917094270388285 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.10981106758117676 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848196096], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8944666544596354 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.11207199096679688 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848196096], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8779831695556639 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.1157522201538086 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848196096], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8719155867894491 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.1113901138305664 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848196096], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 0.896471651395162 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11444211006164551 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848196096], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.895895536740621 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.009943962097167969 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848196096], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0344268232584 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.13707208633422852 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848560640], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['100'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.6357815790176393 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.035104990005493164 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848560640], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9466021323204041 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13378000259399414 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848560640], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9453198313713074 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.13663411140441895 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848560640], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['100'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.980001859664917 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13481497764587402 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848560640], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.935412609577179 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.13699102401733398 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848560640], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.4194149672985077 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.13383698463439941 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848560640], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['100'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 0.9815503705115546 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.13402891159057617 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848163328], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.604649431364877 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.03272390365600586 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848163328], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['100'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0169100705782572 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.06175088882446289 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848163328], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9207410287857055 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.0669100284576416 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848163328], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.9213829430666833 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.15906500816345215 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848163328], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 2.3742807176378036 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.16130590438842773 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848163328], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.0512352069218953 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.1644759178161621 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848163328], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.9822834074497222 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.15858983993530273 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848634368], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.9823222756385803 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.00759124755859375 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3851526144], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.10114988386631 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.10909891128540039 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3851526144], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8910636027654013 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.13857316970825195 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3851526144], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.422174859046936 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.1316208839416504 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3851776000], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.394358491897583 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.13361787796020508 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3851776000], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.6402884721755981 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.13489198684692383 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3850182656], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.3892797470092773 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.13438677787780762 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3850182656], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9471423864364624 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.1113731861114502 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849224192], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8817726182937621 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.009887933731079102 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3851427840], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.1699551969766617 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11336612701416016 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3851427840], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8785693315359262 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.11381769180297852 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848048640], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8809693495432536 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.112152099609375 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3848048640], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 0.8973411321640015 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.11415290832519531 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846848512], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.876961636543274 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.11019635200500488 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846852608], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.8969973087310791 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.1345832347869873 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846438912], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.4195640683174133 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13852787017822266 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846438912], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.935689389705658 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.04191994667053223 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846438912], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.274033358097076 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13174200057983398 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846438912], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9415112912654877 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.15268921852111816 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846438912], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9504475402832032 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.13456296920776367 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846397952], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.6098462867736818 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.06531906127929688 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3845988352], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.8888519915667445 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.060923099517822266 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847192576], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0302523565292359 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.0651700496673584 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847086080], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.946784201535311 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.16079306602478027 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847086080], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.8970525860786438 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.16340088844299316 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847086080], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.9384314219156902 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.16508007049560547 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847086080], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0686373949050902 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.1598043441772461 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847086080], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.975288414955139 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.15615391731262207 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847208960], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.9743391036987306 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.06392216682434082 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847127040], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 1.0381668519973755 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.10989594459533691 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847278592], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9074403979561545 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.11030292510986328 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847278592], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['100'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.8859843709252097 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.10862398147583008 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847278592], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8812964598337809 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.10980987548828125 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847278592], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9307422854683616 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.008546113967895508 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847278592], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.070162358880043 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.11218476295471191 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3847278592], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.8958923556587912 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11387801170349121 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846819840], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.877892478307088 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.11102604866027832 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849428992], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8942884047826132 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.008626937866210938 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849428992], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 0.9483567625284195 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.1350851058959961 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849428992], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.92515949010849 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.036873817443847656 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849428992], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.2021541380882264 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.131483793258667 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849428992], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.618560485839844 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.1376199722290039 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849428992], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9763202548027039 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.03813314437866211 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3849428992], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.295145180225372 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13437795639038086 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846283264], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9374429881572723 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.13296008110046387 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846283264], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.3766037225723267 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.0357968807220459 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846283264], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['100'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.016736891269684 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.1312551498413086 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846283264], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 1.3968247413635253 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.16652393341064453 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846283264], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.840582263469696 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.16738104820251465 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846283264], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.0857722997665404 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.1680772304534912 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846119424], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.0678205516603259 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.07244181632995605 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3845689344], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['100'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.97015810807546 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.1166238784790039 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3819466752], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8714692024084238 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.11173892021179199 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846356992], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.864839251836141 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data added for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.037464141845703125 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3851284480], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [5], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9736780881881714 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.0592799186706543 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3850788864], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [5], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9982396125793457 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.09956002235412598 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3850985472], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [5], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.8951967000961303 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.11282610893249512 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3846262784], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8621383706728617 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.11004519462585449 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3844644864], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.8518078009287515 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.1136159896850586 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3844644864], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8688940882682801 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11137104034423828 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836768256], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.881139507660499 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.013087034225463867 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3837018112], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.1197435855865479 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.011712074279785156 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3839401984], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0743327617645264 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.11496305465698242 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3839401984], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.849994953473409 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.13336396217346191 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3839401984], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9314002462795802 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13478493690490723 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3839401984], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9221396803855896 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.17316079139709473 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3839131648], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.3836281061172486 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13543295860290527 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3839139840], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9198234915733338 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.12985610961914062 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3842129920], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.406421148777008 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.15624785423278809 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3842129920], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.6030682274273462 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.156203031539917 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3842129920], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9348305034637452 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.06441307067871094 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3842129920], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.917991042137146 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.09785699844360352 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3840163840], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.875519168376923 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.16478586196899414 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3840163840], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 1.8928628444671631 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.16569805145263672 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3840163840], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.0763639238145617 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.1582961082458496 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3840163840], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.0454391649791173 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.16218018531799316 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3840163840], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 2.4507280826568603 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.1621990203857422 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836825600], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0750378449757894 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.16408896446228027 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836825600], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.0538788517316182 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.11292386054992676 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836825600], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8884074012438455 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.11249303817749023 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836825600], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8749513546625772 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.11264371871948242 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836825600], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.861832950331948 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.009063959121704102 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836825600], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['100'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9980653969446818 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.11223411560058594 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3826163712], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8694942522048951 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11143136024475098 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3825762304], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8991824058385995 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.11359095573425293 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836223488], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9114233710549093 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.012115001678466797 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836223488], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0763773066656932 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.012697935104370117 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836223488], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.1326794011252268 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.11319589614868164 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836223488], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.8531543302536011 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.008858203887939453 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836223488], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.899877505302429 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.008606910705566406 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836223488], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 0.9474108028411864 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.11339092254638672 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3836223488], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.8958923556587912 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11000299453735352 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3827470336], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.8991363366444907 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.1348888874053955 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3827322880], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['100'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9793672431082954 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.13746094703674316 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3837980672], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9771627068519593 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.13697409629821777 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3837980672], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9377288460731507 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.13736391067504883 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3837980672], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.427629679441452 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13151001930236816 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3837980672], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9462860524654388 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.1320497989654541 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3827904512], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.4150437712669373 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.13623404502868652 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3827769344], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.5890455433300563 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.16161108016967773 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3827769344], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.0828594139644079 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.1570281982421875 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3827769344], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.9390212893486023 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.16586589813232422 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3828654080], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.0592655923631455 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.15781903266906738 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3828654080], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.0563596844673158 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.06973481178283691 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3828654080], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9507956743240357 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.09517598152160645 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3828654080], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.9130659222602846 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.16006922721862793 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [3828654080], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.9622302055358887 seconds\n",
      "INFO:Trainer._permute took 55.328s seconds\n",
      "INFO:Trainer._generate_data took 55.335s seconds\n",
      "INFO:Trainer.model_validate took 55.337s seconds\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('scikest/result_latest.csv')\n",
    "t = Trainer(verbose=3, drop_rate=0.999)\n",
    "cols = t.params['other_params'] + list(t.params['external_params'].keys()) + list(t.params['internal_params'].keys()) + ['output']\n",
    "df.columns = cols\n",
    "inputs = df [t.params['other_params'] + list(t.params['external_params'].keys()) + list(t.params['internal_params'].keys())]\n",
    "outputs = df[['output']]\n",
    "skl = t.model_fit(generate_data=False, inputs=inputs, outputs=outputs)\n",
    "vals = t.model_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Generating dummy training durations to create a training set\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.008669137954711914 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1231224832], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.425875759124756 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.11359095573425293 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1232236544], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9643458366394043 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.11195182800292969 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1232236544], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9360626459121704 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.13533282279968262 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1209794560], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9981407642364502 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.16866683959960938 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1208688640], 'num_cpu': [8], 'num_rows': [100], 'num_features': [5], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.047412109375 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11158299446105957 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1045225472], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.933778715133667 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.11521196365356445 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1014419456], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9491959333419799 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.11517596244812012 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1016164352], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9430327415466309 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.10916686058044434 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1016164352], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9947784900665283 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.012624979019165039 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1016164352], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.3380088567733766 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.11006593704223633 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1016164352], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9762500047683715 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11274600028991699 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1016164352], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9309807300567627 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.007477998733520508 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1016164352], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9299647331237793 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.10782408714294434 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1012543488], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9504484415054322 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.11315679550170898 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1013084160], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9060304880142211 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.14066195487976074 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1012948992], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.4438867092132568 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.13440895080566406 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1012948992], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.4259135484695435 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.05049014091491699 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1012948992], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.505588483810425 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.03962898254394531 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1012948992], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.050593407948812 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13915586471557617 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [1012948992], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 0.9710036754608155 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.04355812072753906 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [989880320], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0512844880421957 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.14630818367004395 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [918929408], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.4223840236663818 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.1657729148864746 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [988241920], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.018276858329773 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.19104981422424316 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [988241920], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0555210351943969 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.17313528060913086 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [988241920], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.925179696083069 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.1729578971862793 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [983015424], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0442238807678224 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.09366679191589355 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [950661120], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0467921495437622 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.164078950881958 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [944775168], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.966977345943451 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.16953587532043457 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [944775168], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 1.9282403230667113 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.17430996894836426 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [944775168], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.0070144653320312 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.16141891479492188 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [944775168], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.0515033721923828 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.0726172924041748 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [797999104], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.171314811706543 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.07004690170288086 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [797999104], 'num_cpu': [8], 'num_rows': [100], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 3.2267858266830443 seconds\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 100, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.10836982727050781 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [797999104], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9344361543655395 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.1084280014038086 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [797999104], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.005534815788269 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.10969996452331543 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [777109504], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['100'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9996753215789795 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.11240077018737793 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [777199616], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 1.00761559009552 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.11249613761901855 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [777035776], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9407189846038818 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.11333084106445312 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [777035776], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9381421506404877 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.10817718505859375 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [777035776], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9455698192119598 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.1068410873413086 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [777035776], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9071890354156494 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.11085319519042969 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [777035776], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.965286374092102 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.06598782539367676 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [601194496], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.533738541603088 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.16693997383117676 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [601194496], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.4287933588027955 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.1592569351196289 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [601194496], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.4341477632522583 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.13665413856506348 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [601194496], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 1.5195128202438355 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.13834095001220703 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [601194496], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.5548378705978394 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.03734397888183594 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [601194496], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 2.4814085483551027 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.14670586585998535 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [596959232], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.3933393955230713 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.15719890594482422 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [599662592], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0438703441619874 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.1618349552154541 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [599662592], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0672974348068238 seconds\n",
      "INFO:data added for {'num_rows': 100, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.06936883926391602 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [599662592], 'num_cpu': [8], 'num_rows': [100], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 3.1367183446884157 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.0066339969635009766 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [599662592], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.949302339553833 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.0067899227142333984 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [599662592], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9537601470947266 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.10717296600341797 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [611299328], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.933778715133667 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.0076830387115478516 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [611299328], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9578989267349243 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.1394329071044922 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [5566693376], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.4287096023559571 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.23994183540344238 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4932268032], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.9262266635894776 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data added for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.06683087348937988 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4897906688], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [5], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 3.198776388168335 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.11156010627746582 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4946722816], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9546697616577149 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.008368253707885742 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949028864], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.3967710494995118 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.10821676254272461 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949028864], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9402233362197876 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.0069119930267333984 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949028864], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9541197538375854 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11298680305480957 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949028864], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9416153192520141 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.007991790771484375 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949028864], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.4121201515197754 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.007443904876708984 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949028864], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.3424494028091432 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.10822582244873047 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949028864], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.943550705909729 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.008551836013793945 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949028864], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9222944021224976 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.11029195785522461 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4945428480], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9454212427139282 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.11249899864196777 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4948348928], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.0214088678359985 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.1337590217590332 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4947320832], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.004678225517273 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13310813903808594 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949479424], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 0.9726885318756103 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.1352379322052002 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949479424], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0013497114181518 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.03833508491516113 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949479424], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0493557453155518 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.1336350440979004 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949479424], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9687809467315673 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.1349930763244629 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4949479424], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.5644376039505006 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13723230361938477 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4946399232], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9940357685089112 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.13406777381896973 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4945891328], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0067001819610595 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.13857412338256836 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4945891328], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9971724629402161 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.13338518142700195 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4946403328], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.545047688484192 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.13032031059265137 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4945985536], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9955055952072144 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.06440091133117676 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4945985536], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0466681480407716 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.16290688514709473 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4945985536], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0576648712158203 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.16145992279052734 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4945985536], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.0708590984344482 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.16094017028808594 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4945985536], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.9128454327583313 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.17833805084228516 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4817555456], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 2.201792049407959 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.07380199432373047 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4817932288], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 3.2419185400009156 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.18112897872924805 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4820729856], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.048265314102173 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.19297218322753906 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4820729856], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 1.0488199949264527 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.16977572441101074 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4820729856], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0100146675109865 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.15701889991760254 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4693131264], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0375568926334382 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.16545772552490234 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4693131264], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.9010740160942077 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.07237720489501953 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4693131264], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.102713942527771 seconds\n",
      "WARNING:model fit for {'num_rows': 1000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.10906696319580078 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4684038144], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['100'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0086839318275451 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.00857686996459961 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4678578176], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9564273118972778 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.11095786094665527 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4681752576], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9428561687469482 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.12262296676635742 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4681752576], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9631544828414917 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.13924527168273926 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4681752576], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.964055061340332 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.11104989051818848 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4681752576], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['100'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9416153192520141 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.10998320579528809 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4222279680], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.006682276725769 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.11266827583312988 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4212232192], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9020894765853882 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11129498481750488 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4215328768], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9384687900543213 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.008472204208374023 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4215328768], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.3378544569015502 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.11246109008789062 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4215328768], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['100'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9448884963989258 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.03331422805786133 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4215328768], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0498707135518393 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.1355748176574707 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4215328768], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9701103925704956 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.13904476165771484 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4215328768], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.5835665941238404 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.13147497177124023 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4212113408], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9712521314620972 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.13326478004455566 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4212408320], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.4361245393753053 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.13280582427978516 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4216283136], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.4087788820266725 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.1604158878326416 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4216283136], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 2.1315838098526 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.15730571746826172 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4216283136], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 2.146137261390686 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.15727901458740234 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4216283136], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.0474400758743285 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.1649169921875 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4224978944], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 1.0504788875579834 seconds\n",
      "INFO:data added for {'num_rows': 1000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.16098403930664062 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4224942080], 'num_cpu': [8], 'num_rows': [1000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 2.1286461114883424 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.007038116455078125 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4224942080], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9630794286727905 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.11174798011779785 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4224942080], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9549719333648682 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.11446213722229004 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4282626048], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9505796909332276 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.11261105537414551 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4325183488], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.986979866027832 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data added for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.11285710334777832 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4326965248], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [5], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9664422273635864 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.1631762981414795 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4254633984], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [5], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.048292088508606 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.08749890327453613 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4254633984], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [5], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 3.1945496797561646 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 5, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.11376619338989258 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4250648576], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9401273488998413 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.11086106300354004 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4250648576], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9360481023788452 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.008233070373535156 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4250648576], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9623567342758179 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.11271190643310547 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4235948032], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9383566796779632 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.1147470474243164 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4235386880], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.942611837387085 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.10988688468933105 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4235112448], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9470007419586182 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.010432004928588867 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4235112448], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 0.9504108667373657 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.13495087623596191 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4235112448], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.998576307296753 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.0362398624420166 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4235112448], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0498707135518393 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13327693939208984 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4235112448], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.0044395208358765 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} throws a ValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.15938878059387207 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4237004800], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.961527454853058 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.1573953628540039 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4237004800], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 2.145409178733826 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.1560678482055664 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4237004800], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.0467625856399536 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.16093707084655762 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4230680576], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.051534652709961 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.16447186470031738 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4230189056], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.9229715585708618 seconds\n",
      "WARNING:model fit for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} throws a JoblibValueError\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 50, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.1608278751373291 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4230336512], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [50], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.046971869468689 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.10780978202819824 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4230336512], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9643458366394043 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.11137890815734863 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4224282624], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.996347987651825 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.008502006530761719 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4223266816], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 0.9619709014892578 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11008906364440918 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4223266816], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9487239360809326 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.112030029296875 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4223266816], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9327775955200195 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.10850119590759277 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4223266816], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.9337478160858155 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.007913351058959961 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4223266816], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 0.9694589614868164 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.11008214950561523 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4223266816], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9151323080062866 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.11111807823181152 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4223266816], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [10], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 0.932735276222229 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.13495111465454102 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4222930944], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0003722429275512 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.13479208946228027 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4222210048], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['100'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.3999503612518311 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.13016986846923828 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4232110080], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.4058395385742188 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.1314098834991455 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4232110080], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 0.9583584070205688 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.13580799102783203 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4232110080], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['100'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.00088951587677 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.13528895378112793 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4232110080], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.002193021774292 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.034487009048461914 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4221988864], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model should take ~ 1.022140081723531 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.03365778923034668 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4222189568], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.0721290349960326 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.13196110725402832 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4221243392], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0006501793861389 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.13301372528076172 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4221243392], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 0.9966791152954102 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 5} which outputs 0.1356799602508545 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4221243392], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.4126428365707397 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.13213181495666504 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4221243392], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [50], 'max_depth': [100], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.4156564712524413 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 20, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.15801692008972168 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4215447552], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['20'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.0701364040374757 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 1, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.07337212562561035 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4226363392], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.1], 'max_features': ['100'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [1], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.1854494571685792 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 100, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.1631608009338379 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4226363392], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['100'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.0468736708164215 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.25, 'max_features': 50, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 5} which outputs 0.1628260612487793 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4226363392], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.25], 'max_features': ['50'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [5]}\n",
      "INFO:Training your model should take ~ 1.031667375564575 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.5, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 1} which outputs 0.07631373405456543 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4226363392], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.5], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 1.1397565126419067 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.25, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 5, 'bootstrap': False, 'oob_score': False, 'n_jobs': 8} which outputs 0.16243219375610352 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4226363392], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.25], 'max_features': ['auto'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [5], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.037696123123169 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 2} which outputs 0.1662309169769287 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4215533568], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [4], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['auto'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 2.0823909759521486 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.09692120552062988 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4214476800], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 3.2306315422058107 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 50, 'max_leaf_nodes': 2, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.16988182067871094 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4224999424], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [50], 'min_samples_split': [10], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['50'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.9336886405944824 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.5, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 5, 'min_impurity_split': 1, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.10363197326660156 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4224999424], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [1], 'min_weight_fraction_leaf': [0.5], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [5], 'min_impurity_split': [1], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 3.18902747631073 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 4, 'min_impurity_decrease': 1, 'min_impurity_split': 10, 'bootstrap': False, 'oob_score': False, 'n_jobs': 2} which outputs 0.16314411163330078 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4224999424], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [1], 'min_impurity_split': [10], 'bootstrap': [False], 'oob_score': [False], 'n_jobs': [2]}\n",
      "INFO:Training your model should take ~ 1.046971869468689 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'max_features': 100, 'max_leaf_nodes': 4, 'min_impurity_decrease': 10, 'min_impurity_split': 5, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.16927886009216309 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4224999424], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.1], 'max_features': ['100'], 'max_leaf_nodes': [4], 'min_impurity_decrease': [10], 'min_impurity_split': [5], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.9177430391311645 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.25, 'max_features': 20, 'max_leaf_nodes': 10, 'min_impurity_decrease': 10, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 8} which outputs 0.15964126586914062 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4721770496], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [5], 'min_weight_fraction_leaf': [0.25], 'max_features': ['20'], 'max_leaf_nodes': [10], 'min_impurity_decrease': [10], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [8]}\n",
      "INFO:Training your model should take ~ 1.9087105989456177 seconds\n",
      "INFO:data added for {'num_rows': 10000, 'num_features': 100, 'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'max_features': 10, 'max_leaf_nodes': 2, 'min_impurity_decrease': 5, 'min_impurity_split': 10, 'bootstrap': True, 'oob_score': False, 'n_jobs': 1} which outputs 0.09908914566040039 seconds\n",
      "INFO:Fetching estimator: RF_RandomForestRegressor_estimator.pkl\n",
      "INFO:Training your model for these params: {'total_memory': [17179869184], 'available_memory': [4721852416], 'num_cpu': [8], 'num_rows': [10000], 'num_features': [100], 'n_estimators': [100], 'max_depth': [100], 'min_samples_split': [2], 'min_samples_leaf': [10], 'min_weight_fraction_leaf': [0.1], 'max_features': ['10'], 'max_leaf_nodes': [2], 'min_impurity_decrease': [5], 'min_impurity_split': [10], 'bootstrap': [True], 'oob_score': [False], 'n_jobs': [1]}\n",
      "INFO:Training your model should take ~ 3.2001972436904906 seconds\n",
      "INFO:Trainer._permute took 70.487s seconds\n",
      "INFO:Trainer._generate_data took 70.495s seconds\n",
      "INFO:Trainer.model_validate took 70.681s seconds\n"
     ]
    }
   ],
   "source": [
    "vals = t.model_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>estimated_outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008669</td>\n",
       "      <td>1.425876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113591</td>\n",
       "      <td>0.964346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111952</td>\n",
       "      <td>0.936063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.135333</td>\n",
       "      <td>0.998141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.168667</td>\n",
       "      <td>1.047412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.111583</td>\n",
       "      <td>0.933779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.115212</td>\n",
       "      <td>0.949196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.115176</td>\n",
       "      <td>0.943033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.109167</td>\n",
       "      <td>0.994778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012625</td>\n",
       "      <td>1.338009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.110066</td>\n",
       "      <td>0.976250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.112746</td>\n",
       "      <td>0.930981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.007478</td>\n",
       "      <td>0.929965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.107824</td>\n",
       "      <td>0.950448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.113157</td>\n",
       "      <td>0.906030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.140662</td>\n",
       "      <td>1.443887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.134409</td>\n",
       "      <td>1.425914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.050490</td>\n",
       "      <td>2.505588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.039629</td>\n",
       "      <td>1.050593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.139156</td>\n",
       "      <td>0.971004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.043558</td>\n",
       "      <td>1.051284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.146308</td>\n",
       "      <td>1.422384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.165773</td>\n",
       "      <td>1.018277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.191050</td>\n",
       "      <td>1.055521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.173135</td>\n",
       "      <td>1.925180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.172958</td>\n",
       "      <td>1.044224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.093667</td>\n",
       "      <td>1.046792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.164079</td>\n",
       "      <td>1.966977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.169536</td>\n",
       "      <td>1.928240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.174310</td>\n",
       "      <td>1.007014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.108501</td>\n",
       "      <td>0.933748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.007913</td>\n",
       "      <td>0.969459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.915132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.111118</td>\n",
       "      <td>0.932735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.134951</td>\n",
       "      <td>1.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.134792</td>\n",
       "      <td>1.399950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.130170</td>\n",
       "      <td>1.405840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.131410</td>\n",
       "      <td>0.958358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.135808</td>\n",
       "      <td>1.000890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.135289</td>\n",
       "      <td>1.002193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.034487</td>\n",
       "      <td>1.022140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.033658</td>\n",
       "      <td>1.072129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.131961</td>\n",
       "      <td>1.000650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.133014</td>\n",
       "      <td>0.996679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.135680</td>\n",
       "      <td>1.412643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.132132</td>\n",
       "      <td>1.415656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.158017</td>\n",
       "      <td>1.070136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.073372</td>\n",
       "      <td>1.185449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.163161</td>\n",
       "      <td>1.046874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.162826</td>\n",
       "      <td>1.031667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.076314</td>\n",
       "      <td>1.139757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.162432</td>\n",
       "      <td>1.037696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.166231</td>\n",
       "      <td>2.082391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.096921</td>\n",
       "      <td>3.230632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.169882</td>\n",
       "      <td>1.933689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.103632</td>\n",
       "      <td>3.189027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.163144</td>\n",
       "      <td>1.046972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.169279</td>\n",
       "      <td>1.917743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.159641</td>\n",
       "      <td>1.908711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.099089</td>\n",
       "      <td>3.200197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       output  estimated_outputs\n",
       "0    0.008669           1.425876\n",
       "1    0.113591           0.964346\n",
       "2    0.111952           0.936063\n",
       "3    0.135333           0.998141\n",
       "4    0.168667           1.047412\n",
       "5    0.111583           0.933779\n",
       "6    0.115212           0.949196\n",
       "7    0.115176           0.943033\n",
       "8    0.109167           0.994778\n",
       "9    0.012625           1.338009\n",
       "10   0.110066           0.976250\n",
       "11   0.112746           0.930981\n",
       "12   0.007478           0.929965\n",
       "13   0.107824           0.950448\n",
       "14   0.113157           0.906030\n",
       "15   0.140662           1.443887\n",
       "16   0.134409           1.425914\n",
       "17   0.050490           2.505588\n",
       "18   0.039629           1.050593\n",
       "19   0.139156           0.971004\n",
       "20   0.043558           1.051284\n",
       "21   0.146308           1.422384\n",
       "22   0.165773           1.018277\n",
       "23   0.191050           1.055521\n",
       "24   0.173135           1.925180\n",
       "25   0.172958           1.044224\n",
       "26   0.093667           1.046792\n",
       "27   0.164079           1.966977\n",
       "28   0.169536           1.928240\n",
       "29   0.174310           1.007014\n",
       "..        ...                ...\n",
       "143  0.108501           0.933748\n",
       "144  0.007913           0.969459\n",
       "145  0.110082           0.915132\n",
       "146  0.111118           0.932735\n",
       "147  0.134951           1.000372\n",
       "148  0.134792           1.399950\n",
       "149  0.130170           1.405840\n",
       "150  0.131410           0.958358\n",
       "151  0.135808           1.000890\n",
       "152  0.135289           1.002193\n",
       "153  0.034487           1.022140\n",
       "154  0.033658           1.072129\n",
       "155  0.131961           1.000650\n",
       "156  0.133014           0.996679\n",
       "157  0.135680           1.412643\n",
       "158  0.132132           1.415656\n",
       "159  0.158017           1.070136\n",
       "160  0.073372           1.185449\n",
       "161  0.163161           1.046874\n",
       "162  0.162826           1.031667\n",
       "163  0.076314           1.139757\n",
       "164  0.162432           1.037696\n",
       "165  0.166231           2.082391\n",
       "166  0.096921           3.230632\n",
       "167  0.169882           1.933689\n",
       "168  0.103632           3.189027\n",
       "169  0.163144           1.046972\n",
       "170  0.169279           1.917743\n",
       "171  0.159641           1.908711\n",
       "172  0.099089           3.200197\n",
       "\n",
       "[173 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals[1].join(vals[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimated_outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.425876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.964346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.936063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.047412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.933779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.949196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.943033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.994778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.338009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.976250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.930981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.929965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.950448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.906030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.443887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.425914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.505588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.050593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.971004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.051284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.422384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.018277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.055521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.925180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.044224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.046792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.966977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.928240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.007014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.933748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.969459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.915132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.932735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.399950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.405840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.958358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1.000890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1.002193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1.022140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1.072129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1.000650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.996679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.412643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.415656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.070136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.185449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.046874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.031667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.139757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.037696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2.082391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>3.230632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.933689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>3.189027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.046972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.917743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.908711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3.200197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     estimated_outputs\n",
       "0             1.425876\n",
       "1             0.964346\n",
       "2             0.936063\n",
       "3             0.998141\n",
       "4             1.047412\n",
       "5             0.933779\n",
       "6             0.949196\n",
       "7             0.943033\n",
       "8             0.994778\n",
       "9             1.338009\n",
       "10            0.976250\n",
       "11            0.930981\n",
       "12            0.929965\n",
       "13            0.950448\n",
       "14            0.906030\n",
       "15            1.443887\n",
       "16            1.425914\n",
       "17            2.505588\n",
       "18            1.050593\n",
       "19            0.971004\n",
       "20            1.051284\n",
       "21            1.422384\n",
       "22            1.018277\n",
       "23            1.055521\n",
       "24            1.925180\n",
       "25            1.044224\n",
       "26            1.046792\n",
       "27            1.966977\n",
       "28            1.928240\n",
       "29            1.007014\n",
       "..                 ...\n",
       "143           0.933748\n",
       "144           0.969459\n",
       "145           0.915132\n",
       "146           0.932735\n",
       "147           1.000372\n",
       "148           1.399950\n",
       "149           1.405840\n",
       "150           0.958358\n",
       "151           1.000890\n",
       "152           1.002193\n",
       "153           1.022140\n",
       "154           1.072129\n",
       "155           1.000650\n",
       "156           0.996679\n",
       "157           1.412643\n",
       "158           1.415656\n",
       "159           1.070136\n",
       "160           1.185449\n",
       "161           1.046874\n",
       "162           1.031667\n",
       "163           1.139757\n",
       "164           1.037696\n",
       "165           2.082391\n",
       "166           3.230632\n",
       "167           1.933689\n",
       "168           3.189027\n",
       "169           1.046972\n",
       "170           1.917743\n",
       "171           1.908711\n",
       "172           3.200197\n",
       "\n",
       "[173 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3552.000000\n",
       "mean        1.147250\n",
       "std         1.303457\n",
       "min         0.008392\n",
       "25%         0.137756\n",
       "50%         0.789910\n",
       "75%         1.578794\n",
       "max         8.408077\n",
       "Name: output, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['output'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_memory</th>\n",
       "      <th>available_memory</th>\n",
       "      <th>num_cpu</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>num_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_weight_fraction_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_impurity_split</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>oob_score</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7866642432</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.111470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7866396672</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7866396672</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.109440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7866396672</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.110034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7866400768</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.109050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7866400768</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.110876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7866273792</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7866273792</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.108982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7866273792</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.109257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7865892864</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.109607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7865892864</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.110622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7865516032</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.109584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7865643008</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.109588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7865769984</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.109140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7865524224</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7865524224</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.109747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7865397248</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7865020416</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7865020416</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.137816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7865245696</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7864995840</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.137165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7864995840</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.137422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7864995840</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.137675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7864864768</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.138184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7864868864</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.138006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7864487936</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.137448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7864614912</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.138417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7864614912</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.138349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7864614912</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.137466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7864614912</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.138478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7737450496</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>8.408077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7737171968</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.864994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7737393152</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>4.311031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7743938560</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.777174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7743918080</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>4.363928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7722721280</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2.953918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7708467200</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2.885204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7721271296</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3.177824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7728721920</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>8.228459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7720828928</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2.899300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7713673216</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.829369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7713808384</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>4.861142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7714541568</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>4.877358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7702306816</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>4.883076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7682064384</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2.848859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7700299776</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>4.719067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7699615744</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>4.927418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7696257024</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2.871254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7716163584</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3.092481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7724032000</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2.926043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7708397568</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>4.919522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7672819712</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2.864806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7721512960</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2.847708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7713689600</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3.176153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7721811968</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>4.279345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7708086272</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>5.127818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7672541184</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>4.429864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7716155392</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2.879327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7721082880</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>4.820026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>8375676928</td>\n",
       "      <td>7728533504</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2.877606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3552 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_memory  available_memory  num_cpu  num_rows  num_features  \\\n",
       "0       8375676928        7866642432        4       100             5   \n",
       "1       8375676928        7866396672        4       100             5   \n",
       "2       8375676928        7866396672        4       100             5   \n",
       "3       8375676928        7866396672        4       100             5   \n",
       "4       8375676928        7866400768        4       100             5   \n",
       "5       8375676928        7866400768        4       100             5   \n",
       "6       8375676928        7866273792        4       100             5   \n",
       "7       8375676928        7866273792        4       100             5   \n",
       "8       8375676928        7866273792        4       100             5   \n",
       "9       8375676928        7865892864        4       100             5   \n",
       "10      8375676928        7865892864        4       100             5   \n",
       "11      8375676928        7865516032        4       100             5   \n",
       "12      8375676928        7865643008        4       100             5   \n",
       "13      8375676928        7865769984        4       100             5   \n",
       "14      8375676928        7865524224        4       100             5   \n",
       "15      8375676928        7865524224        4       100             5   \n",
       "16      8375676928        7865397248        4       100             5   \n",
       "17      8375676928        7865020416        4       100             5   \n",
       "18      8375676928        7865020416        4       100             5   \n",
       "19      8375676928        7865245696        4       100             5   \n",
       "20      8375676928        7864995840        4       100             5   \n",
       "21      8375676928        7864995840        4       100             5   \n",
       "22      8375676928        7864995840        4       100             5   \n",
       "23      8375676928        7864864768        4       100             5   \n",
       "24      8375676928        7864868864        4       100             5   \n",
       "25      8375676928        7864487936        4       100             5   \n",
       "26      8375676928        7864614912        4       100             5   \n",
       "27      8375676928        7864614912        4       100             5   \n",
       "28      8375676928        7864614912        4       100             5   \n",
       "29      8375676928        7864614912        4       100             5   \n",
       "...            ...               ...      ...       ...           ...   \n",
       "3522    8375676928        7737450496        4   1000000           600   \n",
       "3523    8375676928        7737171968        4   1000000           600   \n",
       "3524    8375676928        7737393152        4   1000000           600   \n",
       "3525    8375676928        7743938560        4   1000000           600   \n",
       "3526    8375676928        7743918080        4   1000000           600   \n",
       "3527    8375676928        7722721280        4   1000000           600   \n",
       "3528    8375676928        7708467200        4   1000000           600   \n",
       "3529    8375676928        7721271296        4   1000000           600   \n",
       "3530    8375676928        7728721920        4   1000000           600   \n",
       "3531    8375676928        7720828928        4   1000000           600   \n",
       "3532    8375676928        7713673216        4   1000000           600   \n",
       "3533    8375676928        7713808384        4   1000000           600   \n",
       "3534    8375676928        7714541568        4   1000000           600   \n",
       "3535    8375676928        7702306816        4   1000000           600   \n",
       "3536    8375676928        7682064384        4   1000000           600   \n",
       "3537    8375676928        7700299776        4   1000000           600   \n",
       "3538    8375676928        7699615744        4   1000000           600   \n",
       "3539    8375676928        7696257024        4   1000000           600   \n",
       "3540    8375676928        7716163584        4   1000000           600   \n",
       "3541    8375676928        7724032000        4   1000000           600   \n",
       "3542    8375676928        7708397568        4   1000000           600   \n",
       "3543    8375676928        7672819712        4   1000000           600   \n",
       "3544    8375676928        7721512960        4   1000000           600   \n",
       "3545    8375676928        7713689600        4   1000000           600   \n",
       "3546    8375676928        7721811968        4   1000000           600   \n",
       "3547    8375676928        7708086272        4   1000000           600   \n",
       "3548    8375676928        7672541184        4   1000000           600   \n",
       "3549    8375676928        7716155392        4   1000000           600   \n",
       "3550    8375676928        7721082880        4   1000000           600   \n",
       "3551    8375676928        7728533504        4   1000000           600   \n",
       "\n",
       "      n_estimators  max_depth  min_samples_split  min_samples_leaf  \\\n",
       "0               10         10                 10                 5   \n",
       "1               10         50                  2                 5   \n",
       "2               10         50                  2                 5   \n",
       "3               10         50                  2                 5   \n",
       "4               10         50                  2                10   \n",
       "5               10         50                  2                10   \n",
       "6               10         50                  4                 1   \n",
       "7               10         50                  4                 1   \n",
       "8               10         50                  4                 1   \n",
       "9               10         50                 10                 5   \n",
       "10              10         50                 10                10   \n",
       "11              10        100                  2                 5   \n",
       "12              10        100                  4                 1   \n",
       "13              10        100                  4                 5   \n",
       "14              10        100                  4                 5   \n",
       "15              10        100                  4                10   \n",
       "16              10        100                  4                10   \n",
       "17              10        100                 10                10   \n",
       "18              50         10                  2                 1   \n",
       "19              50         10                  4                 5   \n",
       "20              50         10                  4                10   \n",
       "21              50         10                  4                10   \n",
       "22              50         10                  4                10   \n",
       "23              50         10                 10                 1   \n",
       "24              50         10                 10                 5   \n",
       "25              50         10                 10                10   \n",
       "26              50         50                  2                 1   \n",
       "27              50         50                  2                 5   \n",
       "28              50         50                  2                 5   \n",
       "29              50         50                 10                 1   \n",
       "...            ...        ...                ...               ...   \n",
       "3522           100         50                 10                10   \n",
       "3523           100         50                 10                10   \n",
       "3524           100         50                 10                10   \n",
       "3525           100        100                  2                 1   \n",
       "3526           100        100                  2                 1   \n",
       "3527           100        100                  2                 5   \n",
       "3528           100        100                  2                10   \n",
       "3529           100        100                  2                10   \n",
       "3530           100        100                  2                10   \n",
       "3531           100        100                  4                 1   \n",
       "3532           100        100                  4                 1   \n",
       "3533           100        100                  4                 1   \n",
       "3534           100        100                  4                 1   \n",
       "3535           100        100                  4                 1   \n",
       "3536           100        100                  4                 1   \n",
       "3537           100        100                  4                 1   \n",
       "3538           100        100                  4                 1   \n",
       "3539           100        100                  4                 5   \n",
       "3540           100        100                  4                 5   \n",
       "3541           100        100                  4                10   \n",
       "3542           100        100                  4                10   \n",
       "3543           100        100                  4                10   \n",
       "3544           100        100                  4                10   \n",
       "3545           100        100                  4                10   \n",
       "3546           100        100                 10                 1   \n",
       "3547           100        100                 10                 1   \n",
       "3548           100        100                 10                 1   \n",
       "3549           100        100                 10                 5   \n",
       "3550           100        100                 10                 5   \n",
       "3551           100        100                 10                 5   \n",
       "\n",
       "      min_weight_fraction_leaf max_features  max_leaf_nodes  \\\n",
       "0                         0.25         auto               2   \n",
       "1                         0.10         auto               2   \n",
       "2                         0.25         auto               4   \n",
       "3                         0.50         auto               4   \n",
       "4                         0.25         auto               4   \n",
       "5                         0.50         auto              10   \n",
       "6                         0.25         auto               4   \n",
       "7                         0.25         auto              10   \n",
       "8                         0.50         auto              10   \n",
       "9                         0.25         auto               4   \n",
       "10                        0.10         auto              10   \n",
       "11                        0.50         auto              10   \n",
       "12                        0.10         auto              10   \n",
       "13                        0.10         auto               4   \n",
       "14                        0.50         auto               4   \n",
       "15                        0.10         auto               2   \n",
       "16                        0.25         auto              10   \n",
       "17                        0.50         auto               2   \n",
       "18                        0.10         auto               4   \n",
       "19                        0.10         auto               2   \n",
       "20                        0.25         auto              10   \n",
       "21                        0.50         auto               4   \n",
       "22                        0.50         auto              10   \n",
       "23                        0.10         auto               2   \n",
       "24                        0.25         auto               4   \n",
       "25                        0.10         auto              10   \n",
       "26                        0.50         auto               2   \n",
       "27                        0.10         auto               2   \n",
       "28                        0.25         auto               2   \n",
       "29                        0.25         auto              10   \n",
       "...                        ...          ...             ...   \n",
       "3522                      0.25          100              10   \n",
       "3523                      0.50           50               4   \n",
       "3524                      0.50           50               4   \n",
       "3525                      0.10         auto               4   \n",
       "3526                      0.25           10              10   \n",
       "3527                      0.25           10               2   \n",
       "3528                      0.10           20               2   \n",
       "3529                      0.25          100              10   \n",
       "3530                      0.50          100               2   \n",
       "3531                      0.10         auto               4   \n",
       "3532                      0.10           10               4   \n",
       "3533                      0.10           20              10   \n",
       "3534                      0.10           50               4   \n",
       "3535                      0.25           20               4   \n",
       "3536                      0.25           50               2   \n",
       "3537                      0.25          100               4   \n",
       "3538                      0.50           10              10   \n",
       "3539                      0.10           10              10   \n",
       "3540                      0.50           10               4   \n",
       "3541                      0.10           50               4   \n",
       "3542                      0.10          100               4   \n",
       "3543                      0.25         auto              10   \n",
       "3544                      0.50           20               4   \n",
       "3545                      0.50          100               2   \n",
       "3546                      0.50           20              10   \n",
       "3547                      0.50           50               4   \n",
       "3548                      0.50           50              10   \n",
       "3549                      0.10         auto               4   \n",
       "3550                      0.50           20              10   \n",
       "3551                      0.50          100               4   \n",
       "\n",
       "      min_impurity_decrease  min_impurity_split  bootstrap  oob_score  n_jobs  \\\n",
       "0                         1                   5      False      False       8   \n",
       "1                        10                   1      False      False       1   \n",
       "2                         1                   1       True      False       2   \n",
       "3                        10                   5       True      False       5   \n",
       "4                         5                  10      False      False       2   \n",
       "5                        10                   1       True      False       8   \n",
       "6                         5                   5      False      False       1   \n",
       "7                        10                   1       True      False       2   \n",
       "8                         1                   1      False      False       2   \n",
       "9                        10                   5       True      False       5   \n",
       "10                        5                   5       True      False       8   \n",
       "11                        1                   5       True      False       5   \n",
       "12                        5                   1       True      False       5   \n",
       "13                       10                  10      False      False       2   \n",
       "14                       10                   1      False      False       1   \n",
       "15                        1                   1      False      False       5   \n",
       "16                        1                  10      False      False       1   \n",
       "17                       10                   5       True      False       1   \n",
       "18                       10                  10       True      False       8   \n",
       "19                        1                   1      False      False       1   \n",
       "20                       10                   5      False      False       5   \n",
       "21                        5                  10      False      False       5   \n",
       "22                        5                  10      False      False       8   \n",
       "23                        5                   5       True      False       8   \n",
       "24                       10                   1       True      False       5   \n",
       "25                       10                  10      False      False       8   \n",
       "26                        1                   1      False      False       8   \n",
       "27                       10                   1       True      False       8   \n",
       "28                        1                  10      False      False       5   \n",
       "29                        1                  10      False      False       8   \n",
       "...                     ...                 ...        ...        ...     ...   \n",
       "3522                     10                   1       True      False       1   \n",
       "3523                      1                  10       True      False       1   \n",
       "3524                     10                   5       True      False       8   \n",
       "3525                      1                   1       True      False       1   \n",
       "3526                     10                   5       True      False       8   \n",
       "3527                      1                  10      False      False       2   \n",
       "3528                     10                  10      False      False       8   \n",
       "3529                      5                   5      False      False       1   \n",
       "3530                     10                   5       True      False       1   \n",
       "3531                     10                   1      False      False       5   \n",
       "3532                     10                  10       True      False       1   \n",
       "3533                      5                   5       True      False       8   \n",
       "3534                      5                   5       True      False       2   \n",
       "3535                      5                  10       True      False       2   \n",
       "3536                      5                   1      False      False       5   \n",
       "3537                      5                   1       True      False       2   \n",
       "3538                     10                   1       True      False       2   \n",
       "3539                     10                   5      False      False       8   \n",
       "3540                      1                   1      False      False       1   \n",
       "3541                      5                   1      False      False       8   \n",
       "3542                      1                  10       True      False       2   \n",
       "3543                      5                   1      False      False       5   \n",
       "3544                      5                  10      False      False       8   \n",
       "3545                      1                   5      False      False       1   \n",
       "3546                     10                   1       True      False       5   \n",
       "3547                      5                   1       True      False       2   \n",
       "3548                      5                   1       True      False       5   \n",
       "3549                      5                   5      False      False       5   \n",
       "3550                     10                   5       True      False       5   \n",
       "3551                     10                  10      False      False       5   \n",
       "\n",
       "        output  \n",
       "0     0.111470  \n",
       "1     0.009609  \n",
       "2     0.109440  \n",
       "3     0.110034  \n",
       "4     0.109050  \n",
       "5     0.110876  \n",
       "6     0.009290  \n",
       "7     0.108982  \n",
       "8     0.109257  \n",
       "9     0.109607  \n",
       "10    0.110622  \n",
       "11    0.109584  \n",
       "12    0.109588  \n",
       "13    0.109140  \n",
       "14    0.008633  \n",
       "15    0.109747  \n",
       "16    0.008592  \n",
       "17    0.008888  \n",
       "18    0.137816  \n",
       "19    0.039762  \n",
       "20    0.137165  \n",
       "21    0.137422  \n",
       "22    0.137675  \n",
       "23    0.138184  \n",
       "24    0.138006  \n",
       "25    0.137448  \n",
       "26    0.138417  \n",
       "27    0.138349  \n",
       "28    0.137466  \n",
       "29    0.138478  \n",
       "...        ...  \n",
       "3522  8.408077  \n",
       "3523  7.864994  \n",
       "3524  4.311031  \n",
       "3525  7.777174  \n",
       "3526  4.363928  \n",
       "3527  2.953918  \n",
       "3528  2.885204  \n",
       "3529  3.177824  \n",
       "3530  8.228459  \n",
       "3531  2.899300  \n",
       "3532  7.829369  \n",
       "3533  4.861142  \n",
       "3534  4.877358  \n",
       "3535  4.883076  \n",
       "3536  2.848859  \n",
       "3537  4.719067  \n",
       "3538  4.927418  \n",
       "3539  2.871254  \n",
       "3540  3.092481  \n",
       "3541  2.926043  \n",
       "3542  4.919522  \n",
       "3543  2.864806  \n",
       "3544  2.847708  \n",
       "3545  3.176153  \n",
       "3546  4.279345  \n",
       "3547  5.127818  \n",
       "3548  4.429864  \n",
       "3549  2.879327  \n",
       "3550  4.820026  \n",
       "3551  2.877606  \n",
       "\n",
       "[3552 rows x 18 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
